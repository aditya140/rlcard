{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('rlcard': conda)",
   "display_name": "Python 3.6.12 64-bit ('rlcard': conda)",
   "metadata": {
    "interpreter": {
     "hash": "05f5c1c5a3162497bb8d473e589ac69618e771154a6edb3ca39318199bbc0425"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1\n",
      "  reward       |  -0.192\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132, rl-loss: 0.38883736729621887\n",
      "----------------------------------------\n",
      "  timestep     |  131\n",
      "  reward       |  -0.128\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 264, rl-loss: 0.38365113735198975\n",
      "----------------------------------------\n",
      "  timestep     |  263\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 397, rl-loss: 0.5564534068107605\n",
      "----------------------------------------\n",
      "  timestep     |  396\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 540, rl-loss: 0.435441255569458\n",
      "----------------------------------------\n",
      "  timestep     |  539\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 678, rl-loss: 0.4252524673938751\n",
      "----------------------------------------\n",
      "  timestep     |  677\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 825, rl-loss: 0.5442679524421692\n",
      "----------------------------------------\n",
      "  timestep     |  824\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 969, rl-loss: 0.564335286617279\n",
      "----------------------------------------\n",
      "  timestep     |  968\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1106, rl-loss: 0.3736012578010559\n",
      "----------------------------------------\n",
      "  timestep     |  1105\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1250, rl-loss: 0.5598679184913635\n",
      "----------------------------------------\n",
      "  timestep     |  1249\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1381, rl-loss: 0.4453868865966797\n",
      "----------------------------------------\n",
      "  timestep     |  1380\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1514, rl-loss: 0.4552152752876282\n",
      "----------------------------------------\n",
      "  timestep     |  1513\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1643, rl-loss: 0.5506138205528259\n",
      "----------------------------------------\n",
      "  timestep     |  1642\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1783, rl-loss: 0.3768208622932434\n",
      "----------------------------------------\n",
      "  timestep     |  1782\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 1916, rl-loss: 0.5365272760391235\n",
      "----------------------------------------\n",
      "  timestep     |  1915\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2052, rl-loss: 0.6120015382766724\n",
      "----------------------------------------\n",
      "  timestep     |  2051\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2183, rl-loss: 0.49011629819869995\n",
      "----------------------------------------\n",
      "  timestep     |  2182\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2317, rl-loss: 0.4501672089099884\n",
      "----------------------------------------\n",
      "  timestep     |  2316\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2460, rl-loss: 0.6710898280143738\n",
      "----------------------------------------\n",
      "  timestep     |  2459\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2597, rl-loss: 0.5238342881202698\n",
      "----------------------------------------\n",
      "  timestep     |  2596\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2739, rl-loss: 0.5763018131256104\n",
      "----------------------------------------\n",
      "  timestep     |  2738\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 2887, rl-loss: 0.742267370223999\n",
      "----------------------------------------\n",
      "  timestep     |  2886\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3026, rl-loss: 0.6244816184043884\n",
      "----------------------------------------\n",
      "  timestep     |  3025\n",
      "  reward       |  -0.007\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3162, rl-loss: 0.4425872564315796\n",
      "----------------------------------------\n",
      "  timestep     |  3161\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3310, rl-loss: 0.6568706035614014\n",
      "----------------------------------------\n",
      "  timestep     |  3309\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3438, rl-loss: 0.5544776916503906\n",
      "----------------------------------------\n",
      "  timestep     |  3437\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3581, rl-loss: 0.5914115309715271\n",
      "----------------------------------------\n",
      "  timestep     |  3580\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3731, rl-loss: 0.5632489919662476\n",
      "----------------------------------------\n",
      "  timestep     |  3730\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 3867, rl-loss: 0.5889490842819214\n",
      "----------------------------------------\n",
      "  timestep     |  3866\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4015, rl-loss: 0.4506531059741974\n",
      "----------------------------------------\n",
      "  timestep     |  4014\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4150, rl-loss: 0.48810669779777527\n",
      "----------------------------------------\n",
      "  timestep     |  4149\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4296, rl-loss: 0.6324409246444702\n",
      "----------------------------------------\n",
      "  timestep     |  4295\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4450, rl-loss: 0.42023783922195435\n",
      "----------------------------------------\n",
      "  timestep     |  4449\n",
      "  reward       |  0.004\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4591, rl-loss: 0.5850872993469238\n",
      "----------------------------------------\n",
      "  timestep     |  4590\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4724, rl-loss: 0.3946588635444641\n",
      "----------------------------------------\n",
      "  timestep     |  4723\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 4862, rl-loss: 0.4043315052986145\n",
      "----------------------------------------\n",
      "  timestep     |  4861\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5001, rl-loss: 0.6390770077705383\n",
      "----------------------------------------\n",
      "  timestep     |  5000\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5143, rl-loss: 0.6440632343292236\n",
      "----------------------------------------\n",
      "  timestep     |  5142\n",
      "  reward       |  0.006\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5296, rl-loss: 0.5084234476089478\n",
      "----------------------------------------\n",
      "  timestep     |  5295\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5435, rl-loss: 0.45490050315856934\n",
      "----------------------------------------\n",
      "  timestep     |  5434\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5567, rl-loss: 0.33788320422172546\n",
      "----------------------------------------\n",
      "  timestep     |  5566\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5705, rl-loss: 0.9494308233261108\n",
      "----------------------------------------\n",
      "  timestep     |  5704\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5849, rl-loss: 0.5962697267532349\n",
      "----------------------------------------\n",
      "  timestep     |  5848\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 5990, rl-loss: 0.5709560513496399\n",
      "----------------------------------------\n",
      "  timestep     |  5989\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 6143, rl-loss: 0.5548994541168213\n",
      "----------------------------------------\n",
      "  timestep     |  6142\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 6281, rl-loss: 0.49928101897239685\n",
      "----------------------------------------\n",
      "  timestep     |  6280\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 6427, rl-loss: 0.6558100581169128\n",
      "----------------------------------------\n",
      "  timestep     |  6426\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 6576, rl-loss: 0.5615272521972656\n",
      "----------------------------------------\n",
      "  timestep     |  6575\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 6722, rl-loss: 0.5826202630996704\n",
      "----------------------------------------\n",
      "  timestep     |  6721\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 6868, rl-loss: 0.4674142003059387\n",
      "----------------------------------------\n",
      "  timestep     |  6867\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7009, rl-loss: 0.7195942401885986\n",
      "----------------------------------------\n",
      "  timestep     |  7008\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7152, rl-loss: 0.4112143814563751\n",
      "----------------------------------------\n",
      "  timestep     |  7151\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7296, rl-loss: 0.3412718176841736\n",
      "----------------------------------------\n",
      "  timestep     |  7295\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7433, rl-loss: 0.3473018705844879\n",
      "----------------------------------------\n",
      "  timestep     |  7432\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7577, rl-loss: 0.4782165288925171\n",
      "----------------------------------------\n",
      "  timestep     |  7576\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7721, rl-loss: 0.6181929111480713\n",
      "----------------------------------------\n",
      "  timestep     |  7720\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 7860, rl-loss: 0.3670458197593689\n",
      "----------------------------------------\n",
      "  timestep     |  7859\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8006, rl-loss: 0.4604532718658447\n",
      "----------------------------------------\n",
      "  timestep     |  8005\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8143, rl-loss: 0.4245046377182007\n",
      "----------------------------------------\n",
      "  timestep     |  8142\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8283, rl-loss: 0.46754729747772217\n",
      "----------------------------------------\n",
      "  timestep     |  8282\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8417, rl-loss: 0.42846205830574036\n",
      "----------------------------------------\n",
      "  timestep     |  8416\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8547, rl-loss: 0.6205256581306458\n",
      "----------------------------------------\n",
      "  timestep     |  8546\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8678, rl-loss: 0.41058167815208435\n",
      "----------------------------------------\n",
      "  timestep     |  8677\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8816, rl-loss: 0.501291036605835\n",
      "----------------------------------------\n",
      "  timestep     |  8815\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 8942, rl-loss: 0.5276542901992798\n",
      "----------------------------------------\n",
      "  timestep     |  8941\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9083, rl-loss: 0.4259952902793884\n",
      "----------------------------------------\n",
      "  timestep     |  9082\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9225, rl-loss: 0.5046534538269043\n",
      "----------------------------------------\n",
      "  timestep     |  9224\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9359, rl-loss: 0.8197499513626099\n",
      "----------------------------------------\n",
      "  timestep     |  9358\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9509, rl-loss: 0.5789082646369934\n",
      "----------------------------------------\n",
      "  timestep     |  9508\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9662, rl-loss: 0.5653302669525146\n",
      "----------------------------------------\n",
      "  timestep     |  9661\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9796, rl-loss: 0.6820724606513977\n",
      "----------------------------------------\n",
      "  timestep     |  9795\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 9933, rl-loss: 0.5011869668960571\n",
      "----------------------------------------\n",
      "  timestep     |  9932\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10078, rl-loss: 0.46681898832321167\n",
      "----------------------------------------\n",
      "  timestep     |  10077\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10218, rl-loss: 0.47057172656059265\n",
      "----------------------------------------\n",
      "  timestep     |  10217\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10358, rl-loss: 0.4789104163646698\n",
      "----------------------------------------\n",
      "  timestep     |  10357\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10501, rl-loss: 0.40375709533691406\n",
      "----------------------------------------\n",
      "  timestep     |  10500\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10637, rl-loss: 0.7466703057289124\n",
      "----------------------------------------\n",
      "  timestep     |  10636\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10792, rl-loss: 0.7180065512657166\n",
      "----------------------------------------\n",
      "  timestep     |  10791\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 10933, rl-loss: 0.5471124053001404\n",
      "----------------------------------------\n",
      "  timestep     |  10932\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11091, rl-loss: 0.42545270919799805\n",
      "----------------------------------------\n",
      "  timestep     |  11090\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11234, rl-loss: 0.4013681411743164\n",
      "----------------------------------------\n",
      "  timestep     |  11233\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11370, rl-loss: 0.5496074557304382\n",
      "----------------------------------------\n",
      "  timestep     |  11369\n",
      "  reward       |  -0.139\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11507, rl-loss: 0.6579811573028564\n",
      "----------------------------------------\n",
      "  timestep     |  11506\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11663, rl-loss: 0.6836962699890137\n",
      "----------------------------------------\n",
      "  timestep     |  11662\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11804, rl-loss: 0.43315181136131287\n",
      "----------------------------------------\n",
      "  timestep     |  11803\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 11950, rl-loss: 0.4332166314125061\n",
      "----------------------------------------\n",
      "  timestep     |  11949\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12098, rl-loss: 0.49841079115867615\n",
      "----------------------------------------\n",
      "  timestep     |  12097\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12247, rl-loss: 0.49806126952171326\n",
      "----------------------------------------\n",
      "  timestep     |  12246\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12393, rl-loss: 0.505187451839447\n",
      "----------------------------------------\n",
      "  timestep     |  12392\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12552, rl-loss: 0.3712480962276459\n",
      "----------------------------------------\n",
      "  timestep     |  12551\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12708, rl-loss: 0.4631430506706238\n",
      "----------------------------------------\n",
      "  timestep     |  12707\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12853, rl-loss: 0.34893926978111267\n",
      "----------------------------------------\n",
      "  timestep     |  12852\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 12996, rl-loss: 0.49471449851989746\n",
      "----------------------------------------\n",
      "  timestep     |  12995\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 13140, rl-loss: 0.3985869288444519\n",
      "----------------------------------------\n",
      "  timestep     |  13139\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 13290, rl-loss: 0.5300565958023071\n",
      "----------------------------------------\n",
      "  timestep     |  13289\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 13435, rl-loss: 0.5040609240531921\n",
      "----------------------------------------\n",
      "  timestep     |  13434\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 13583, rl-loss: 0.3553454875946045\n",
      "----------------------------------------\n",
      "  timestep     |  13582\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 13726, rl-loss: 0.45898163318634033\n",
      "----------------------------------------\n",
      "  timestep     |  13725\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 13868, rl-loss: 0.7259660363197327\n",
      "----------------------------------------\n",
      "  timestep     |  13867\n",
      "  reward       |  -0.139\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14022, rl-loss: 0.6027072072029114\n",
      "----------------------------------------\n",
      "  timestep     |  14021\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14178, rl-loss: 0.5075539350509644\n",
      "----------------------------------------\n",
      "  timestep     |  14177\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14308, rl-loss: 0.6018767952919006\n",
      "----------------------------------------\n",
      "  timestep     |  14307\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14453, rl-loss: 0.6963863968849182\n",
      "----------------------------------------\n",
      "  timestep     |  14452\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14603, rl-loss: 0.359343022108078\n",
      "----------------------------------------\n",
      "  timestep     |  14602\n",
      "  reward       |  -0.144\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14740, rl-loss: 0.5450196266174316\n",
      "----------------------------------------\n",
      "  timestep     |  14739\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 14884, rl-loss: 0.43805843591690063\n",
      "----------------------------------------\n",
      "  timestep     |  14883\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15037, rl-loss: 0.42193347215652466\n",
      "----------------------------------------\n",
      "  timestep     |  15036\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15180, rl-loss: 0.4681064486503601\n",
      "----------------------------------------\n",
      "  timestep     |  15179\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15325, rl-loss: 0.3369680643081665\n",
      "----------------------------------------\n",
      "  timestep     |  15324\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15479, rl-loss: 0.49403059482574463\n",
      "----------------------------------------\n",
      "  timestep     |  15478\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15630, rl-loss: 0.736268162727356\n",
      "----------------------------------------\n",
      "  timestep     |  15629\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15778, rl-loss: 0.44897541403770447\n",
      "----------------------------------------\n",
      "  timestep     |  15777\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 15941, rl-loss: 0.6264722347259521\n",
      "----------------------------------------\n",
      "  timestep     |  15940\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16088, rl-loss: 0.42764174938201904\n",
      "----------------------------------------\n",
      "  timestep     |  16087\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16247, rl-loss: 0.5473177433013916\n",
      "----------------------------------------\n",
      "  timestep     |  16246\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16394, rl-loss: 0.3804325759410858\n",
      "----------------------------------------\n",
      "  timestep     |  16393\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16535, rl-loss: 0.5257118344306946\n",
      "----------------------------------------\n",
      "  timestep     |  16534\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16669, rl-loss: 0.5756571888923645\n",
      "----------------------------------------\n",
      "  timestep     |  16668\n",
      "  reward       |  -0.018\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16809, rl-loss: 0.6806557774543762\n",
      "----------------------------------------\n",
      "  timestep     |  16808\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 16955, rl-loss: 0.37818631529808044\n",
      "----------------------------------------\n",
      "  timestep     |  16954\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 17115, rl-loss: 0.4181453585624695\n",
      "----------------------------------------\n",
      "  timestep     |  17114\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 17265, rl-loss: 0.37621498107910156\n",
      "----------------------------------------\n",
      "  timestep     |  17264\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 17423, rl-loss: 0.4663165807723999\n",
      "----------------------------------------\n",
      "  timestep     |  17422\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 17588, rl-loss: 0.5222873687744141\n",
      "----------------------------------------\n",
      "  timestep     |  17587\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 17752, rl-loss: 0.3236464262008667\n",
      "----------------------------------------\n",
      "  timestep     |  17751\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 17914, rl-loss: 0.5245347023010254\n",
      "----------------------------------------\n",
      "  timestep     |  17913\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18070, rl-loss: 0.4149230718612671\n",
      "----------------------------------------\n",
      "  timestep     |  18069\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18215, rl-loss: 0.4550187587738037\n",
      "----------------------------------------\n",
      "  timestep     |  18214\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18346, rl-loss: 0.4881893992424011\n",
      "----------------------------------------\n",
      "  timestep     |  18345\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18491, rl-loss: 0.5764609575271606\n",
      "----------------------------------------\n",
      "  timestep     |  18490\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18634, rl-loss: 0.43427231907844543\n",
      "----------------------------------------\n",
      "  timestep     |  18633\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18771, rl-loss: 0.7865228056907654\n",
      "----------------------------------------\n",
      "  timestep     |  18770\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 18926, rl-loss: 0.6185201406478882\n",
      "----------------------------------------\n",
      "  timestep     |  18925\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19084, rl-loss: 0.649194598197937\n",
      "----------------------------------------\n",
      "  timestep     |  19083\n",
      "  reward       |  -0.001\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19230, rl-loss: 0.5723501443862915\n",
      "----------------------------------------\n",
      "  timestep     |  19229\n",
      "  reward       |  -0.003\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19373, rl-loss: 0.4515996277332306\n",
      "----------------------------------------\n",
      "  timestep     |  19372\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19536, rl-loss: 0.5074707865715027\n",
      "----------------------------------------\n",
      "  timestep     |  19535\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19685, rl-loss: 0.475402295589447\n",
      "----------------------------------------\n",
      "  timestep     |  19684\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19831, rl-loss: 0.5920310020446777\n",
      "----------------------------------------\n",
      "  timestep     |  19830\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 19994, rl-loss: 0.5379031300544739\n",
      "----------------------------------------\n",
      "  timestep     |  19993\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 20146, rl-loss: 0.5715847611427307\n",
      "----------------------------------------\n",
      "  timestep     |  20145\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 20295, rl-loss: 0.5306278467178345\n",
      "----------------------------------------\n",
      "  timestep     |  20294\n",
      "  reward       |  -0.136\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 20444, rl-loss: 0.5905233025550842\n",
      "----------------------------------------\n",
      "  timestep     |  20443\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 20590, rl-loss: 0.6353398561477661\n",
      "----------------------------------------\n",
      "  timestep     |  20589\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 20742, rl-loss: 0.6362943649291992\n",
      "----------------------------------------\n",
      "  timestep     |  20741\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 20878, rl-loss: 0.42032283544540405\n",
      "----------------------------------------\n",
      "  timestep     |  20877\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21030, rl-loss: 0.4955753684043884\n",
      "----------------------------------------\n",
      "  timestep     |  21029\n",
      "  reward       |  -0.171\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21172, rl-loss: 0.5868043303489685\n",
      "----------------------------------------\n",
      "  timestep     |  21171\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21315, rl-loss: 0.4489876627922058\n",
      "----------------------------------------\n",
      "  timestep     |  21314\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21469, rl-loss: 0.4692710041999817\n",
      "----------------------------------------\n",
      "  timestep     |  21468\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21627, rl-loss: 0.5020095705986023\n",
      "----------------------------------------\n",
      "  timestep     |  21626\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21766, rl-loss: 0.6881735920906067\n",
      "----------------------------------------\n",
      "  timestep     |  21765\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 21914, rl-loss: 0.5515355467796326\n",
      "----------------------------------------\n",
      "  timestep     |  21913\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22069, rl-loss: 0.47918736934661865\n",
      "----------------------------------------\n",
      "  timestep     |  22068\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22220, rl-loss: 0.4087671935558319\n",
      "----------------------------------------\n",
      "  timestep     |  22219\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22364, rl-loss: 0.45900246500968933\n",
      "----------------------------------------\n",
      "  timestep     |  22363\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22509, rl-loss: 0.3708726763725281\n",
      "----------------------------------------\n",
      "  timestep     |  22508\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22665, rl-loss: 0.5014902949333191\n",
      "----------------------------------------\n",
      "  timestep     |  22664\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22833, rl-loss: 0.6384186148643494\n",
      "----------------------------------------\n",
      "  timestep     |  22832\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 22977, rl-loss: 0.5170583724975586\n",
      "----------------------------------------\n",
      "  timestep     |  22976\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 23119, rl-loss: 0.554032564163208\n",
      "----------------------------------------\n",
      "  timestep     |  23118\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 23275, rl-loss: 0.7086118459701538\n",
      "----------------------------------------\n",
      "  timestep     |  23274\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 23422, rl-loss: 0.6613801121711731\n",
      "----------------------------------------\n",
      "  timestep     |  23421\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 23571, rl-loss: 0.35231125354766846\n",
      "----------------------------------------\n",
      "  timestep     |  23570\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 23728, rl-loss: 0.6641339659690857\n",
      "----------------------------------------\n",
      "  timestep     |  23727\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 23879, rl-loss: 0.5907955169677734\n",
      "----------------------------------------\n",
      "  timestep     |  23878\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24032, rl-loss: 0.4249752163887024\n",
      "----------------------------------------\n",
      "  timestep     |  24031\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24182, rl-loss: 0.5951350927352905\n",
      "----------------------------------------\n",
      "  timestep     |  24181\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24327, rl-loss: 0.4883122444152832\n",
      "----------------------------------------\n",
      "  timestep     |  24326\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24479, rl-loss: 0.2997201383113861\n",
      "----------------------------------------\n",
      "  timestep     |  24478\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24621, rl-loss: 0.41840219497680664\n",
      "----------------------------------------\n",
      "  timestep     |  24620\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24775, rl-loss: 0.6012160181999207\n",
      "----------------------------------------\n",
      "  timestep     |  24774\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 24923, rl-loss: 0.4943293631076813\n",
      "----------------------------------------\n",
      "  timestep     |  24922\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25068, rl-loss: 0.4224150478839874\n",
      "----------------------------------------\n",
      "  timestep     |  25067\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25226, rl-loss: 0.6039560437202454\n",
      "----------------------------------------\n",
      "  timestep     |  25225\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25383, rl-loss: 0.4616984724998474\n",
      "----------------------------------------\n",
      "  timestep     |  25382\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25536, rl-loss: 0.5439910888671875\n",
      "----------------------------------------\n",
      "  timestep     |  25535\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25684, rl-loss: 0.4826643764972687\n",
      "----------------------------------------\n",
      "  timestep     |  25683\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25834, rl-loss: 0.8149554133415222\n",
      "----------------------------------------\n",
      "  timestep     |  25833\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 25968, rl-loss: 0.45834416151046753\n",
      "----------------------------------------\n",
      "  timestep     |  25967\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 26117, rl-loss: 0.4672410488128662\n",
      "----------------------------------------\n",
      "  timestep     |  26116\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 26263, rl-loss: 0.43872106075286865\n",
      "----------------------------------------\n",
      "  timestep     |  26262\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 26412, rl-loss: 0.5635066628456116\n",
      "----------------------------------------\n",
      "  timestep     |  26411\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 26569, rl-loss: 0.5543360114097595\n",
      "----------------------------------------\n",
      "  timestep     |  26568\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 26711, rl-loss: 0.577001690864563\n",
      "----------------------------------------\n",
      "  timestep     |  26710\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 26847, rl-loss: 0.5140913128852844\n",
      "----------------------------------------\n",
      "  timestep     |  26846\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27003, rl-loss: 0.6100689172744751\n",
      "----------------------------------------\n",
      "  timestep     |  27002\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27146, rl-loss: 0.5485942959785461\n",
      "----------------------------------------\n",
      "  timestep     |  27145\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27287, rl-loss: 0.5235259532928467\n",
      "----------------------------------------\n",
      "  timestep     |  27286\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27435, rl-loss: 0.4474603533744812\n",
      "----------------------------------------\n",
      "  timestep     |  27434\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27577, rl-loss: 0.3993490934371948\n",
      "----------------------------------------\n",
      "  timestep     |  27576\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27714, rl-loss: 0.6525253653526306\n",
      "----------------------------------------\n",
      "  timestep     |  27713\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 27858, rl-loss: 0.2485196441411972\n",
      "----------------------------------------\n",
      "  timestep     |  27857\n",
      "  reward       |  0.002\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28010, rl-loss: 0.6471219062805176\n",
      "----------------------------------------\n",
      "  timestep     |  28009\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28158, rl-loss: 0.5843833088874817\n",
      "----------------------------------------\n",
      "  timestep     |  28157\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28302, rl-loss: 0.5457919836044312\n",
      "----------------------------------------\n",
      "  timestep     |  28301\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28449, rl-loss: 0.4295802712440491\n",
      "----------------------------------------\n",
      "  timestep     |  28448\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28596, rl-loss: 0.37867406010627747\n",
      "----------------------------------------\n",
      "  timestep     |  28595\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28757, rl-loss: 0.39552372694015503\n",
      "----------------------------------------\n",
      "  timestep     |  28756\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 28915, rl-loss: 0.41545140743255615\n",
      "----------------------------------------\n",
      "  timestep     |  28914\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29064, rl-loss: 0.45889416337013245\n",
      "----------------------------------------\n",
      "  timestep     |  29063\n",
      "  reward       |  -0.115\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29228, rl-loss: 0.49742498993873596\n",
      "----------------------------------------\n",
      "  timestep     |  29227\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29382, rl-loss: 0.5446479916572571\n",
      "----------------------------------------\n",
      "  timestep     |  29381\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29533, rl-loss: 0.46615177392959595\n",
      "----------------------------------------\n",
      "  timestep     |  29532\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29682, rl-loss: 0.5750656723976135\n",
      "----------------------------------------\n",
      "  timestep     |  29681\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29828, rl-loss: 0.35944122076034546\n",
      "----------------------------------------\n",
      "  timestep     |  29827\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 29969, rl-loss: 0.4426991641521454\n",
      "----------------------------------------\n",
      "  timestep     |  29968\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30114, rl-loss: 0.37403595447540283\n",
      "----------------------------------------\n",
      "  timestep     |  30113\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30257, rl-loss: 0.5273362994194031\n",
      "----------------------------------------\n",
      "  timestep     |  30256\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30399, rl-loss: 0.6031461358070374\n",
      "----------------------------------------\n",
      "  timestep     |  30398\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30535, rl-loss: 0.44222283363342285\n",
      "----------------------------------------\n",
      "  timestep     |  30534\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30676, rl-loss: 0.5245646238327026\n",
      "----------------------------------------\n",
      "  timestep     |  30675\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30828, rl-loss: 0.6225171685218811\n",
      "----------------------------------------\n",
      "  timestep     |  30827\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 30982, rl-loss: 0.6584006547927856\n",
      "----------------------------------------\n",
      "  timestep     |  30981\n",
      "  reward       |  -0.022\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 31126, rl-loss: 0.583685040473938\n",
      "----------------------------------------\n",
      "  timestep     |  31125\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 31272, rl-loss: 0.4785830080509186\n",
      "----------------------------------------\n",
      "  timestep     |  31271\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 31416, rl-loss: 0.6066207885742188\n",
      "----------------------------------------\n",
      "  timestep     |  31415\n",
      "  reward       |  0.017\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 31575, rl-loss: 0.44940879940986633\n",
      "----------------------------------------\n",
      "  timestep     |  31574\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 31740, rl-loss: 0.45687246322631836\n",
      "----------------------------------------\n",
      "  timestep     |  31739\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 31887, rl-loss: 0.5090032815933228\n",
      "----------------------------------------\n",
      "  timestep     |  31886\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32027, rl-loss: 0.5601863265037537\n",
      "----------------------------------------\n",
      "  timestep     |  32026\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32171, rl-loss: 0.5146358609199524\n",
      "----------------------------------------\n",
      "  timestep     |  32170\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32318, rl-loss: 0.46087026596069336\n",
      "----------------------------------------\n",
      "  timestep     |  32317\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32466, rl-loss: 0.31591877341270447\n",
      "----------------------------------------\n",
      "  timestep     |  32465\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32609, rl-loss: 0.5243344902992249\n",
      "----------------------------------------\n",
      "  timestep     |  32608\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32747, rl-loss: 0.5322248339653015\n",
      "----------------------------------------\n",
      "  timestep     |  32746\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 32879, rl-loss: 0.5616793632507324\n",
      "----------------------------------------\n",
      "  timestep     |  32878\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33022, rl-loss: 0.5994067788124084\n",
      "----------------------------------------\n",
      "  timestep     |  33021\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33171, rl-loss: 0.564041018486023\n",
      "----------------------------------------\n",
      "  timestep     |  33170\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33324, rl-loss: 0.5540644526481628\n",
      "----------------------------------------\n",
      "  timestep     |  33323\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33468, rl-loss: 0.6261039972305298\n",
      "----------------------------------------\n",
      "  timestep     |  33467\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33610, rl-loss: 0.6551533341407776\n",
      "----------------------------------------\n",
      "  timestep     |  33609\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33764, rl-loss: 0.4461754560470581\n",
      "----------------------------------------\n",
      "  timestep     |  33763\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 33917, rl-loss: 0.4647895097732544\n",
      "----------------------------------------\n",
      "  timestep     |  33916\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34082, rl-loss: 0.4543437063694\n",
      "----------------------------------------\n",
      "  timestep     |  34081\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34231, rl-loss: 0.4366825819015503\n",
      "----------------------------------------\n",
      "  timestep     |  34230\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34374, rl-loss: 0.5085868835449219\n",
      "----------------------------------------\n",
      "  timestep     |  34373\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34521, rl-loss: 0.40886810421943665\n",
      "----------------------------------------\n",
      "  timestep     |  34520\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34679, rl-loss: 0.35895588994026184\n",
      "----------------------------------------\n",
      "  timestep     |  34678\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34826, rl-loss: 0.4318532943725586\n",
      "----------------------------------------\n",
      "  timestep     |  34825\n",
      "  reward       |  -0.013\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 34970, rl-loss: 0.46228593587875366\n",
      "----------------------------------------\n",
      "  timestep     |  34969\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35112, rl-loss: 0.665436327457428\n",
      "----------------------------------------\n",
      "  timestep     |  35111\n",
      "  reward       |  -0.006\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35257, rl-loss: 0.4350872337818146\n",
      "----------------------------------------\n",
      "  timestep     |  35256\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35404, rl-loss: 0.5498501062393188\n",
      "----------------------------------------\n",
      "  timestep     |  35403\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35543, rl-loss: 0.5262869596481323\n",
      "----------------------------------------\n",
      "  timestep     |  35542\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35694, rl-loss: 0.639665961265564\n",
      "----------------------------------------\n",
      "  timestep     |  35693\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35847, rl-loss: 0.6348889470100403\n",
      "----------------------------------------\n",
      "  timestep     |  35846\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 35994, rl-loss: 0.6170929670333862\n",
      "----------------------------------------\n",
      "  timestep     |  35993\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36141, rl-loss: 0.4910127520561218\n",
      "----------------------------------------\n",
      "  timestep     |  36140\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36293, rl-loss: 0.47509825229644775\n",
      "----------------------------------------\n",
      "  timestep     |  36292\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36431, rl-loss: 0.41790223121643066\n",
      "----------------------------------------\n",
      "  timestep     |  36430\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36560, rl-loss: 0.4122822880744934\n",
      "----------------------------------------\n",
      "  timestep     |  36559\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36684, rl-loss: 0.6367794871330261\n",
      "----------------------------------------\n",
      "  timestep     |  36683\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36820, rl-loss: 0.6518909335136414\n",
      "----------------------------------------\n",
      "  timestep     |  36819\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 36948, rl-loss: 0.5965167284011841\n",
      "----------------------------------------\n",
      "  timestep     |  36947\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37083, rl-loss: 0.6170517206192017\n",
      "----------------------------------------\n",
      "  timestep     |  37082\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37211, rl-loss: 0.6824361681938171\n",
      "----------------------------------------\n",
      "  timestep     |  37210\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37342, rl-loss: 0.5597980618476868\n",
      "----------------------------------------\n",
      "  timestep     |  37341\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37493, rl-loss: 0.7585329413414001\n",
      "----------------------------------------\n",
      "  timestep     |  37492\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37651, rl-loss: 0.6825758814811707\n",
      "----------------------------------------\n",
      "  timestep     |  37650\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37798, rl-loss: 0.48377615213394165\n",
      "----------------------------------------\n",
      "  timestep     |  37797\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 37937, rl-loss: 0.43709349632263184\n",
      "----------------------------------------\n",
      "  timestep     |  37936\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38076, rl-loss: 0.4648357629776001\n",
      "----------------------------------------\n",
      "  timestep     |  38075\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38226, rl-loss: 0.542760968208313\n",
      "----------------------------------------\n",
      "  timestep     |  38225\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38377, rl-loss: 0.5303152203559875\n",
      "----------------------------------------\n",
      "  timestep     |  38376\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38522, rl-loss: 0.5192283987998962\n",
      "----------------------------------------\n",
      "  timestep     |  38521\n",
      "  reward       |  -0.119\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38673, rl-loss: 0.43123430013656616\n",
      "----------------------------------------\n",
      "  timestep     |  38672\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38827, rl-loss: 0.38187700510025024\n",
      "----------------------------------------\n",
      "  timestep     |  38826\n",
      "  reward       |  -0.007\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 38984, rl-loss: 0.44548144936561584\n",
      "----------------------------------------\n",
      "  timestep     |  38983\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 39142, rl-loss: 0.4940868616104126\n",
      "----------------------------------------\n",
      "  timestep     |  39141\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 39292, rl-loss: 0.3954562246799469\n",
      "----------------------------------------\n",
      "  timestep     |  39291\n",
      "  reward       |  -0.011\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 39432, rl-loss: 0.523812472820282\n",
      "----------------------------------------\n",
      "  timestep     |  39431\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 39594, rl-loss: 0.3984531760215759\n",
      "----------------------------------------\n",
      "  timestep     |  39593\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 39742, rl-loss: 0.575664758682251\n",
      "----------------------------------------\n",
      "  timestep     |  39741\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 39887, rl-loss: 0.5219530463218689\n",
      "----------------------------------------\n",
      "  timestep     |  39886\n",
      "  reward       |  -0.123\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40030, rl-loss: 0.5367498397827148\n",
      "----------------------------------------\n",
      "  timestep     |  40029\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40161, rl-loss: 0.556981086730957\n",
      "----------------------------------------\n",
      "  timestep     |  40160\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40298, rl-loss: 0.4888650178909302\n",
      "----------------------------------------\n",
      "  timestep     |  40297\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40447, rl-loss: 0.5832982659339905\n",
      "----------------------------------------\n",
      "  timestep     |  40446\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40584, rl-loss: 0.751850962638855\n",
      "----------------------------------------\n",
      "  timestep     |  40583\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40742, rl-loss: 0.7361831068992615\n",
      "----------------------------------------\n",
      "  timestep     |  40741\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 40900, rl-loss: 0.4885410964488983\n",
      "----------------------------------------\n",
      "  timestep     |  40899\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41057, rl-loss: 0.7416701912879944\n",
      "----------------------------------------\n",
      "  timestep     |  41056\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41204, rl-loss: 0.4217771291732788\n",
      "----------------------------------------\n",
      "  timestep     |  41203\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41352, rl-loss: 0.5236311554908752\n",
      "----------------------------------------\n",
      "  timestep     |  41351\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41509, rl-loss: 0.47902166843414307\n",
      "----------------------------------------\n",
      "  timestep     |  41508\n",
      "  reward       |  -0.119\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41650, rl-loss: 0.35486385226249695\n",
      "----------------------------------------\n",
      "  timestep     |  41649\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41788, rl-loss: 0.5763211846351624\n",
      "----------------------------------------\n",
      "  timestep     |  41787\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 41932, rl-loss: 0.5352986454963684\n",
      "----------------------------------------\n",
      "  timestep     |  41931\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42080, rl-loss: 0.3901926875114441\n",
      "----------------------------------------\n",
      "  timestep     |  42079\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42228, rl-loss: 0.5545515418052673\n",
      "----------------------------------------\n",
      "  timestep     |  42227\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42388, rl-loss: 0.4392494261264801\n",
      "----------------------------------------\n",
      "  timestep     |  42387\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42523, rl-loss: 0.5819088220596313\n",
      "----------------------------------------\n",
      "  timestep     |  42522\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42677, rl-loss: 0.5431650876998901\n",
      "----------------------------------------\n",
      "  timestep     |  42676\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42820, rl-loss: 0.6151214838027954\n",
      "----------------------------------------\n",
      "  timestep     |  42819\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 42974, rl-loss: 0.4506540894508362\n",
      "----------------------------------------\n",
      "  timestep     |  42973\n",
      "  reward       |  -0.119\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 43125, rl-loss: 0.34373044967651367\n",
      "----------------------------------------\n",
      "  timestep     |  43124\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 43267, rl-loss: 0.6107439994812012\n",
      "----------------------------------------\n",
      "  timestep     |  43266\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 43415, rl-loss: 0.614042341709137\n",
      "----------------------------------------\n",
      "  timestep     |  43414\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 43555, rl-loss: 0.48903051018714905\n",
      "----------------------------------------\n",
      "  timestep     |  43554\n",
      "  reward       |  -0.019\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 43703, rl-loss: 0.4753677248954773\n",
      "----------------------------------------\n",
      "  timestep     |  43702\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 43857, rl-loss: 0.7811568379402161\n",
      "----------------------------------------\n",
      "  timestep     |  43856\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44005, rl-loss: 0.4083769619464874\n",
      "----------------------------------------\n",
      "  timestep     |  44004\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44149, rl-loss: 0.7027857303619385\n",
      "----------------------------------------\n",
      "  timestep     |  44148\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44299, rl-loss: 0.39301612973213196\n",
      "----------------------------------------\n",
      "  timestep     |  44298\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44451, rl-loss: 0.40980905294418335\n",
      "----------------------------------------\n",
      "  timestep     |  44450\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44589, rl-loss: 0.3460807800292969\n",
      "----------------------------------------\n",
      "  timestep     |  44588\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44742, rl-loss: 0.605459451675415\n",
      "----------------------------------------\n",
      "  timestep     |  44741\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 44888, rl-loss: 0.40126094222068787\n",
      "----------------------------------------\n",
      "  timestep     |  44887\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45039, rl-loss: 0.45557647943496704\n",
      "----------------------------------------\n",
      "  timestep     |  45038\n",
      "  reward       |  -0.142\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45187, rl-loss: 0.41517770290374756\n",
      "----------------------------------------\n",
      "  timestep     |  45186\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45351, rl-loss: 0.5439993143081665\n",
      "----------------------------------------\n",
      "  timestep     |  45350\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45501, rl-loss: 0.3743574023246765\n",
      "----------------------------------------\n",
      "  timestep     |  45500\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45646, rl-loss: 0.5398366451263428\n",
      "----------------------------------------\n",
      "  timestep     |  45645\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45790, rl-loss: 0.5096595883369446\n",
      "----------------------------------------\n",
      "  timestep     |  45789\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 45949, rl-loss: 0.6148315072059631\n",
      "----------------------------------------\n",
      "  timestep     |  45948\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46100, rl-loss: 0.5953647494316101\n",
      "----------------------------------------\n",
      "  timestep     |  46099\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46256, rl-loss: 0.5559676885604858\n",
      "----------------------------------------\n",
      "  timestep     |  46255\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46398, rl-loss: 0.43271636962890625\n",
      "----------------------------------------\n",
      "  timestep     |  46397\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46550, rl-loss: 0.5653347373008728\n",
      "----------------------------------------\n",
      "  timestep     |  46549\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46699, rl-loss: 0.4032614231109619\n",
      "----------------------------------------\n",
      "  timestep     |  46698\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46847, rl-loss: 0.5535768866539001\n",
      "----------------------------------------\n",
      "  timestep     |  46846\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 46992, rl-loss: 0.7486191987991333\n",
      "----------------------------------------\n",
      "  timestep     |  46991\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 47141, rl-loss: 0.3678828179836273\n",
      "----------------------------------------\n",
      "  timestep     |  47140\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 47285, rl-loss: 0.3876289129257202\n",
      "----------------------------------------\n",
      "  timestep     |  47284\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 47425, rl-loss: 0.5598148107528687\n",
      "----------------------------------------\n",
      "  timestep     |  47424\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 47581, rl-loss: 0.5909979343414307\n",
      "----------------------------------------\n",
      "  timestep     |  47580\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 47713, rl-loss: 0.52469801902771\n",
      "----------------------------------------\n",
      "  timestep     |  47712\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 47861, rl-loss: 0.6073287725448608\n",
      "----------------------------------------\n",
      "  timestep     |  47860\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48006, rl-loss: 0.49523553252220154\n",
      "----------------------------------------\n",
      "  timestep     |  48005\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48150, rl-loss: 0.40990352630615234\n",
      "----------------------------------------\n",
      "  timestep     |  48149\n",
      "  reward       |  0.009\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48294, rl-loss: 0.6324803829193115\n",
      "----------------------------------------\n",
      "  timestep     |  48293\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48433, rl-loss: 0.6485841274261475\n",
      "----------------------------------------\n",
      "  timestep     |  48432\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48573, rl-loss: 0.5173476338386536\n",
      "----------------------------------------\n",
      "  timestep     |  48572\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48699, rl-loss: 0.3627268075942993\n",
      "----------------------------------------\n",
      "  timestep     |  48698\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48847, rl-loss: 0.4085519015789032\n",
      "----------------------------------------\n",
      "  timestep     |  48846\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 48996, rl-loss: 0.59243243932724\n",
      "----------------------------------------\n",
      "  timestep     |  48995\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 49147, rl-loss: 0.6527702212333679\n",
      "----------------------------------------\n",
      "  timestep     |  49146\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 49308, rl-loss: 0.515510082244873\n",
      "----------------------------------------\n",
      "  timestep     |  49307\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 49471, rl-loss: 0.3000043034553528\n",
      "----------------------------------------\n",
      "  timestep     |  49470\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 49619, rl-loss: 0.5701225399971008\n",
      "----------------------------------------\n",
      "  timestep     |  49618\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 49790, rl-loss: 0.5314479470252991\n",
      "----------------------------------------\n",
      "  timestep     |  49789\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 49924, rl-loss: 0.23884975910186768\n",
      "----------------------------------------\n",
      "  timestep     |  49923\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50072, rl-loss: 0.6545293927192688\n",
      "----------------------------------------\n",
      "  timestep     |  50071\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50210, rl-loss: 0.4790668487548828\n",
      "----------------------------------------\n",
      "  timestep     |  50209\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50343, rl-loss: 0.52022784948349\n",
      "----------------------------------------\n",
      "  timestep     |  50342\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50483, rl-loss: 0.5346021056175232\n",
      "----------------------------------------\n",
      "  timestep     |  50482\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50625, rl-loss: 0.4849695563316345\n",
      "----------------------------------------\n",
      "  timestep     |  50624\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50775, rl-loss: 0.44235289096832275\n",
      "----------------------------------------\n",
      "  timestep     |  50774\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 50935, rl-loss: 0.4787288308143616\n",
      "----------------------------------------\n",
      "  timestep     |  50934\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51074, rl-loss: 0.41273605823516846\n",
      "----------------------------------------\n",
      "  timestep     |  51073\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51229, rl-loss: 0.4522415101528168\n",
      "----------------------------------------\n",
      "  timestep     |  51228\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51384, rl-loss: 0.5358511805534363\n",
      "----------------------------------------\n",
      "  timestep     |  51383\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51538, rl-loss: 0.40942177176475525\n",
      "----------------------------------------\n",
      "  timestep     |  51537\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51694, rl-loss: 0.6708484888076782\n",
      "----------------------------------------\n",
      "  timestep     |  51693\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51843, rl-loss: 0.6921992897987366\n",
      "----------------------------------------\n",
      "  timestep     |  51842\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 51993, rl-loss: 0.5777250528335571\n",
      "----------------------------------------\n",
      "  timestep     |  51992\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 52155, rl-loss: 0.5465615391731262\n",
      "----------------------------------------\n",
      "  timestep     |  52154\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 52306, rl-loss: 0.3945254981517792\n",
      "----------------------------------------\n",
      "  timestep     |  52305\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 52475, rl-loss: 0.6118890047073364\n",
      "----------------------------------------\n",
      "  timestep     |  52474\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 52638, rl-loss: 0.47224777936935425\n",
      "----------------------------------------\n",
      "  timestep     |  52637\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 52789, rl-loss: 0.47195520997047424\n",
      "----------------------------------------\n",
      "  timestep     |  52788\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 52931, rl-loss: 0.5920423865318298\n",
      "----------------------------------------\n",
      "  timestep     |  52930\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53074, rl-loss: 0.8533298969268799\n",
      "----------------------------------------\n",
      "  timestep     |  53073\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53221, rl-loss: 0.5909115076065063\n",
      "----------------------------------------\n",
      "  timestep     |  53220\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53367, rl-loss: 0.34946003556251526\n",
      "----------------------------------------\n",
      "  timestep     |  53366\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53520, rl-loss: 0.4005205035209656\n",
      "----------------------------------------\n",
      "  timestep     |  53519\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53659, rl-loss: 0.4512210786342621\n",
      "----------------------------------------\n",
      "  timestep     |  53658\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53792, rl-loss: 0.3820876479148865\n",
      "----------------------------------------\n",
      "  timestep     |  53791\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 53920, rl-loss: 0.685710608959198\n",
      "----------------------------------------\n",
      "  timestep     |  53919\n",
      "  reward       |  -0.132\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54057, rl-loss: 0.478851318359375\n",
      "----------------------------------------\n",
      "  timestep     |  54056\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54190, rl-loss: 0.4036083221435547\n",
      "----------------------------------------\n",
      "  timestep     |  54189\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54335, rl-loss: 0.5957670211791992\n",
      "----------------------------------------\n",
      "  timestep     |  54334\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54467, rl-loss: 0.6450009942054749\n",
      "----------------------------------------\n",
      "  timestep     |  54466\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54599, rl-loss: 0.6743811964988708\n",
      "----------------------------------------\n",
      "  timestep     |  54598\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54747, rl-loss: 0.5931968092918396\n",
      "----------------------------------------\n",
      "  timestep     |  54746\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 54884, rl-loss: 0.4236544370651245\n",
      "----------------------------------------\n",
      "  timestep     |  54883\n",
      "  reward       |  0.005\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55047, rl-loss: 0.5358308553695679\n",
      "----------------------------------------\n",
      "  timestep     |  55046\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55201, rl-loss: 0.3863264322280884\n",
      "----------------------------------------\n",
      "  timestep     |  55200\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55349, rl-loss: 0.48214808106422424\n",
      "----------------------------------------\n",
      "  timestep     |  55348\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55498, rl-loss: 0.464224636554718\n",
      "----------------------------------------\n",
      "  timestep     |  55497\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55657, rl-loss: 0.48446619510650635\n",
      "----------------------------------------\n",
      "  timestep     |  55656\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55813, rl-loss: 0.3368563652038574\n",
      "----------------------------------------\n",
      "  timestep     |  55812\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 55964, rl-loss: 0.33684322237968445\n",
      "----------------------------------------\n",
      "  timestep     |  55963\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 56120, rl-loss: 0.5200303792953491\n",
      "----------------------------------------\n",
      "  timestep     |  56119\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 56270, rl-loss: 0.7048747539520264\n",
      "----------------------------------------\n",
      "  timestep     |  56269\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 56425, rl-loss: 0.5427020192146301\n",
      "----------------------------------------\n",
      "  timestep     |  56424\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 56564, rl-loss: 0.45200222730636597\n",
      "----------------------------------------\n",
      "  timestep     |  56563\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 56717, rl-loss: 0.5171489715576172\n",
      "----------------------------------------\n",
      "  timestep     |  56716\n",
      "  reward       |  -0.009\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 56872, rl-loss: 0.4065372943878174\n",
      "----------------------------------------\n",
      "  timestep     |  56871\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57022, rl-loss: 0.3782814145088196\n",
      "----------------------------------------\n",
      "  timestep     |  57021\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57184, rl-loss: 0.7443283200263977\n",
      "----------------------------------------\n",
      "  timestep     |  57183\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57340, rl-loss: 0.3743000626564026\n",
      "----------------------------------------\n",
      "  timestep     |  57339\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57488, rl-loss: 0.32980984449386597\n",
      "----------------------------------------\n",
      "  timestep     |  57487\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57644, rl-loss: 0.4206394851207733\n",
      "----------------------------------------\n",
      "  timestep     |  57643\n",
      "  reward       |  -0.152\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57793, rl-loss: 0.338287889957428\n",
      "----------------------------------------\n",
      "  timestep     |  57792\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 57943, rl-loss: 0.6234064698219299\n",
      "----------------------------------------\n",
      "  timestep     |  57942\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 58101, rl-loss: 0.37851682305336\n",
      "----------------------------------------\n",
      "  timestep     |  58100\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 58259, rl-loss: 0.5984906554222107\n",
      "----------------------------------------\n",
      "  timestep     |  58258\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 58417, rl-loss: 0.6284214854240417\n",
      "----------------------------------------\n",
      "  timestep     |  58416\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 58574, rl-loss: 0.35644418001174927\n",
      "----------------------------------------\n",
      "  timestep     |  58573\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 58733, rl-loss: 0.4673095941543579\n",
      "----------------------------------------\n",
      "  timestep     |  58732\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 58883, rl-loss: 0.5260711908340454\n",
      "----------------------------------------\n",
      "  timestep     |  58882\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59043, rl-loss: 0.5551997423171997\n",
      "----------------------------------------\n",
      "  timestep     |  59042\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59202, rl-loss: 0.36272135376930237\n",
      "----------------------------------------\n",
      "  timestep     |  59201\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59342, rl-loss: 0.541163980960846\n",
      "----------------------------------------\n",
      "  timestep     |  59341\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59489, rl-loss: 0.6087619066238403\n",
      "----------------------------------------\n",
      "  timestep     |  59488\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59661, rl-loss: 0.5223203301429749\n",
      "----------------------------------------\n",
      "  timestep     |  59660\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59799, rl-loss: 0.379527747631073\n",
      "----------------------------------------\n",
      "  timestep     |  59798\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 59965, rl-loss: 0.6749970316886902\n",
      "----------------------------------------\n",
      "  timestep     |  59964\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 60120, rl-loss: 0.5902734398841858\n",
      "----------------------------------------\n",
      "  timestep     |  60119\n",
      "  reward       |  0.025\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 60277, rl-loss: 0.6785730123519897\n",
      "----------------------------------------\n",
      "  timestep     |  60276\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 60421, rl-loss: 0.44288110733032227\n",
      "----------------------------------------\n",
      "  timestep     |  60420\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 60579, rl-loss: 0.5493338108062744\n",
      "----------------------------------------\n",
      "  timestep     |  60578\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 60735, rl-loss: 0.3261834979057312\n",
      "----------------------------------------\n",
      "  timestep     |  60734\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 60888, rl-loss: 0.643661618232727\n",
      "----------------------------------------\n",
      "  timestep     |  60887\n",
      "  reward       |  -0.022\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61047, rl-loss: 0.39937111735343933\n",
      "----------------------------------------\n",
      "  timestep     |  61046\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61204, rl-loss: 0.434663325548172\n",
      "----------------------------------------\n",
      "  timestep     |  61203\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61372, rl-loss: 0.3616645634174347\n",
      "----------------------------------------\n",
      "  timestep     |  61371\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61527, rl-loss: 0.4611022472381592\n",
      "----------------------------------------\n",
      "  timestep     |  61526\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61686, rl-loss: 0.45265451073646545\n",
      "----------------------------------------\n",
      "  timestep     |  61685\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61835, rl-loss: 0.5537787675857544\n",
      "----------------------------------------\n",
      "  timestep     |  61834\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 61990, rl-loss: 0.5294139385223389\n",
      "----------------------------------------\n",
      "  timestep     |  61989\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 62142, rl-loss: 0.6057685017585754\n",
      "----------------------------------------\n",
      "  timestep     |  62141\n",
      "  reward       |  -0.129\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 62292, rl-loss: 0.4681956171989441\n",
      "----------------------------------------\n",
      "  timestep     |  62291\n",
      "  reward       |  -0.126\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 62453, rl-loss: 0.5267345309257507\n",
      "----------------------------------------\n",
      "  timestep     |  62452\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 62594, rl-loss: 0.54115229845047\n",
      "----------------------------------------\n",
      "  timestep     |  62593\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 62746, rl-loss: 0.5061684250831604\n",
      "----------------------------------------\n",
      "  timestep     |  62745\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 62902, rl-loss: 0.5289700031280518\n",
      "----------------------------------------\n",
      "  timestep     |  62901\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63053, rl-loss: 0.3849206566810608\n",
      "----------------------------------------\n",
      "  timestep     |  63052\n",
      "  reward       |  -0.007\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63203, rl-loss: 0.4419540464878082\n",
      "----------------------------------------\n",
      "  timestep     |  63202\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63357, rl-loss: 0.5204718112945557\n",
      "----------------------------------------\n",
      "  timestep     |  63356\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63495, rl-loss: 0.6461143493652344\n",
      "----------------------------------------\n",
      "  timestep     |  63494\n",
      "  reward       |  0.01\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63646, rl-loss: 0.6140186190605164\n",
      "----------------------------------------\n",
      "  timestep     |  63645\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63783, rl-loss: 0.5973518490791321\n",
      "----------------------------------------\n",
      "  timestep     |  63782\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 63932, rl-loss: 0.5254780650138855\n",
      "----------------------------------------\n",
      "  timestep     |  63931\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64068, rl-loss: 0.5012267231941223\n",
      "----------------------------------------\n",
      "  timestep     |  64067\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64190, rl-loss: 0.5425131916999817\n",
      "----------------------------------------\n",
      "  timestep     |  64189\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64333, rl-loss: 0.45476770401000977\n",
      "----------------------------------------\n",
      "  timestep     |  64332\n",
      "  reward       |  -0.011\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64488, rl-loss: 0.561674177646637\n",
      "----------------------------------------\n",
      "  timestep     |  64487\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64636, rl-loss: 0.5094795823097229\n",
      "----------------------------------------\n",
      "  timestep     |  64635\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64778, rl-loss: 0.5675075054168701\n",
      "----------------------------------------\n",
      "  timestep     |  64777\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 64924, rl-loss: 0.5941020846366882\n",
      "----------------------------------------\n",
      "  timestep     |  64923\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65079, rl-loss: 0.5179564952850342\n",
      "----------------------------------------\n",
      "  timestep     |  65078\n",
      "  reward       |  0.0\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65231, rl-loss: 0.5785645246505737\n",
      "----------------------------------------\n",
      "  timestep     |  65230\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65371, rl-loss: 0.39460790157318115\n",
      "----------------------------------------\n",
      "  timestep     |  65370\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65526, rl-loss: 0.5386428236961365\n",
      "----------------------------------------\n",
      "  timestep     |  65525\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65672, rl-loss: 0.5253872871398926\n",
      "----------------------------------------\n",
      "  timestep     |  65671\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65821, rl-loss: 0.24335958063602448\n",
      "----------------------------------------\n",
      "  timestep     |  65820\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 65963, rl-loss: 0.5639389157295227\n",
      "----------------------------------------\n",
      "  timestep     |  65962\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66113, rl-loss: 0.5542529821395874\n",
      "----------------------------------------\n",
      "  timestep     |  66112\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66252, rl-loss: 0.4740937650203705\n",
      "----------------------------------------\n",
      "  timestep     |  66251\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66390, rl-loss: 0.40021422505378723\n",
      "----------------------------------------\n",
      "  timestep     |  66389\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66534, rl-loss: 0.28605711460113525\n",
      "----------------------------------------\n",
      "  timestep     |  66533\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66672, rl-loss: 0.3810184597969055\n",
      "----------------------------------------\n",
      "  timestep     |  66671\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66820, rl-loss: 0.4144192934036255\n",
      "----------------------------------------\n",
      "  timestep     |  66819\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 66960, rl-loss: 0.49003779888153076\n",
      "----------------------------------------\n",
      "  timestep     |  66959\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67109, rl-loss: 0.6360589265823364\n",
      "----------------------------------------\n",
      "  timestep     |  67108\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67245, rl-loss: 0.4220913350582123\n",
      "----------------------------------------\n",
      "  timestep     |  67244\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67384, rl-loss: 0.5674455761909485\n",
      "----------------------------------------\n",
      "  timestep     |  67383\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67527, rl-loss: 0.4962450861930847\n",
      "----------------------------------------\n",
      "  timestep     |  67526\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67671, rl-loss: 0.5960819125175476\n",
      "----------------------------------------\n",
      "  timestep     |  67670\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67822, rl-loss: 0.5071805715560913\n",
      "----------------------------------------\n",
      "  timestep     |  67821\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 67974, rl-loss: 0.5544712543487549\n",
      "----------------------------------------\n",
      "  timestep     |  67973\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 68120, rl-loss: 0.3536764681339264\n",
      "----------------------------------------\n",
      "  timestep     |  68119\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 68259, rl-loss: 0.44385382533073425\n",
      "----------------------------------------\n",
      "  timestep     |  68258\n",
      "  reward       |  -0.155\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 68403, rl-loss: 0.47665682435035706\n",
      "----------------------------------------\n",
      "  timestep     |  68402\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 68553, rl-loss: 0.6248334646224976\n",
      "----------------------------------------\n",
      "  timestep     |  68552\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 68718, rl-loss: 0.4786313772201538\n",
      "----------------------------------------\n",
      "  timestep     |  68717\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 68866, rl-loss: 0.5287685394287109\n",
      "----------------------------------------\n",
      "  timestep     |  68865\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69013, rl-loss: 0.5639146566390991\n",
      "----------------------------------------\n",
      "  timestep     |  69012\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69160, rl-loss: 0.5279695987701416\n",
      "----------------------------------------\n",
      "  timestep     |  69159\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69306, rl-loss: 0.4035283029079437\n",
      "----------------------------------------\n",
      "  timestep     |  69305\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69448, rl-loss: 0.573598325252533\n",
      "----------------------------------------\n",
      "  timestep     |  69447\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69590, rl-loss: 0.6045618057250977\n",
      "----------------------------------------\n",
      "  timestep     |  69589\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69744, rl-loss: 0.384838342666626\n",
      "----------------------------------------\n",
      "  timestep     |  69743\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 69892, rl-loss: 0.4621482491493225\n",
      "----------------------------------------\n",
      "  timestep     |  69891\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70045, rl-loss: 0.48961150646209717\n",
      "----------------------------------------\n",
      "  timestep     |  70044\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70191, rl-loss: 0.43910837173461914\n",
      "----------------------------------------\n",
      "  timestep     |  70190\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70343, rl-loss: 0.5885558724403381\n",
      "----------------------------------------\n",
      "  timestep     |  70342\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70487, rl-loss: 0.5708622336387634\n",
      "----------------------------------------\n",
      "  timestep     |  70486\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70640, rl-loss: 0.4172195792198181\n",
      "----------------------------------------\n",
      "  timestep     |  70639\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70793, rl-loss: 0.3509008288383484\n",
      "----------------------------------------\n",
      "  timestep     |  70792\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 70927, rl-loss: 0.5691204071044922\n",
      "----------------------------------------\n",
      "  timestep     |  70926\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71071, rl-loss: 0.369022935628891\n",
      "----------------------------------------\n",
      "  timestep     |  71070\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71224, rl-loss: 0.4254882335662842\n",
      "----------------------------------------\n",
      "  timestep     |  71223\n",
      "  reward       |  -0.143\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71364, rl-loss: 0.535222053527832\n",
      "----------------------------------------\n",
      "  timestep     |  71363\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71515, rl-loss: 0.6744824647903442\n",
      "----------------------------------------\n",
      "  timestep     |  71514\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71665, rl-loss: 0.4592612087726593\n",
      "----------------------------------------\n",
      "  timestep     |  71664\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71816, rl-loss: 0.4210691452026367\n",
      "----------------------------------------\n",
      "  timestep     |  71815\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 71973, rl-loss: 0.4961394667625427\n",
      "----------------------------------------\n",
      "  timestep     |  71972\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72124, rl-loss: 0.5693148374557495\n",
      "----------------------------------------\n",
      "  timestep     |  72123\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72274, rl-loss: 0.532340407371521\n",
      "----------------------------------------\n",
      "  timestep     |  72273\n",
      "  reward       |  -0.013\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72423, rl-loss: 0.5106731653213501\n",
      "----------------------------------------\n",
      "  timestep     |  72422\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72562, rl-loss: 0.4871315062046051\n",
      "----------------------------------------\n",
      "  timestep     |  72561\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72710, rl-loss: 0.49819108843803406\n",
      "----------------------------------------\n",
      "  timestep     |  72709\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72838, rl-loss: 0.7905973196029663\n",
      "----------------------------------------\n",
      "  timestep     |  72837\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 72977, rl-loss: 0.5478985905647278\n",
      "----------------------------------------\n",
      "  timestep     |  72976\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73122, rl-loss: 0.6027542352676392\n",
      "----------------------------------------\n",
      "  timestep     |  73121\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73266, rl-loss: 0.6546504497528076\n",
      "----------------------------------------\n",
      "  timestep     |  73265\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73408, rl-loss: 0.43560564517974854\n",
      "----------------------------------------\n",
      "  timestep     |  73407\n",
      "  reward       |  0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73561, rl-loss: 0.495055615901947\n",
      "----------------------------------------\n",
      "  timestep     |  73560\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73712, rl-loss: 0.5572284460067749\n",
      "----------------------------------------\n",
      "  timestep     |  73711\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73857, rl-loss: 0.5320375561714172\n",
      "----------------------------------------\n",
      "  timestep     |  73856\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 73996, rl-loss: 0.4732745587825775\n",
      "----------------------------------------\n",
      "  timestep     |  73995\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 74154, rl-loss: 0.35082483291625977\n",
      "----------------------------------------\n",
      "  timestep     |  74153\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 74296, rl-loss: 0.5790404081344604\n",
      "----------------------------------------\n",
      "  timestep     |  74295\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 74441, rl-loss: 0.6452016234397888\n",
      "----------------------------------------\n",
      "  timestep     |  74440\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 74588, rl-loss: 0.4497477114200592\n",
      "----------------------------------------\n",
      "  timestep     |  74587\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 74726, rl-loss: 0.7476140856742859\n",
      "----------------------------------------\n",
      "  timestep     |  74725\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 74880, rl-loss: 0.6176267862319946\n",
      "----------------------------------------\n",
      "  timestep     |  74879\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75031, rl-loss: 0.7861939072608948\n",
      "----------------------------------------\n",
      "  timestep     |  75030\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75178, rl-loss: 0.40141284465789795\n",
      "----------------------------------------\n",
      "  timestep     |  75177\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75320, rl-loss: 0.47851040959358215\n",
      "----------------------------------------\n",
      "  timestep     |  75319\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75461, rl-loss: 0.6003554463386536\n",
      "----------------------------------------\n",
      "  timestep     |  75460\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75605, rl-loss: 0.5810858011245728\n",
      "----------------------------------------\n",
      "  timestep     |  75604\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75746, rl-loss: 0.7069599628448486\n",
      "----------------------------------------\n",
      "  timestep     |  75745\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 75898, rl-loss: 0.6153830885887146\n",
      "----------------------------------------\n",
      "  timestep     |  75897\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76036, rl-loss: 0.5261286497116089\n",
      "----------------------------------------\n",
      "  timestep     |  76035\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76188, rl-loss: 0.42332595586776733\n",
      "----------------------------------------\n",
      "  timestep     |  76187\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76347, rl-loss: 0.6637117862701416\n",
      "----------------------------------------\n",
      "  timestep     |  76346\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76492, rl-loss: 0.6061875224113464\n",
      "----------------------------------------\n",
      "  timestep     |  76491\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76649, rl-loss: 0.4744167923927307\n",
      "----------------------------------------\n",
      "  timestep     |  76648\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76795, rl-loss: 0.6318567395210266\n",
      "----------------------------------------\n",
      "  timestep     |  76794\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 76956, rl-loss: 0.6135190725326538\n",
      "----------------------------------------\n",
      "  timestep     |  76955\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 77100, rl-loss: 0.4576622545719147\n",
      "----------------------------------------\n",
      "  timestep     |  77099\n",
      "  reward       |  -0.001\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 77257, rl-loss: 0.47809305787086487\n",
      "----------------------------------------\n",
      "  timestep     |  77256\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 77415, rl-loss: 0.6234588623046875\n",
      "----------------------------------------\n",
      "  timestep     |  77414\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 77562, rl-loss: 0.32469111680984497\n",
      "----------------------------------------\n",
      "  timestep     |  77561\n",
      "  reward       |  -0.019\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 77711, rl-loss: 0.576999306678772\n",
      "----------------------------------------\n",
      "  timestep     |  77710\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 77858, rl-loss: 0.6356080770492554\n",
      "----------------------------------------\n",
      "  timestep     |  77857\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78000, rl-loss: 0.5203275680541992\n",
      "----------------------------------------\n",
      "  timestep     |  77999\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78145, rl-loss: 0.42164331674575806\n",
      "----------------------------------------\n",
      "  timestep     |  78144\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78293, rl-loss: 0.40872329473495483\n",
      "----------------------------------------\n",
      "  timestep     |  78292\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78440, rl-loss: 0.6003277897834778\n",
      "----------------------------------------\n",
      "  timestep     |  78439\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78585, rl-loss: 0.5715616941452026\n",
      "----------------------------------------\n",
      "  timestep     |  78584\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78727, rl-loss: 0.5301638245582581\n",
      "----------------------------------------\n",
      "  timestep     |  78726\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 78868, rl-loss: 0.7784242630004883\n",
      "----------------------------------------\n",
      "  timestep     |  78867\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79011, rl-loss: 0.430947482585907\n",
      "----------------------------------------\n",
      "  timestep     |  79010\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79164, rl-loss: 0.5893396735191345\n",
      "----------------------------------------\n",
      "  timestep     |  79163\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79319, rl-loss: 0.48732951283454895\n",
      "----------------------------------------\n",
      "  timestep     |  79318\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79475, rl-loss: 0.3790681064128876\n",
      "----------------------------------------\n",
      "  timestep     |  79474\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79628, rl-loss: 0.5398265719413757\n",
      "----------------------------------------\n",
      "  timestep     |  79627\n",
      "  reward       |  -0.004\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79777, rl-loss: 0.4201511740684509\n",
      "----------------------------------------\n",
      "  timestep     |  79776\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 79928, rl-loss: 0.3445524573326111\n",
      "----------------------------------------\n",
      "  timestep     |  79927\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 80076, rl-loss: 0.4724549651145935\n",
      "----------------------------------------\n",
      "  timestep     |  80075\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 80222, rl-loss: 0.42568954825401306\n",
      "----------------------------------------\n",
      "  timestep     |  80221\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 80385, rl-loss: 0.6093829870223999\n",
      "----------------------------------------\n",
      "  timestep     |  80384\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 80535, rl-loss: 0.36311349272727966\n",
      "----------------------------------------\n",
      "  timestep     |  80534\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 80695, rl-loss: 0.5584122538566589\n",
      "----------------------------------------\n",
      "  timestep     |  80694\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 80857, rl-loss: 0.5301330089569092\n",
      "----------------------------------------\n",
      "  timestep     |  80856\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81018, rl-loss: 0.3040474057197571\n",
      "----------------------------------------\n",
      "  timestep     |  81017\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81181, rl-loss: 0.5559314489364624\n",
      "----------------------------------------\n",
      "  timestep     |  81180\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81343, rl-loss: 0.5797924995422363\n",
      "----------------------------------------\n",
      "  timestep     |  81342\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81483, rl-loss: 0.4710180461406708\n",
      "----------------------------------------\n",
      "  timestep     |  81482\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81621, rl-loss: 0.5466445684432983\n",
      "----------------------------------------\n",
      "  timestep     |  81620\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81776, rl-loss: 0.4350280165672302\n",
      "----------------------------------------\n",
      "  timestep     |  81775\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 81929, rl-loss: 0.4347623884677887\n",
      "----------------------------------------\n",
      "  timestep     |  81928\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82083, rl-loss: 0.5049185752868652\n",
      "----------------------------------------\n",
      "  timestep     |  82082\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82244, rl-loss: 0.47480663657188416\n",
      "----------------------------------------\n",
      "  timestep     |  82243\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82385, rl-loss: 0.3571184277534485\n",
      "----------------------------------------\n",
      "  timestep     |  82384\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82530, rl-loss: 0.4555249512195587\n",
      "----------------------------------------\n",
      "  timestep     |  82529\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82678, rl-loss: 0.49830469489097595\n",
      "----------------------------------------\n",
      "  timestep     |  82677\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82825, rl-loss: 0.5188295841217041\n",
      "----------------------------------------\n",
      "  timestep     |  82824\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 82974, rl-loss: 0.6491713523864746\n",
      "----------------------------------------\n",
      "  timestep     |  82973\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83129, rl-loss: 0.5566373467445374\n",
      "----------------------------------------\n",
      "  timestep     |  83128\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83267, rl-loss: 0.4481562376022339\n",
      "----------------------------------------\n",
      "  timestep     |  83266\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83415, rl-loss: 0.508454442024231\n",
      "----------------------------------------\n",
      "  timestep     |  83414\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83556, rl-loss: 0.4244730770587921\n",
      "----------------------------------------\n",
      "  timestep     |  83555\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83696, rl-loss: 0.7407037615776062\n",
      "----------------------------------------\n",
      "  timestep     |  83695\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83825, rl-loss: 0.6908366680145264\n",
      "----------------------------------------\n",
      "  timestep     |  83824\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 83964, rl-loss: 0.5094228982925415\n",
      "----------------------------------------\n",
      "  timestep     |  83963\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84115, rl-loss: 0.6258469223976135\n",
      "----------------------------------------\n",
      "  timestep     |  84114\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84251, rl-loss: 0.6965497732162476\n",
      "----------------------------------------\n",
      "  timestep     |  84250\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84394, rl-loss: 0.5498098134994507\n",
      "----------------------------------------\n",
      "  timestep     |  84393\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84545, rl-loss: 0.34617751836776733\n",
      "----------------------------------------\n",
      "  timestep     |  84544\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84686, rl-loss: 0.5492842793464661\n",
      "----------------------------------------\n",
      "  timestep     |  84685\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84837, rl-loss: 0.4024195075035095\n",
      "----------------------------------------\n",
      "  timestep     |  84836\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 84984, rl-loss: 0.5951294898986816\n",
      "----------------------------------------\n",
      "  timestep     |  84983\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 85137, rl-loss: 0.46329426765441895\n",
      "----------------------------------------\n",
      "  timestep     |  85136\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 85272, rl-loss: 0.544497013092041\n",
      "----------------------------------------\n",
      "  timestep     |  85271\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 85423, rl-loss: 0.5408987998962402\n",
      "----------------------------------------\n",
      "  timestep     |  85422\n",
      "  reward       |  -0.018\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 85577, rl-loss: 0.38284000754356384\n",
      "----------------------------------------\n",
      "  timestep     |  85576\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 85726, rl-loss: 0.546465277671814\n",
      "----------------------------------------\n",
      "  timestep     |  85725\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 85867, rl-loss: 0.5420330762863159\n",
      "----------------------------------------\n",
      "  timestep     |  85866\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86018, rl-loss: 0.5576432943344116\n",
      "----------------------------------------\n",
      "  timestep     |  86017\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86157, rl-loss: 0.5791881680488586\n",
      "----------------------------------------\n",
      "  timestep     |  86156\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86304, rl-loss: 0.32290396094322205\n",
      "----------------------------------------\n",
      "  timestep     |  86303\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86449, rl-loss: 0.40083324909210205\n",
      "----------------------------------------\n",
      "  timestep     |  86448\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86594, rl-loss: 0.5456498265266418\n",
      "----------------------------------------\n",
      "  timestep     |  86593\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86734, rl-loss: 0.6567127108573914\n",
      "----------------------------------------\n",
      "  timestep     |  86733\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 86864, rl-loss: 0.6309753656387329\n",
      "----------------------------------------\n",
      "  timestep     |  86863\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87002, rl-loss: 0.6395683288574219\n",
      "----------------------------------------\n",
      "  timestep     |  87001\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87145, rl-loss: 0.4096089005470276\n",
      "----------------------------------------\n",
      "  timestep     |  87144\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87287, rl-loss: 0.5680069923400879\n",
      "----------------------------------------\n",
      "  timestep     |  87286\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87430, rl-loss: 0.5778729915618896\n",
      "----------------------------------------\n",
      "  timestep     |  87429\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87574, rl-loss: 0.47620096802711487\n",
      "----------------------------------------\n",
      "  timestep     |  87573\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87719, rl-loss: 0.4270350933074951\n",
      "----------------------------------------\n",
      "  timestep     |  87718\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 87870, rl-loss: 0.5322667956352234\n",
      "----------------------------------------\n",
      "  timestep     |  87869\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88014, rl-loss: 0.5116816163063049\n",
      "----------------------------------------\n",
      "  timestep     |  88013\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88156, rl-loss: 0.36512067914009094\n",
      "----------------------------------------\n",
      "  timestep     |  88155\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88308, rl-loss: 0.6338320374488831\n",
      "----------------------------------------\n",
      "  timestep     |  88307\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88458, rl-loss: 0.5933305025100708\n",
      "----------------------------------------\n",
      "  timestep     |  88457\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88608, rl-loss: 0.513038158416748\n",
      "----------------------------------------\n",
      "  timestep     |  88607\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88739, rl-loss: 0.4284476637840271\n",
      "----------------------------------------\n",
      "  timestep     |  88738\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 88887, rl-loss: 0.519481360912323\n",
      "----------------------------------------\n",
      "  timestep     |  88886\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89028, rl-loss: 0.6847087740898132\n",
      "----------------------------------------\n",
      "  timestep     |  89027\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89172, rl-loss: 0.4952552914619446\n",
      "----------------------------------------\n",
      "  timestep     |  89171\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89329, rl-loss: 0.6777318716049194\n",
      "----------------------------------------\n",
      "  timestep     |  89328\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89482, rl-loss: 0.4642208516597748\n",
      "----------------------------------------\n",
      "  timestep     |  89481\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89634, rl-loss: 0.6389551758766174\n",
      "----------------------------------------\n",
      "  timestep     |  89633\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89781, rl-loss: 0.7776947021484375\n",
      "----------------------------------------\n",
      "  timestep     |  89780\n",
      "  reward       |  0.001\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 89931, rl-loss: 0.2725215256214142\n",
      "----------------------------------------\n",
      "  timestep     |  89930\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90082, rl-loss: 0.24935266375541687\n",
      "----------------------------------------\n",
      "  timestep     |  90081\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90226, rl-loss: 0.45092666149139404\n",
      "----------------------------------------\n",
      "  timestep     |  90225\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90377, rl-loss: 0.5992026925086975\n",
      "----------------------------------------\n",
      "  timestep     |  90376\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90524, rl-loss: 0.6196803450584412\n",
      "----------------------------------------\n",
      "  timestep     |  90523\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90674, rl-loss: 0.7142772674560547\n",
      "----------------------------------------\n",
      "  timestep     |  90673\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90803, rl-loss: 0.9911450147628784\n",
      "----------------------------------------\n",
      "  timestep     |  90802\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 90942, rl-loss: 0.3763008713722229\n",
      "----------------------------------------\n",
      "  timestep     |  90941\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91082, rl-loss: 0.365402489900589\n",
      "----------------------------------------\n",
      "  timestep     |  91081\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91229, rl-loss: 0.4662743806838989\n",
      "----------------------------------------\n",
      "  timestep     |  91228\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91367, rl-loss: 0.5629671812057495\n",
      "----------------------------------------\n",
      "  timestep     |  91366\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91521, rl-loss: 0.665551483631134\n",
      "----------------------------------------\n",
      "  timestep     |  91520\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91669, rl-loss: 0.6100264191627502\n",
      "----------------------------------------\n",
      "  timestep     |  91668\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91824, rl-loss: 0.5192667245864868\n",
      "----------------------------------------\n",
      "  timestep     |  91823\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 91963, rl-loss: 0.3997092843055725\n",
      "----------------------------------------\n",
      "  timestep     |  91962\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 92111, rl-loss: 0.5123438835144043\n",
      "----------------------------------------\n",
      "  timestep     |  92110\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 92258, rl-loss: 0.34233778715133667\n",
      "----------------------------------------\n",
      "  timestep     |  92257\n",
      "  reward       |  -0.121\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 92406, rl-loss: 0.6890017986297607\n",
      "----------------------------------------\n",
      "  timestep     |  92405\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 92543, rl-loss: 0.3911370038986206\n",
      "----------------------------------------\n",
      "  timestep     |  92542\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 92700, rl-loss: 0.5055108666419983\n",
      "----------------------------------------\n",
      "  timestep     |  92699\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 92845, rl-loss: 0.4502463638782501\n",
      "----------------------------------------\n",
      "  timestep     |  92844\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93001, rl-loss: 0.4976377487182617\n",
      "----------------------------------------\n",
      "  timestep     |  93000\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93149, rl-loss: 0.5848938822746277\n",
      "----------------------------------------\n",
      "  timestep     |  93148\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93300, rl-loss: 0.34913235902786255\n",
      "----------------------------------------\n",
      "  timestep     |  93299\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93442, rl-loss: 0.5321621298789978\n",
      "----------------------------------------\n",
      "  timestep     |  93441\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93599, rl-loss: 0.40833768248558044\n",
      "----------------------------------------\n",
      "  timestep     |  93598\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93745, rl-loss: 0.4962896704673767\n",
      "----------------------------------------\n",
      "  timestep     |  93744\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 93895, rl-loss: 0.49721089005470276\n",
      "----------------------------------------\n",
      "  timestep     |  93894\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94042, rl-loss: 0.5284897089004517\n",
      "----------------------------------------\n",
      "  timestep     |  94041\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94190, rl-loss: 0.4381735026836395\n",
      "----------------------------------------\n",
      "  timestep     |  94189\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94339, rl-loss: 0.5291037559509277\n",
      "----------------------------------------\n",
      "  timestep     |  94338\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94487, rl-loss: 0.5322736501693726\n",
      "----------------------------------------\n",
      "  timestep     |  94486\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94631, rl-loss: 0.63402259349823\n",
      "----------------------------------------\n",
      "  timestep     |  94630\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94774, rl-loss: 0.5722423791885376\n",
      "----------------------------------------\n",
      "  timestep     |  94773\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 94929, rl-loss: 0.5802743434906006\n",
      "----------------------------------------\n",
      "  timestep     |  94928\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95078, rl-loss: 0.6650915741920471\n",
      "----------------------------------------\n",
      "  timestep     |  95077\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95236, rl-loss: 0.7541726231575012\n",
      "----------------------------------------\n",
      "  timestep     |  95235\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95390, rl-loss: 0.5507572889328003\n",
      "----------------------------------------\n",
      "  timestep     |  95389\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95534, rl-loss: 0.45305317640304565\n",
      "----------------------------------------\n",
      "  timestep     |  95533\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95695, rl-loss: 0.353554904460907\n",
      "----------------------------------------\n",
      "  timestep     |  95694\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95842, rl-loss: 0.7057895660400391\n",
      "----------------------------------------\n",
      "  timestep     |  95841\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 95994, rl-loss: 0.38967809081077576\n",
      "----------------------------------------\n",
      "  timestep     |  95993\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 96155, rl-loss: 0.412662535905838\n",
      "----------------------------------------\n",
      "  timestep     |  96154\n",
      "  reward       |  0.008\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 96301, rl-loss: 0.5751574635505676\n",
      "----------------------------------------\n",
      "  timestep     |  96300\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 96445, rl-loss: 0.392404705286026\n",
      "----------------------------------------\n",
      "  timestep     |  96444\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 96594, rl-loss: 0.3487080931663513\n",
      "----------------------------------------\n",
      "  timestep     |  96593\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 96750, rl-loss: 0.3427196443080902\n",
      "----------------------------------------\n",
      "  timestep     |  96749\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 96894, rl-loss: 0.6120954751968384\n",
      "----------------------------------------\n",
      "  timestep     |  96893\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97056, rl-loss: 0.5853215456008911\n",
      "----------------------------------------\n",
      "  timestep     |  97055\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97207, rl-loss: 0.3942842185497284\n",
      "----------------------------------------\n",
      "  timestep     |  97206\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97364, rl-loss: 0.46006160974502563\n",
      "----------------------------------------\n",
      "  timestep     |  97363\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97510, rl-loss: 0.39637404680252075\n",
      "----------------------------------------\n",
      "  timestep     |  97509\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97662, rl-loss: 0.43149226903915405\n",
      "----------------------------------------\n",
      "  timestep     |  97661\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97802, rl-loss: 0.4691188335418701\n",
      "----------------------------------------\n",
      "  timestep     |  97801\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 97967, rl-loss: 0.4449617266654968\n",
      "----------------------------------------\n",
      "  timestep     |  97966\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98126, rl-loss: 0.5119600296020508\n",
      "----------------------------------------\n",
      "  timestep     |  98125\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98271, rl-loss: 0.5650076866149902\n",
      "----------------------------------------\n",
      "  timestep     |  98270\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98417, rl-loss: 0.3642600178718567\n",
      "----------------------------------------\n",
      "  timestep     |  98416\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98563, rl-loss: 0.47799450159072876\n",
      "----------------------------------------\n",
      "  timestep     |  98562\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98711, rl-loss: 0.5328909754753113\n",
      "----------------------------------------\n",
      "  timestep     |  98710\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98858, rl-loss: 0.5703551173210144\n",
      "----------------------------------------\n",
      "  timestep     |  98857\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 98994, rl-loss: 0.6498842239379883\n",
      "----------------------------------------\n",
      "  timestep     |  98993\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99149, rl-loss: 0.49354177713394165\n",
      "----------------------------------------\n",
      "  timestep     |  99148\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99287, rl-loss: 0.5435560345649719\n",
      "----------------------------------------\n",
      "  timestep     |  99286\n",
      "  reward       |  -0.159\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99418, rl-loss: 0.3855334222316742\n",
      "----------------------------------------\n",
      "  timestep     |  99417\n",
      "  reward       |  -0.15\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99555, rl-loss: 0.5106958150863647\n",
      "----------------------------------------\n",
      "  timestep     |  99554\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99696, rl-loss: 0.6001237630844116\n",
      "----------------------------------------\n",
      "  timestep     |  99695\n",
      "  reward       |  -0.17\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99840, rl-loss: 0.6092871427536011\n",
      "----------------------------------------\n",
      "  timestep     |  99839\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 99979, rl-loss: 0.27951541543006897\n",
      "----------------------------------------\n",
      "  timestep     |  99978\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100128, rl-loss: 0.6080725193023682\n",
      "----------------------------------------\n",
      "  timestep     |  100127\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100257, rl-loss: 0.43392235040664673\n",
      "----------------------------------------\n",
      "  timestep     |  100256\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100401, rl-loss: 0.3822769820690155\n",
      "----------------------------------------\n",
      "  timestep     |  100400\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100548, rl-loss: 0.39162683486938477\n",
      "----------------------------------------\n",
      "  timestep     |  100547\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100694, rl-loss: 0.5621157884597778\n",
      "----------------------------------------\n",
      "  timestep     |  100693\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100836, rl-loss: 0.7155517339706421\n",
      "----------------------------------------\n",
      "  timestep     |  100835\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 100985, rl-loss: 0.6530265808105469\n",
      "----------------------------------------\n",
      "  timestep     |  100984\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 101126, rl-loss: 0.6236212849617004\n",
      "----------------------------------------\n",
      "  timestep     |  101125\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 101277, rl-loss: 0.48170194029808044\n",
      "----------------------------------------\n",
      "  timestep     |  101276\n",
      "  reward       |  -0.129\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 101422, rl-loss: 0.511417031288147\n",
      "----------------------------------------\n",
      "  timestep     |  101421\n",
      "  reward       |  -0.125\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 101575, rl-loss: 0.5654338002204895\n",
      "----------------------------------------\n",
      "  timestep     |  101574\n",
      "  reward       |  -0.003\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 101729, rl-loss: 0.4837295413017273\n",
      "----------------------------------------\n",
      "  timestep     |  101728\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 101886, rl-loss: 0.34428590536117554\n",
      "----------------------------------------\n",
      "  timestep     |  101885\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102037, rl-loss: 0.6142016053199768\n",
      "----------------------------------------\n",
      "  timestep     |  102036\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102180, rl-loss: 0.4284130036830902\n",
      "----------------------------------------\n",
      "  timestep     |  102179\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102319, rl-loss: 0.390238493680954\n",
      "----------------------------------------\n",
      "  timestep     |  102318\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102467, rl-loss: 0.5609566569328308\n",
      "----------------------------------------\n",
      "  timestep     |  102466\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102629, rl-loss: 0.5363408327102661\n",
      "----------------------------------------\n",
      "  timestep     |  102628\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102775, rl-loss: 0.5426033735275269\n",
      "----------------------------------------\n",
      "  timestep     |  102774\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 102923, rl-loss: 0.434805691242218\n",
      "----------------------------------------\n",
      "  timestep     |  102922\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103069, rl-loss: 0.5153021216392517\n",
      "----------------------------------------\n",
      "  timestep     |  103068\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103218, rl-loss: 0.3130473792552948\n",
      "----------------------------------------\n",
      "  timestep     |  103217\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103373, rl-loss: 0.42859578132629395\n",
      "----------------------------------------\n",
      "  timestep     |  103372\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103518, rl-loss: 0.5639439225196838\n",
      "----------------------------------------\n",
      "  timestep     |  103517\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103661, rl-loss: 0.49514302611351013\n",
      "----------------------------------------\n",
      "  timestep     |  103660\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103801, rl-loss: 0.5492100715637207\n",
      "----------------------------------------\n",
      "  timestep     |  103800\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 103945, rl-loss: 0.39559945464134216\n",
      "----------------------------------------\n",
      "  timestep     |  103944\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104088, rl-loss: 0.521690309047699\n",
      "----------------------------------------\n",
      "  timestep     |  104087\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104240, rl-loss: 0.5264098048210144\n",
      "----------------------------------------\n",
      "  timestep     |  104239\n",
      "  reward       |  -0.158\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104386, rl-loss: 0.6276510953903198\n",
      "----------------------------------------\n",
      "  timestep     |  104385\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104537, rl-loss: 0.5166487693786621\n",
      "----------------------------------------\n",
      "  timestep     |  104536\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104671, rl-loss: 0.48341625928878784\n",
      "----------------------------------------\n",
      "  timestep     |  104670\n",
      "  reward       |  -0.129\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104811, rl-loss: 0.4485718607902527\n",
      "----------------------------------------\n",
      "  timestep     |  104810\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 104965, rl-loss: 0.6771633625030518\n",
      "----------------------------------------\n",
      "  timestep     |  104964\n",
      "  reward       |  -0.137\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 105112, rl-loss: 0.7342969179153442\n",
      "----------------------------------------\n",
      "  timestep     |  105111\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 105275, rl-loss: 0.477609783411026\n",
      "----------------------------------------\n",
      "  timestep     |  105274\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 105442, rl-loss: 0.34293121099472046\n",
      "----------------------------------------\n",
      "  timestep     |  105441\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 105591, rl-loss: 0.4442967474460602\n",
      "----------------------------------------\n",
      "  timestep     |  105590\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 105742, rl-loss: 0.41823911666870117\n",
      "----------------------------------------\n",
      "  timestep     |  105741\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 105893, rl-loss: 0.443393737077713\n",
      "----------------------------------------\n",
      "  timestep     |  105892\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106042, rl-loss: 0.5601957440376282\n",
      "----------------------------------------\n",
      "  timestep     |  106041\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106185, rl-loss: 0.46363791823387146\n",
      "----------------------------------------\n",
      "  timestep     |  106184\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106328, rl-loss: 0.5551983118057251\n",
      "----------------------------------------\n",
      "  timestep     |  106327\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106459, rl-loss: 0.3373931050300598\n",
      "----------------------------------------\n",
      "  timestep     |  106458\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106589, rl-loss: 0.6669493913650513\n",
      "----------------------------------------\n",
      "  timestep     |  106588\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106729, rl-loss: 0.4785268008708954\n",
      "----------------------------------------\n",
      "  timestep     |  106728\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106860, rl-loss: 0.5266327857971191\n",
      "----------------------------------------\n",
      "  timestep     |  106859\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 106996, rl-loss: 0.6368420124053955\n",
      "----------------------------------------\n",
      "  timestep     |  106995\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107136, rl-loss: 0.6863192319869995\n",
      "----------------------------------------\n",
      "  timestep     |  107135\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107274, rl-loss: 0.7152239084243774\n",
      "----------------------------------------\n",
      "  timestep     |  107273\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107406, rl-loss: 0.6517181396484375\n",
      "----------------------------------------\n",
      "  timestep     |  107405\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107549, rl-loss: 0.5639654994010925\n",
      "----------------------------------------\n",
      "  timestep     |  107548\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107700, rl-loss: 0.432542085647583\n",
      "----------------------------------------\n",
      "  timestep     |  107699\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107844, rl-loss: 0.5989135503768921\n",
      "----------------------------------------\n",
      "  timestep     |  107843\n",
      "  reward       |  -0.126\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 107997, rl-loss: 0.5916194319725037\n",
      "----------------------------------------\n",
      "  timestep     |  107996\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 108134, rl-loss: 0.564714252948761\n",
      "----------------------------------------\n",
      "  timestep     |  108133\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 108282, rl-loss: 0.4151904881000519\n",
      "----------------------------------------\n",
      "  timestep     |  108281\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 108436, rl-loss: 0.27794671058654785\n",
      "----------------------------------------\n",
      "  timestep     |  108435\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 108585, rl-loss: 0.5674623847007751\n",
      "----------------------------------------\n",
      "  timestep     |  108584\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 108728, rl-loss: 0.48082900047302246\n",
      "----------------------------------------\n",
      "  timestep     |  108727\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 108882, rl-loss: 0.5086202621459961\n",
      "----------------------------------------\n",
      "  timestep     |  108881\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109041, rl-loss: 0.5209444761276245\n",
      "----------------------------------------\n",
      "  timestep     |  109040\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109199, rl-loss: 0.5101778507232666\n",
      "----------------------------------------\n",
      "  timestep     |  109198\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109351, rl-loss: 0.7209922075271606\n",
      "----------------------------------------\n",
      "  timestep     |  109350\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109501, rl-loss: 0.40652555227279663\n",
      "----------------------------------------\n",
      "  timestep     |  109500\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109657, rl-loss: 0.2911756932735443\n",
      "----------------------------------------\n",
      "  timestep     |  109656\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109808, rl-loss: 0.49918991327285767\n",
      "----------------------------------------\n",
      "  timestep     |  109807\n",
      "  reward       |  -0.001\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 109952, rl-loss: 0.44946908950805664\n",
      "----------------------------------------\n",
      "  timestep     |  109951\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110096, rl-loss: 0.5541023015975952\n",
      "----------------------------------------\n",
      "  timestep     |  110095\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110246, rl-loss: 0.5653820633888245\n",
      "----------------------------------------\n",
      "  timestep     |  110245\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110391, rl-loss: 0.4091868996620178\n",
      "----------------------------------------\n",
      "  timestep     |  110390\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110540, rl-loss: 0.639970600605011\n",
      "----------------------------------------\n",
      "  timestep     |  110539\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110691, rl-loss: 0.6374547481536865\n",
      "----------------------------------------\n",
      "  timestep     |  110690\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110845, rl-loss: 0.48392143845558167\n",
      "----------------------------------------\n",
      "  timestep     |  110844\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 110995, rl-loss: 0.5071011781692505\n",
      "----------------------------------------\n",
      "  timestep     |  110994\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 111141, rl-loss: 0.3649307191371918\n",
      "----------------------------------------\n",
      "  timestep     |  111140\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 111304, rl-loss: 0.4785284698009491\n",
      "----------------------------------------\n",
      "  timestep     |  111303\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 111460, rl-loss: 0.532814085483551\n",
      "----------------------------------------\n",
      "  timestep     |  111459\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 111611, rl-loss: 0.5747479796409607\n",
      "----------------------------------------\n",
      "  timestep     |  111610\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 111753, rl-loss: 0.33539700508117676\n",
      "----------------------------------------\n",
      "  timestep     |  111752\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 111895, rl-loss: 0.5158944129943848\n",
      "----------------------------------------\n",
      "  timestep     |  111894\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112042, rl-loss: 0.3873624801635742\n",
      "----------------------------------------\n",
      "  timestep     |  112041\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112190, rl-loss: 0.6242953538894653\n",
      "----------------------------------------\n",
      "  timestep     |  112189\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112330, rl-loss: 0.6477281451225281\n",
      "----------------------------------------\n",
      "  timestep     |  112329\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112469, rl-loss: 0.5452460646629333\n",
      "----------------------------------------\n",
      "  timestep     |  112468\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112614, rl-loss: 0.6683679223060608\n",
      "----------------------------------------\n",
      "  timestep     |  112613\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112763, rl-loss: 0.5526278018951416\n",
      "----------------------------------------\n",
      "  timestep     |  112762\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 112916, rl-loss: 0.47264134883880615\n",
      "----------------------------------------\n",
      "  timestep     |  112915\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113064, rl-loss: 0.5192292332649231\n",
      "----------------------------------------\n",
      "  timestep     |  113063\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113198, rl-loss: 0.37443551421165466\n",
      "----------------------------------------\n",
      "  timestep     |  113197\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113360, rl-loss: 0.5269761085510254\n",
      "----------------------------------------\n",
      "  timestep     |  113359\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113500, rl-loss: 0.39421311020851135\n",
      "----------------------------------------\n",
      "  timestep     |  113499\n",
      "  reward       |  -0.019\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113644, rl-loss: 0.5038275718688965\n",
      "----------------------------------------\n",
      "  timestep     |  113643\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113780, rl-loss: 0.520624041557312\n",
      "----------------------------------------\n",
      "  timestep     |  113779\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 113931, rl-loss: 0.5381842255592346\n",
      "----------------------------------------\n",
      "  timestep     |  113930\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 114079, rl-loss: 0.5457155108451843\n",
      "----------------------------------------\n",
      "  timestep     |  114078\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 114237, rl-loss: 0.6148900985717773\n",
      "----------------------------------------\n",
      "  timestep     |  114236\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 114388, rl-loss: 0.5864489674568176\n",
      "----------------------------------------\n",
      "  timestep     |  114387\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 114539, rl-loss: 0.5508449673652649\n",
      "----------------------------------------\n",
      "  timestep     |  114538\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 114702, rl-loss: 0.47640442848205566\n",
      "----------------------------------------\n",
      "  timestep     |  114701\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 114861, rl-loss: 0.43436533212661743\n",
      "----------------------------------------\n",
      "  timestep     |  114860\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115011, rl-loss: 0.4367782473564148\n",
      "----------------------------------------\n",
      "  timestep     |  115010\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115164, rl-loss: 0.4718152582645416\n",
      "----------------------------------------\n",
      "  timestep     |  115163\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115306, rl-loss: 0.4776168167591095\n",
      "----------------------------------------\n",
      "  timestep     |  115305\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115450, rl-loss: 0.7301756739616394\n",
      "----------------------------------------\n",
      "  timestep     |  115449\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115594, rl-loss: 0.511873185634613\n",
      "----------------------------------------\n",
      "  timestep     |  115593\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115739, rl-loss: 0.5505608320236206\n",
      "----------------------------------------\n",
      "  timestep     |  115738\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 115882, rl-loss: 0.40075305104255676\n",
      "----------------------------------------\n",
      "  timestep     |  115881\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116033, rl-loss: 0.5943061113357544\n",
      "----------------------------------------\n",
      "  timestep     |  116032\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116184, rl-loss: 0.3460841178894043\n",
      "----------------------------------------\n",
      "  timestep     |  116183\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116339, rl-loss: 0.5446397066116333\n",
      "----------------------------------------\n",
      "  timestep     |  116338\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116488, rl-loss: 0.4652891159057617\n",
      "----------------------------------------\n",
      "  timestep     |  116487\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116640, rl-loss: 0.4309813678264618\n",
      "----------------------------------------\n",
      "  timestep     |  116639\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116794, rl-loss: 0.4059833884239197\n",
      "----------------------------------------\n",
      "  timestep     |  116793\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 116944, rl-loss: 0.38027775287628174\n",
      "----------------------------------------\n",
      "  timestep     |  116943\n",
      "  reward       |  -0.123\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117099, rl-loss: 0.5738916397094727\n",
      "----------------------------------------\n",
      "  timestep     |  117098\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117224, rl-loss: 0.387627512216568\n",
      "----------------------------------------\n",
      "  timestep     |  117223\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117361, rl-loss: 0.5739140510559082\n",
      "----------------------------------------\n",
      "  timestep     |  117360\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117492, rl-loss: 0.44190001487731934\n",
      "----------------------------------------\n",
      "  timestep     |  117491\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117620, rl-loss: 0.5552884340286255\n",
      "----------------------------------------\n",
      "  timestep     |  117619\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117751, rl-loss: 0.547823429107666\n",
      "----------------------------------------\n",
      "  timestep     |  117750\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 117889, rl-loss: 0.4488048851490021\n",
      "----------------------------------------\n",
      "  timestep     |  117888\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118032, rl-loss: 0.5641133189201355\n",
      "----------------------------------------\n",
      "  timestep     |  118031\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118187, rl-loss: 0.4782813787460327\n",
      "----------------------------------------\n",
      "  timestep     |  118186\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118327, rl-loss: 0.3743932843208313\n",
      "----------------------------------------\n",
      "  timestep     |  118326\n",
      "  reward       |  -0.007\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118472, rl-loss: 0.48842671513557434\n",
      "----------------------------------------\n",
      "  timestep     |  118471\n",
      "  reward       |  -0.001\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118619, rl-loss: 0.5881166458129883\n",
      "----------------------------------------\n",
      "  timestep     |  118618\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118759, rl-loss: 0.42622047662734985\n",
      "----------------------------------------\n",
      "  timestep     |  118758\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 118914, rl-loss: 0.5428557395935059\n",
      "----------------------------------------\n",
      "  timestep     |  118913\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119064, rl-loss: 0.5764256119728088\n",
      "----------------------------------------\n",
      "  timestep     |  119063\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119208, rl-loss: 0.4330269992351532\n",
      "----------------------------------------\n",
      "  timestep     |  119207\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119350, rl-loss: 0.49191030859947205\n",
      "----------------------------------------\n",
      "  timestep     |  119349\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119498, rl-loss: 0.544567346572876\n",
      "----------------------------------------\n",
      "  timestep     |  119497\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119655, rl-loss: 0.6381011009216309\n",
      "----------------------------------------\n",
      "  timestep     |  119654\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119797, rl-loss: 0.4476037323474884\n",
      "----------------------------------------\n",
      "  timestep     |  119796\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 119950, rl-loss: 0.5361947417259216\n",
      "----------------------------------------\n",
      "  timestep     |  119949\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 120108, rl-loss: 0.5416164994239807\n",
      "----------------------------------------\n",
      "  timestep     |  120107\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 120259, rl-loss: 0.4330924153327942\n",
      "----------------------------------------\n",
      "  timestep     |  120258\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 120405, rl-loss: 0.5065445899963379\n",
      "----------------------------------------\n",
      "  timestep     |  120404\n",
      "  reward       |  0.003\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 120554, rl-loss: 0.5823075175285339\n",
      "----------------------------------------\n",
      "  timestep     |  120553\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 120704, rl-loss: 0.5264397263526917\n",
      "----------------------------------------\n",
      "  timestep     |  120703\n",
      "  reward       |  -0.022\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 120851, rl-loss: 0.637062132358551\n",
      "----------------------------------------\n",
      "  timestep     |  120850\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121008, rl-loss: 0.1777830719947815\n",
      "----------------------------------------\n",
      "  timestep     |  121007\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121165, rl-loss: 0.5079569816589355\n",
      "----------------------------------------\n",
      "  timestep     |  121164\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121321, rl-loss: 0.5383312106132507\n",
      "----------------------------------------\n",
      "  timestep     |  121320\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121463, rl-loss: 0.5835314393043518\n",
      "----------------------------------------\n",
      "  timestep     |  121462\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121609, rl-loss: 0.36287009716033936\n",
      "----------------------------------------\n",
      "  timestep     |  121608\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121760, rl-loss: 0.4313725233078003\n",
      "----------------------------------------\n",
      "  timestep     |  121759\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 121916, rl-loss: 0.4754137396812439\n",
      "----------------------------------------\n",
      "  timestep     |  121915\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122066, rl-loss: 0.4726240932941437\n",
      "----------------------------------------\n",
      "  timestep     |  122065\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122204, rl-loss: 0.5057169795036316\n",
      "----------------------------------------\n",
      "  timestep     |  122203\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122345, rl-loss: 0.4705684185028076\n",
      "----------------------------------------\n",
      "  timestep     |  122344\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122492, rl-loss: 0.41552817821502686\n",
      "----------------------------------------\n",
      "  timestep     |  122491\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122647, rl-loss: 0.4838358461856842\n",
      "----------------------------------------\n",
      "  timestep     |  122646\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122800, rl-loss: 0.5335367321968079\n",
      "----------------------------------------\n",
      "  timestep     |  122799\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 122943, rl-loss: 0.5160373449325562\n",
      "----------------------------------------\n",
      "  timestep     |  122942\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123092, rl-loss: 0.5734413862228394\n",
      "----------------------------------------\n",
      "  timestep     |  123091\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123246, rl-loss: 0.5437017679214478\n",
      "----------------------------------------\n",
      "  timestep     |  123245\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123396, rl-loss: 0.5408763289451599\n",
      "----------------------------------------\n",
      "  timestep     |  123395\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123526, rl-loss: 0.5216595530509949\n",
      "----------------------------------------\n",
      "  timestep     |  123525\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123663, rl-loss: 0.45987623929977417\n",
      "----------------------------------------\n",
      "  timestep     |  123662\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123812, rl-loss: 0.49844446778297424\n",
      "----------------------------------------\n",
      "  timestep     |  123811\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 123958, rl-loss: 0.3683191239833832\n",
      "----------------------------------------\n",
      "  timestep     |  123957\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124099, rl-loss: 0.5670027136802673\n",
      "----------------------------------------\n",
      "  timestep     |  124098\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124239, rl-loss: 0.49475255608558655\n",
      "----------------------------------------\n",
      "  timestep     |  124238\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124397, rl-loss: 0.44935598969459534\n",
      "----------------------------------------\n",
      "  timestep     |  124396\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124544, rl-loss: 0.46795016527175903\n",
      "----------------------------------------\n",
      "  timestep     |  124543\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124697, rl-loss: 0.44612881541252136\n",
      "----------------------------------------\n",
      "  timestep     |  124696\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124846, rl-loss: 0.3539904057979584\n",
      "----------------------------------------\n",
      "  timestep     |  124845\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 124993, rl-loss: 0.3260030746459961\n",
      "----------------------------------------\n",
      "  timestep     |  124992\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125146, rl-loss: 0.5350627303123474\n",
      "----------------------------------------\n",
      "  timestep     |  125145\n",
      "  reward       |  0.022\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125290, rl-loss: 0.564963698387146\n",
      "----------------------------------------\n",
      "  timestep     |  125289\n",
      "  reward       |  -0.003\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125433, rl-loss: 0.3499166965484619\n",
      "----------------------------------------\n",
      "  timestep     |  125432\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125578, rl-loss: 0.45889681577682495\n",
      "----------------------------------------\n",
      "  timestep     |  125577\n",
      "  reward       |  0.005\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125721, rl-loss: 0.6398298144340515\n",
      "----------------------------------------\n",
      "  timestep     |  125720\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125855, rl-loss: 0.47559231519699097\n",
      "----------------------------------------\n",
      "  timestep     |  125854\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 125997, rl-loss: 0.41363489627838135\n",
      "----------------------------------------\n",
      "  timestep     |  125996\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126137, rl-loss: 0.5390186309814453\n",
      "----------------------------------------\n",
      "  timestep     |  126136\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126272, rl-loss: 0.49775180220603943\n",
      "----------------------------------------\n",
      "  timestep     |  126271\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126416, rl-loss: 0.4448683261871338\n",
      "----------------------------------------\n",
      "  timestep     |  126415\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126553, rl-loss: 0.5549362301826477\n",
      "----------------------------------------\n",
      "  timestep     |  126552\n",
      "  reward       |  -0.165\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126693, rl-loss: 0.6270272731781006\n",
      "----------------------------------------\n",
      "  timestep     |  126692\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126836, rl-loss: 0.5249767899513245\n",
      "----------------------------------------\n",
      "  timestep     |  126835\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 126990, rl-loss: 0.707569420337677\n",
      "----------------------------------------\n",
      "  timestep     |  126989\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 127133, rl-loss: 0.6580643653869629\n",
      "----------------------------------------\n",
      "  timestep     |  127132\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 127266, rl-loss: 0.25870612263679504\n",
      "----------------------------------------\n",
      "  timestep     |  127265\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 127420, rl-loss: 0.6667578220367432\n",
      "----------------------------------------\n",
      "  timestep     |  127419\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 127563, rl-loss: 0.5600747466087341\n",
      "----------------------------------------\n",
      "  timestep     |  127562\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 127706, rl-loss: 0.6351998448371887\n",
      "----------------------------------------\n",
      "  timestep     |  127705\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 127853, rl-loss: 0.5095745921134949\n",
      "----------------------------------------\n",
      "  timestep     |  127852\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128004, rl-loss: 0.49206942319869995\n",
      "----------------------------------------\n",
      "  timestep     |  128003\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128153, rl-loss: 0.5931231379508972\n",
      "----------------------------------------\n",
      "  timestep     |  128152\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128301, rl-loss: 0.6002597212791443\n",
      "----------------------------------------\n",
      "  timestep     |  128300\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128450, rl-loss: 0.5378403663635254\n",
      "----------------------------------------\n",
      "  timestep     |  128449\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128593, rl-loss: 0.43747857213020325\n",
      "----------------------------------------\n",
      "  timestep     |  128592\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128738, rl-loss: 0.3780793845653534\n",
      "----------------------------------------\n",
      "  timestep     |  128737\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 128885, rl-loss: 0.6176465749740601\n",
      "----------------------------------------\n",
      "  timestep     |  128884\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129024, rl-loss: 0.6199916005134583\n",
      "----------------------------------------\n",
      "  timestep     |  129023\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129183, rl-loss: 0.39494630694389343\n",
      "----------------------------------------\n",
      "  timestep     |  129182\n",
      "  reward       |  -0.131\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129319, rl-loss: 0.371733158826828\n",
      "----------------------------------------\n",
      "  timestep     |  129318\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129464, rl-loss: 0.5057837963104248\n",
      "----------------------------------------\n",
      "  timestep     |  129463\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129614, rl-loss: 0.4205852150917053\n",
      "----------------------------------------\n",
      "  timestep     |  129613\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129760, rl-loss: 0.4357011020183563\n",
      "----------------------------------------\n",
      "  timestep     |  129759\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 129901, rl-loss: 0.42490190267562866\n",
      "----------------------------------------\n",
      "  timestep     |  129900\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130032, rl-loss: 0.43911096453666687\n",
      "----------------------------------------\n",
      "  timestep     |  130031\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130183, rl-loss: 0.5378990769386292\n",
      "----------------------------------------\n",
      "  timestep     |  130182\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130338, rl-loss: 0.6922838091850281\n",
      "----------------------------------------\n",
      "  timestep     |  130337\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130492, rl-loss: 0.6248413920402527\n",
      "----------------------------------------\n",
      "  timestep     |  130491\n",
      "  reward       |  -0.129\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130639, rl-loss: 0.7949048280715942\n",
      "----------------------------------------\n",
      "  timestep     |  130638\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130798, rl-loss: 0.6726369857788086\n",
      "----------------------------------------\n",
      "  timestep     |  130797\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 130949, rl-loss: 0.5202288031578064\n",
      "----------------------------------------\n",
      "  timestep     |  130948\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131093, rl-loss: 0.5410146713256836\n",
      "----------------------------------------\n",
      "  timestep     |  131092\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131234, rl-loss: 0.7876173257827759\n",
      "----------------------------------------\n",
      "  timestep     |  131233\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131385, rl-loss: 0.441729873418808\n",
      "----------------------------------------\n",
      "  timestep     |  131384\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131535, rl-loss: 0.36275312304496765\n",
      "----------------------------------------\n",
      "  timestep     |  131534\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131681, rl-loss: 0.4833643436431885\n",
      "----------------------------------------\n",
      "  timestep     |  131680\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131832, rl-loss: 0.5366005897521973\n",
      "----------------------------------------\n",
      "  timestep     |  131831\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 131974, rl-loss: 0.82744300365448\n",
      "----------------------------------------\n",
      "  timestep     |  131973\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132122, rl-loss: 0.5905673503875732\n",
      "----------------------------------------\n",
      "  timestep     |  132121\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132260, rl-loss: 0.28301578760147095\n",
      "----------------------------------------\n",
      "  timestep     |  132259\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132400, rl-loss: 0.5448551774024963\n",
      "----------------------------------------\n",
      "  timestep     |  132399\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132543, rl-loss: 0.6067743301391602\n",
      "----------------------------------------\n",
      "  timestep     |  132542\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132693, rl-loss: 0.5095969438552856\n",
      "----------------------------------------\n",
      "  timestep     |  132692\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132841, rl-loss: 0.5368742942810059\n",
      "----------------------------------------\n",
      "  timestep     |  132840\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 132986, rl-loss: 0.5535889267921448\n",
      "----------------------------------------\n",
      "  timestep     |  132985\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 133132, rl-loss: 0.6176654696464539\n",
      "----------------------------------------\n",
      "  timestep     |  133131\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 133283, rl-loss: 0.48859918117523193\n",
      "----------------------------------------\n",
      "  timestep     |  133282\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 133436, rl-loss: 0.45528334379196167\n",
      "----------------------------------------\n",
      "  timestep     |  133435\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 133579, rl-loss: 0.578070342540741\n",
      "----------------------------------------\n",
      "  timestep     |  133578\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 133723, rl-loss: 0.794868528842926\n",
      "----------------------------------------\n",
      "  timestep     |  133722\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 133874, rl-loss: 0.4055314064025879\n",
      "----------------------------------------\n",
      "  timestep     |  133873\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134030, rl-loss: 0.3516730070114136\n",
      "----------------------------------------\n",
      "  timestep     |  134029\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134184, rl-loss: 0.5391415357589722\n",
      "----------------------------------------\n",
      "  timestep     |  134183\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134344, rl-loss: 0.48349258303642273\n",
      "----------------------------------------\n",
      "  timestep     |  134343\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134501, rl-loss: 0.5739713311195374\n",
      "----------------------------------------\n",
      "  timestep     |  134500\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134669, rl-loss: 0.36439046263694763\n",
      "----------------------------------------\n",
      "  timestep     |  134668\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134807, rl-loss: 0.5503418445587158\n",
      "----------------------------------------\n",
      "  timestep     |  134806\n",
      "  reward       |  -0.123\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 134950, rl-loss: 0.4464736878871918\n",
      "----------------------------------------\n",
      "  timestep     |  134949\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 135105, rl-loss: 0.42114174365997314\n",
      "----------------------------------------\n",
      "  timestep     |  135104\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 135263, rl-loss: 0.5631370544433594\n",
      "----------------------------------------\n",
      "  timestep     |  135262\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 135430, rl-loss: 0.6470445990562439\n",
      "----------------------------------------\n",
      "  timestep     |  135429\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 135582, rl-loss: 0.5179564952850342\n",
      "----------------------------------------\n",
      "  timestep     |  135581\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 135747, rl-loss: 0.3539700508117676\n",
      "----------------------------------------\n",
      "  timestep     |  135746\n",
      "  reward       |  -0.121\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 135904, rl-loss: 0.4836733639240265\n",
      "----------------------------------------\n",
      "  timestep     |  135903\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136070, rl-loss: 0.600204586982727\n",
      "----------------------------------------\n",
      "  timestep     |  136069\n",
      "  reward       |  -0.022\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136226, rl-loss: 0.5744236707687378\n",
      "----------------------------------------\n",
      "  timestep     |  136225\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136363, rl-loss: 0.48193132877349854\n",
      "----------------------------------------\n",
      "  timestep     |  136362\n",
      "  reward       |  -0.115\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136510, rl-loss: 0.48850733041763306\n",
      "----------------------------------------\n",
      "  timestep     |  136509\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136665, rl-loss: 0.3518301248550415\n",
      "----------------------------------------\n",
      "  timestep     |  136664\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136814, rl-loss: 0.4339471459388733\n",
      "----------------------------------------\n",
      "  timestep     |  136813\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 136968, rl-loss: 0.531359076499939\n",
      "----------------------------------------\n",
      "  timestep     |  136967\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137103, rl-loss: 0.40762147307395935\n",
      "----------------------------------------\n",
      "  timestep     |  137102\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137249, rl-loss: 0.5990182161331177\n",
      "----------------------------------------\n",
      "  timestep     |  137248\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137405, rl-loss: 0.4845435619354248\n",
      "----------------------------------------\n",
      "  timestep     |  137404\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137541, rl-loss: 0.4108200967311859\n",
      "----------------------------------------\n",
      "  timestep     |  137540\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137674, rl-loss: 0.8022511005401611\n",
      "----------------------------------------\n",
      "  timestep     |  137673\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137836, rl-loss: 0.6247989535331726\n",
      "----------------------------------------\n",
      "  timestep     |  137835\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 137978, rl-loss: 0.6892356872558594\n",
      "----------------------------------------\n",
      "  timestep     |  137977\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 138121, rl-loss: 0.5192591547966003\n",
      "----------------------------------------\n",
      "  timestep     |  138120\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 138275, rl-loss: 0.5062087774276733\n",
      "----------------------------------------\n",
      "  timestep     |  138274\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 138422, rl-loss: 0.3503115773200989\n",
      "----------------------------------------\n",
      "  timestep     |  138421\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 138570, rl-loss: 0.4050845801830292\n",
      "----------------------------------------\n",
      "  timestep     |  138569\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 138708, rl-loss: 0.523853600025177\n",
      "----------------------------------------\n",
      "  timestep     |  138707\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 138851, rl-loss: 0.513010561466217\n",
      "----------------------------------------\n",
      "  timestep     |  138850\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139003, rl-loss: 0.45148852467536926\n",
      "----------------------------------------\n",
      "  timestep     |  139002\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139151, rl-loss: 0.3513108491897583\n",
      "----------------------------------------\n",
      "  timestep     |  139150\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139312, rl-loss: 0.5253722071647644\n",
      "----------------------------------------\n",
      "  timestep     |  139311\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139461, rl-loss: 0.5061153769493103\n",
      "----------------------------------------\n",
      "  timestep     |  139460\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139614, rl-loss: 0.6773492693901062\n",
      "----------------------------------------\n",
      "  timestep     |  139613\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139771, rl-loss: 0.502225935459137\n",
      "----------------------------------------\n",
      "  timestep     |  139770\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 139935, rl-loss: 0.489291250705719\n",
      "----------------------------------------\n",
      "  timestep     |  139934\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 140093, rl-loss: 0.5380266308784485\n",
      "----------------------------------------\n",
      "  timestep     |  140092\n",
      "  reward       |  0.005\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 140238, rl-loss: 0.4151836633682251\n",
      "----------------------------------------\n",
      "  timestep     |  140237\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 140386, rl-loss: 0.5366472601890564\n",
      "----------------------------------------\n",
      "  timestep     |  140385\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 140549, rl-loss: 0.623956561088562\n",
      "----------------------------------------\n",
      "  timestep     |  140548\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 140712, rl-loss: 0.39839136600494385\n",
      "----------------------------------------\n",
      "  timestep     |  140711\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 140864, rl-loss: 0.60582035779953\n",
      "----------------------------------------\n",
      "  timestep     |  140863\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141017, rl-loss: 0.502716064453125\n",
      "----------------------------------------\n",
      "  timestep     |  141016\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141181, rl-loss: 0.5048772096633911\n",
      "----------------------------------------\n",
      "  timestep     |  141180\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141335, rl-loss: 0.5188292860984802\n",
      "----------------------------------------\n",
      "  timestep     |  141334\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141493, rl-loss: 0.7349386215209961\n",
      "----------------------------------------\n",
      "  timestep     |  141492\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141639, rl-loss: 0.5061918497085571\n",
      "----------------------------------------\n",
      "  timestep     |  141638\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141786, rl-loss: 0.4039158523082733\n",
      "----------------------------------------\n",
      "  timestep     |  141785\n",
      "  reward       |  -0.138\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 141931, rl-loss: 0.7296909093856812\n",
      "----------------------------------------\n",
      "  timestep     |  141930\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142074, rl-loss: 0.39304420351982117\n",
      "----------------------------------------\n",
      "  timestep     |  142073\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142226, rl-loss: 0.48744997382164\n",
      "----------------------------------------\n",
      "  timestep     |  142225\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142381, rl-loss: 0.608559250831604\n",
      "----------------------------------------\n",
      "  timestep     |  142380\n",
      "  reward       |  0.018\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142535, rl-loss: 0.41811859607696533\n",
      "----------------------------------------\n",
      "  timestep     |  142534\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142686, rl-loss: 0.4894862771034241\n",
      "----------------------------------------\n",
      "  timestep     |  142685\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142841, rl-loss: 0.387459397315979\n",
      "----------------------------------------\n",
      "  timestep     |  142840\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 142981, rl-loss: 0.41338151693344116\n",
      "----------------------------------------\n",
      "  timestep     |  142980\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 143126, rl-loss: 0.45403027534484863\n",
      "----------------------------------------\n",
      "  timestep     |  143125\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 143273, rl-loss: 0.7053728699684143\n",
      "----------------------------------------\n",
      "  timestep     |  143272\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 143421, rl-loss: 0.6920396685600281\n",
      "----------------------------------------\n",
      "  timestep     |  143420\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 143568, rl-loss: 0.5706305503845215\n",
      "----------------------------------------\n",
      "  timestep     |  143567\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 143724, rl-loss: 0.5533004999160767\n",
      "----------------------------------------\n",
      "  timestep     |  143723\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 143877, rl-loss: 0.45890918374061584\n",
      "----------------------------------------\n",
      "  timestep     |  143876\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144022, rl-loss: 0.5202995538711548\n",
      "----------------------------------------\n",
      "  timestep     |  144021\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144160, rl-loss: 0.5297116637229919\n",
      "----------------------------------------\n",
      "  timestep     |  144159\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144307, rl-loss: 0.6414695382118225\n",
      "----------------------------------------\n",
      "  timestep     |  144306\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144465, rl-loss: 0.6595612168312073\n",
      "----------------------------------------\n",
      "  timestep     |  144464\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144594, rl-loss: 0.7539209127426147\n",
      "----------------------------------------\n",
      "  timestep     |  144593\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144734, rl-loss: 0.7253710031509399\n",
      "----------------------------------------\n",
      "  timestep     |  144733\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 144883, rl-loss: 0.605207085609436\n",
      "----------------------------------------\n",
      "  timestep     |  144882\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145036, rl-loss: 0.3723147213459015\n",
      "----------------------------------------\n",
      "  timestep     |  145035\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145190, rl-loss: 0.396657258272171\n",
      "----------------------------------------\n",
      "  timestep     |  145189\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145317, rl-loss: 0.3036166727542877\n",
      "----------------------------------------\n",
      "  timestep     |  145316\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145465, rl-loss: 0.4321180284023285\n",
      "----------------------------------------\n",
      "  timestep     |  145464\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145612, rl-loss: 0.3247814178466797\n",
      "----------------------------------------\n",
      "  timestep     |  145611\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145761, rl-loss: 0.602811872959137\n",
      "----------------------------------------\n",
      "  timestep     |  145760\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 145902, rl-loss: 0.5467169880867004\n",
      "----------------------------------------\n",
      "  timestep     |  145901\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146048, rl-loss: 0.625481367111206\n",
      "----------------------------------------\n",
      "  timestep     |  146047\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146201, rl-loss: 0.5397540330886841\n",
      "----------------------------------------\n",
      "  timestep     |  146200\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146344, rl-loss: 0.5150955319404602\n",
      "----------------------------------------\n",
      "  timestep     |  146343\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146495, rl-loss: 0.5026718378067017\n",
      "----------------------------------------\n",
      "  timestep     |  146494\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146641, rl-loss: 0.38763171434402466\n",
      "----------------------------------------\n",
      "  timestep     |  146640\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146788, rl-loss: 0.490536093711853\n",
      "----------------------------------------\n",
      "  timestep     |  146787\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 146934, rl-loss: 0.6350600719451904\n",
      "----------------------------------------\n",
      "  timestep     |  146933\n",
      "  reward       |  -0.134\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 147079, rl-loss: 0.42432156205177307\n",
      "----------------------------------------\n",
      "  timestep     |  147078\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent DQN-Agent, step 147228, rl-loss: 0.4925398528575897./experiments/blackjack_results_dqn/performance.csv\n",
      "odict_keys(['fc_layers.1.weight', 'fc_layers.1.bias', 'fc_layers.1.running_mean', 'fc_layers.1.running_var', 'fc_layers.1.num_batches_tracked', 'fc_layers.2.weight', 'fc_layers.2.bias', 'fc_layers.4.weight', 'fc_layers.4.bias', 'fc_layers.6.weight', 'fc_layers.6.bias'])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 400.523438 262.19625\" width=\"400.523438pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-27T19:32:41.643770</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 400.523438 262.19625 \nL 400.523438 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 58.523438 224.64 \nL 393.323438 224.64 \nL 393.323438 7.2 \nL 58.523438 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 73.73955 224.64 \nL 73.73955 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"md8d82f8f00\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.73955\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(70.5583 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 115.127889 224.64 \nL 115.127889 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"115.127889\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20000 -->\n      <g transform=\"translate(99.221639 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 156.516228 224.64 \nL 156.516228 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.516228\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40000 -->\n      <g transform=\"translate(140.609978 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 197.904567 224.64 \nL 197.904567 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.904567\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60000 -->\n      <g transform=\"translate(181.998317 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 239.292906 224.64 \nL 239.292906 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.292906\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80000 -->\n      <g transform=\"translate(223.386656 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 280.681245 224.64 \nL 280.681245 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"280.681245\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100000 -->\n      <g transform=\"translate(261.593745 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 322.069584 224.64 \nL 322.069584 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"322.069584\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120000 -->\n      <g transform=\"translate(302.982084 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 363.457923 224.64 \nL 363.457923 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.457923\" xlink:href=\"#md8d82f8f00\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140000 -->\n      <g transform=\"translate(344.370423 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- timestep -->\n     <g transform=\"translate(203.811719 252.916563)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"66.992188\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"164.404297\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"225.927734\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"278.027344\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"317.236328\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"378.759766\" xlink:href=\"#DejaVuSans-112\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 58.523438 221.661961 \nL 393.323438 221.661961 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m5bbd84553a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.523438\" xlink:href=\"#m5bbd84553a\" y=\"221.661961\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −0.20 -->\n      <g transform=\"translate(20.878125 225.46118)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 58.523438 178.501977 \nL 393.323438 178.501977 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.523438\" xlink:href=\"#m5bbd84553a\" y=\"178.501977\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −0.15 -->\n      <g transform=\"translate(20.878125 182.301196)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 58.523438 135.341993 \nL 393.323438 135.341993 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.523438\" xlink:href=\"#m5bbd84553a\" y=\"135.341993\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- −0.10 -->\n      <g transform=\"translate(20.878125 139.141212)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 58.523438 92.182009 \nL 393.323438 92.182009 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.523438\" xlink:href=\"#m5bbd84553a\" y=\"92.182009\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- −0.05 -->\n      <g transform=\"translate(20.878125 95.981227)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p2826b542ae)\" d=\"M 58.523438 49.022025 \nL 393.323438 49.022025 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.523438\" xlink:href=\"#m5bbd84553a\" y=\"49.022025\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.00 -->\n      <g transform=\"translate(29.257813 52.821243)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- reward -->\n     <g transform=\"translate(14.798438 133.234844)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"38.863281\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.386719\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"182.173828\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"243.453125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"282.816406\" xlink:href=\"#DejaVuSans-100\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p2826b542ae)\" d=\"M 73.741619 214.756364 \nL 74.283807 101.677205 \nL 74.559039 91.318809 \nL 74.854966 73.191616 \nL 75.140545 85.276411 \nL 75.444749 124.120397 \nL 75.742746 105.130004 \nL 76.026256 121.530798 \nL 76.324252 154.332386 \nL 76.595345 107.719603 \nL 76.870578 138.794792 \nL 77.137533 92.182009 \nL 77.427251 91.318809 \nL 77.702483 116.3516 \nL 77.983924 98.224407 \nL 78.255018 147.426788 \nL 78.53232 105.130004 \nL 79.111756 156.058785 \nL 79.405614 137.068392 \nL 79.711887 80.960413 \nL 79.999536 55.064422 \nL 80.280977 103.403605 \nL 80.587251 134.478793 \nL 80.852136 138.794792 \nL 81.148063 84.413212 \nL 81.458475 132.752394 \nL 81.739916 138.794792 \nL 82.04619 99.087606 \nL 82.325561 92.182009 \nL 82.627696 147.426788 \nL 82.946386 45.569226 \nL 83.238174 117.2148 \nL 83.513406 134.478793 \nL 83.798986 107.719603 \nL 84.086635 124.120397 \nL 84.380492 43.842827 \nL 84.697113 135.341993 \nL 84.984762 94.771608 \nL 85.257925 105.130004 \nL 85.543504 130.162795 \nL 85.8415 97.361207 \nL 86.133288 136.205193 \nL 86.449909 99.950806 \nL 86.735488 87.002811 \nL 87.037623 150.016387 \nL 87.345966 93.908408 \nL 87.648101 146.563589 \nL 87.950236 111.172402 \nL 88.242024 118.077999 \nL 88.53795 86.139611 \nL 88.835947 89.59241 \nL 89.119457 81.823613 \nL 89.715449 140.521191 \nL 90.003098 90.455609 \nL 90.305233 145.700389 \nL 90.588743 86.139611 \nL 90.878461 98.224407 \nL 91.155763 118.077999 \nL 91.424787 93.045208 \nL 91.695881 106.856403 \nL 91.98146 86.139611 \nL 92.242207 122.393998 \nL 92.533995 77.507614 \nL 92.827852 118.941199 \nL 93.105154 85.276411 \nL 93.415566 97.361207 \nL 93.732187 137.068392 \nL 94.009489 124.120397 \nL 94.292999 118.941199 \nL 94.593064 124.120397 \nL 94.882783 140.521191 \nL 95.172501 125.846796 \nL 95.468428 129.299595 \nL 95.749869 128.436395 \nL 96.070628 89.59241 \nL 96.362416 146.563589 \nL 96.689384 117.2148 \nL 97.266751 169.00678 \nL 97.550261 152.605987 \nL 97.87309 144.837189 \nL 98.467013 79.234013 \nL 98.773287 107.719603 \nL 99.08163 117.2148 \nL 99.383765 131.025994 \nL 99.712802 115.4884 \nL 100.035631 154.332386 \nL 100.335697 61.97002 \nL 100.631623 85.276411 \nL 100.929619 132.752394 \nL 101.240032 143.11079 \nL 101.540097 130.162795 \nL 101.846371 90.455609 \nL 102.142298 143.97399 \nL 102.436155 169.00678 \nL 103.077674 82.686812 \nL 103.346698 84.413212 \nL 103.957176 173.322779 \nL 104.240686 112.035601 \nL 104.538682 116.3516 \nL 104.855303 61.97002 \nL 105.15123 80.097213 \nL 105.451295 117.2148 \nL 105.769985 139.657991 \nL 106.082467 119.804399 \nL 106.388741 150.016387 \nL 106.726056 130.162795 \nL 107.03026 100.814006 \nL 107.359298 82.686812 \nL 107.663502 131.025994 \nL 108.232592 64.559619 \nL 108.52231 119.804399 \nL 108.824445 84.413212 \nL 109.155552 131.889194 \nL 109.465964 74.918015 \nL 109.792932 149.153188 \nL 110.134386 115.4884 \nL 110.47377 98.224407 \nL 110.809016 105.130004 \nL 111.131845 91.318809 \nL 111.43191 92.182009 \nL 111.703004 104.266804 \nL 112.003069 97.361207 \nL 112.298996 67.149218 \nL 112.582506 111.172402 \nL 112.903266 73.191616 \nL 113.230234 49.885224 \nL 113.532368 51.611624 \nL 114.16561 139.657991 \nL 114.473953 150.879587 \nL 114.776088 86.139611 \nL 115.113403 99.087606 \nL 115.427954 96.498007 \nL 115.736297 166.417181 \nL 116.044641 94.771608 \nL 116.346775 88.72921 \nL 116.661327 120.667598 \nL 116.942768 134.478793 \nL 117.257319 196.62917 \nL 117.551176 74.918015 \nL 117.847103 124.120397 \nL 118.165793 142.24759 \nL 118.492761 95.634807 \nL 118.78041 125.846796 \nL 119.086683 114.6252 \nL 119.407443 115.4884 \nL 119.719925 114.6252 \nL 120.317987 108.582803 \nL 120.640816 69.738817 \nL 120.988478 146.563589 \nL 121.286474 132.752394 \nL 121.580331 70.602017 \nL 121.90316 115.4884 \nL 122.207364 131.889194 \nL 122.515707 104.266804 \nL 122.840606 119.804399 \nL 123.153088 96.498007 \nL 123.469709 124.983597 \nL 123.780121 100.814006 \nL 124.080187 114.6252 \nL 124.394738 109.446002 \nL 124.688595 118.077999 \nL 125.007285 108.582803 \nL 125.313559 124.983597 \nL 125.613625 123.257197 \nL 125.940592 125.846796 \nL 126.265491 132.752394 \nL 126.582112 127.573196 \nL 126.888385 74.918015 \nL 127.198798 123.257197 \nL 127.4761 99.087606 \nL 127.784443 85.276411 \nL 128.086578 84.413212 \nL 128.394921 100.814006 \nL 128.719819 126.709996 \nL 129.013677 105.993204 \nL 129.295117 68.875617 \nL 129.617946 147.426788 \nL 129.913873 80.097213 \nL 130.205661 125.846796 \nL 130.511934 99.087606 \nL 130.805792 136.205193 \nL 131.387298 47.295625 \nL 131.701849 68.875617 \nL 132.008123 113.762001 \nL 132.306119 108.582803 \nL 132.610323 107.719603 \nL 132.914528 123.257197 \nL 133.247704 131.889194 \nL 133.574672 107.719603 \nL 133.883015 148.289988 \nL 134.222399 100.814006 \nL 134.541089 122.393998 \nL 134.853571 106.856403 \nL 135.161914 146.563589 \nL 135.755837 104.266804 \nL 136.055902 154.332386 \nL 136.351829 117.2148 \nL 136.927127 87.002811 \nL 137.218915 92.182009 \nL 137.533466 101.677205 \nL 137.852156 68.012418 \nL 138.150152 86.139611 \nL 138.452287 112.898801 \nL 138.750283 34.34763 \nL 139.079321 88.72921 \nL 139.420774 68.875617 \nL 139.724979 63.696419 \nL 140.312693 129.299595 \nL 140.616897 111.172402 \nL 141.219098 61.97002 \nL 141.77784 121.530798 \nL 142.073767 121.530798 \nL 142.38211 59.380421 \nL 142.996727 101.677205 \nL 143.290584 93.045208 \nL 143.609274 121.530798 \nL 143.925895 88.72921 \nL 144.267349 113.762001 \nL 144.575692 97.361207 \nL 144.871619 136.205193 \nL 145.175823 67.149218 \nL 145.502791 117.2148 \nL 145.806995 60.24362 \nL 146.104991 104.266804 \nL 146.398848 54.201223 \nL 146.698914 93.045208 \nL 147.003118 103.403605 \nL 147.290767 140.521191 \nL 147.603249 71.465216 \nL 147.91987 96.498007 \nL 148.528278 125.846796 \nL 148.84283 93.908408 \nL 149.128409 118.077999 \nL 149.395364 81.823613 \nL 149.651972 126.709996 \nL 149.933412 112.035601 \nL 150.198298 145.700389 \nL 150.477669 117.2148 \nL 150.742555 130.162795 \nL 151.013648 87.002811 \nL 151.32613 78.370814 \nL 151.653098 152.605987 \nL 151.957302 83.550012 \nL 152.244951 93.045208 \nL 152.5326 140.521191 \nL 152.843013 108.582803 \nL 153.45556 151.742787 \nL 154.086732 55.064422 \nL 154.411631 144.837189 \nL 154.738599 108.582803 \nL 155.049011 58.517221 \nL 155.33873 70.602017 \nL 155.673975 118.941199 \nL 155.980249 131.025994 \nL 156.280314 155.195586 \nL 156.576241 149.153188 \nL 156.847335 93.908408 \nL 157.130845 118.077999 \nL 157.439188 112.898801 \nL 157.722698 136.205193 \nL 158.049666 97.361207 \nL 158.701532 146.563589 \nL 159.005736 129.299595 \nL 159.31201 145.700389 \nL 159.636909 151.742787 \nL 159.928696 134.478793 \nL 160.512272 69.738817 \nL 160.818546 95.634807 \nL 161.124819 79.234013 \nL 161.455926 125.846796 \nL 161.735297 91.318809 \nL 162.053988 78.370814 \nL 162.349914 137.931592 \nL 162.668604 151.742787 \nL 162.981086 78.370814 \nL 163.274944 125.846796 \nL 163.581217 105.130004 \nL 163.870936 65.422819 \nL 164.4959 124.983597 \nL 164.802173 124.120397 \nL 165.100169 97.361207 \nL 165.410582 95.634807 \nL 165.725133 118.077999 \nL 166.010713 73.191616 \nL 166.94195 171.59638 \nL 167.248224 112.035601 \nL 167.587608 85.276411 \nL 167.898021 116.3516 \nL 168.198086 68.875617 \nL 168.496083 134.478793 \nL 168.82512 106.856403 \nL 169.137602 156.058785 \nL 169.460431 102.540405 \nL 169.754288 101.677205 \nL 170.068839 88.72921 \nL 170.377183 62.83322 \nL 170.683456 121.530798 \nL 170.983522 136.205193 \nL 171.291865 128.436395 \nL 171.589861 132.752394 \nL 171.879579 103.403605 \nL 172.202408 55.927622 \nL 172.475571 88.72921 \nL 172.781845 87.86601 \nL 173.08191 131.889194 \nL 173.379906 41.253227 \nL 174.516016 137.931592 \nL 174.82229 138.794792 \nL 175.130633 83.550012 \nL 175.443115 139.657991 \nL 175.776291 132.752394 \nL 176.113606 79.234013 \nL 176.41988 113.762001 \nL 176.77375 68.875617 \nL 177.051052 99.950806 \nL 177.357326 99.087606 \nL 177.642905 121.530798 \nL 177.918138 121.530798 \nL 178.207856 94.771608 \nL 178.501713 89.59241 \nL 178.812126 129.299595 \nL 179.430882 102.540405 \nL 179.751641 112.898801 \nL 180.072401 118.077999 \nL 180.71392 90.455609 \nL 181.022263 67.149218 \nL 181.332676 103.403605 \nL 181.667921 86.139611 \nL 181.980403 96.498007 \nL 182.330135 89.59241 \nL 182.66745 85.276411 \nL 182.979932 113.762001 \nL 183.273789 61.97002 \nL 183.569716 114.6252 \nL 183.87392 71.465216 \nL 184.176055 113.762001 \nL 184.492676 124.983597 \nL 184.780324 101.677205 \nL 185.055557 97.361207 \nL 185.320442 162.964383 \nL 185.603952 114.6252 \nL 185.879185 147.426788 \nL 186.17925 152.605987 \nL 186.452413 132.752394 \nL 186.725576 124.983597 \nL 187.03185 123.257197 \nL 187.31536 44.706026 \nL 187.652675 85.276411 \nL 187.971365 93.045208 \nL 188.277639 88.72921 \nL 188.585982 81.823613 \nL 188.91502 99.087606 \nL 189.237849 107.719603 \nL 189.550331 131.025994 \nL 189.87316 93.908408 \nL 190.183572 93.908408 \nL 190.791981 143.97399 \nL 191.108601 56.790822 \nL 191.429361 146.563589 \nL 191.739774 89.59241 \nL 192.075019 99.950806 \nL 192.397848 134.478793 \nL 192.704122 105.130004 \nL 193.026951 180.228376 \nL 193.335294 111.172402 \nL 193.645707 113.762001 \nL 193.972675 103.403605 \nL 194.299642 75.781215 \nL 194.62661 99.087606 \nL 194.951509 63.696419 \nL 195.280546 130.162795 \nL 195.590959 132.752394 \nL 195.922065 137.931592 \nL 196.251103 75.781215 \nL 196.540821 154.332386 \nL 196.845025 115.4884 \nL 197.200965 142.24759 \nL 197.486545 100.814006 \nL 197.830068 116.3516 \nL 198.150827 27.442033 \nL 198.475726 104.266804 \nL 198.773722 109.446002 \nL 199.74014 68.012418 \nL 200.069177 88.72921 \nL 200.394075 135.341993 \nL 200.741737 129.299595 \nL 201.062497 87.86601 \nL 201.391534 86.139611 \nL 201.699877 105.993204 \nL 202.020637 93.908408 \nL 202.335188 160.374784 \nL 202.645601 157.785185 \nL 202.978777 105.993204 \nL 203.270565 81.823613 \nL 203.585116 135.341993 \nL 203.907945 133.615593 \nL 204.220427 55.064422 \nL 204.84953 139.657991 \nL 205.13511 40.390028 \nL 205.447592 117.2148 \nL 206.039445 143.11079 \nL 206.320885 152.605987 \nL 206.573354 98.224407 \nL 206.869281 58.517221 \nL 207.190041 99.087606 \nL 207.496314 105.130004 \nL 207.790171 122.393998 \nL 208.092306 96.498007 \nL 208.413066 49.022025 \nL 208.727617 128.436395 \nL 209.017336 83.550012 \nL 209.338095 98.224407 \nL 209.64023 84.413212 \nL 209.948573 98.224407 \nL 210.242431 118.941199 \nL 210.552843 74.054815 \nL 210.840492 98.224407 \nL 211.126072 140.521191 \nL 211.424068 89.59241 \nL 211.709647 144.837189 \nL 212.015921 103.403605 \nL 212.305639 105.993204 \nL 212.613982 114.6252 \nL 212.895423 112.898801 \nL 213.183072 144.837189 \nL 213.478999 88.72921 \nL 213.776995 110.309202 \nL 214.089477 87.86601 \nL 214.404028 89.59241 \nL 214.706163 62.83322 \nL 214.993812 182.817975 \nL 215.291808 105.130004 \nL 215.60222 74.918015 \nL 215.943674 114.6252 \nL 216.249948 74.918015 \nL 216.554152 78.370814 \nL 216.858357 121.530798 \nL 217.160491 80.097213 \nL 217.454349 107.719603 \nL 217.748206 110.309202 \nL 218.066896 129.299595 \nL 218.37317 122.393998 \nL 218.689791 122.393998 \nL 218.991925 131.025994 \nL 219.306477 126.709996 \nL 219.604473 119.804399 \nL 219.921094 142.24759 \nL 220.237714 71.465216 \nL 221.129633 172.459579 \nL 221.419352 112.898801 \nL 221.731833 104.266804 \nL 222.042246 101.677205 \nL 222.679626 149.153188 \nL 223.302521 60.24362 \nL 223.610864 128.436395 \nL 223.898513 109.446002 \nL 224.204787 128.436395 \nL 224.469672 93.045208 \nL 224.757321 111.172402 \nL 225.057387 100.814006 \nL 225.355383 105.993204 \nL 225.64924 17.083636 \nL 225.965861 118.077999 \nL 226.278343 61.97002 \nL 226.578408 94.771608 \nL 226.866057 78.370814 \nL 227.193025 73.191616 \nL 227.486882 143.97399 \nL 227.786947 88.72921 \nL 228.376731 79.234013 \nL 228.695422 97.361207 \nL 229.007903 130.162795 \nL 229.312108 112.898801 \nL 229.605965 61.97002 \nL 229.897753 118.941199 \nL 230.195749 112.035601 \nL 230.487537 127.573196 \nL 230.802088 93.908408 \nL 231.087667 118.077999 \nL 231.731256 66.286018 \nL 232.35622 125.846796 \nL 232.658355 99.950806 \nL 232.991531 102.540405 \nL 233.289527 49.885224 \nL 233.614426 129.299595 \nL 233.941393 82.686812 \nL 234.245598 65.422819 \nL 234.553941 94.771608 \nL 234.858145 93.045208 \nL 235.452068 130.162795 \nL 236.062546 70.602017 \nL 236.656468 124.983597 \nL 236.948256 111.172402 \nL 237.244183 73.191616 \nL 237.560804 88.72921 \nL 238.204392 137.931592 \nL 238.521013 52.474823 \nL 238.829356 117.2148 \nL 239.141838 110.309202 \nL 239.448112 83.550012 \nL 239.750247 83.550012 \nL 240.087562 78.370814 \nL 240.397974 98.224407 \nL 240.729081 138.794792 \nL 241.064327 102.540405 \nL 241.397503 124.983597 \nL 241.734818 112.035601 \nL 242.070063 112.035601 \nL 242.359782 99.950806 \nL 242.645361 141.384391 \nL 242.966121 72.328416 \nL 243.282742 87.002811 \nL 243.601432 96.498007 \nL 243.934608 152.605987 \nL 244.226396 134.478793 \nL 244.526461 57.654021 \nL 245.136939 106.856403 \nL 245.445282 118.941199 \nL 245.766042 67.149218 \nL 246.051621 115.4884 \nL 246.357895 81.823613 \nL 246.649683 105.993204 \nL 246.939401 93.045208 \nL 247.494005 105.130004 \nL 247.806487 133.615593 \nL 248.087928 110.309202 \nL 248.383854 68.875617 \nL 248.696336 145.700389 \nL 248.988124 106.856403 \nL 249.300606 136.205193 \nL 249.60481 79.234013 \nL 250.200802 138.794792 \nL 250.513284 64.559619 \nL 250.831975 82.686812 \nL 251.140318 113.762001 \nL 251.432106 85.276411 \nL 251.744587 112.035601 \nL 252.032236 96.498007 \nL 252.336441 73.191616 \nL 252.636506 132.752394 \nL 252.936572 90.455609 \nL 253.22629 72.328416 \nL 253.495314 150.879587 \nL 253.780894 111.172402 \nL 254.07682 99.087606 \nL 254.370678 130.162795 \nL 254.666604 102.540405 \nL 254.9646 93.045208 \nL 255.264666 130.162795 \nL 255.577148 102.540405 \nL 255.875144 57.654021 \nL 256.169001 133.615593 \nL 256.483552 72.328416 \nL 256.793965 115.4884 \nL 257.104377 72.328416 \nL 257.375471 62.83322 \nL 257.681745 84.413212 \nL 257.973532 112.898801 \nL 258.271529 97.361207 \nL 258.596427 92.182009 \nL 258.913048 73.191616 \nL 259.227599 75.781215 \nL 259.531803 48.158825 \nL 259.842216 121.530798 \nL 260.154698 85.276411 \nL 260.452694 92.182009 \nL 260.765176 66.286018 \nL 261.06938 99.950806 \nL 261.379793 74.918015 \nL 261.646748 109.446002 \nL 261.934397 80.097213 \nL 262.224115 99.087606 \nL 262.528319 140.521191 \nL 262.813899 99.087606 \nL 263.132589 79.234013 \nL 263.438863 103.403605 \nL 263.759622 116.3516 \nL 264.047271 118.077999 \nL 264.353545 103.403605 \nL 264.657749 153.469186 \nL 264.964023 129.299595 \nL 265.247533 87.86601 \nL 265.572432 93.908408 \nL 265.872497 92.182009 \nL 266.195326 80.960413 \nL 266.5016 118.077999 \nL 266.814082 73.191616 \nL 267.107939 141.384391 \nL 267.432837 105.993204 \nL 268.045385 154.332386 \nL 268.349589 130.162795 \nL 268.655863 93.045208 \nL 268.964206 86.139611 \nL 269.27048 120.667598 \nL 269.568476 121.530798 \nL 269.864402 94.771608 \nL 270.185162 100.814006 \nL 270.493505 124.983597 \nL 270.820473 88.72921 \nL 271.139163 88.72921 \nL 271.437159 59.380421 \nL 271.770335 118.941199 \nL 272.07454 118.941199 \nL 272.389091 110.309202 \nL 272.722267 42.116427 \nL 273.024402 91.318809 \nL 273.322398 81.823613 \nL 273.630741 84.413212 \nL 273.95357 132.752394 \nL 274.251566 78.370814 \nL 274.586812 133.615593 \nL 274.899294 89.59241 \nL 275.224192 110.309202 \nL 275.526327 118.941199 \nL 275.840878 94.771608 \nL 276.130597 59.380421 \nL 276.472051 90.455609 \nL 276.801088 137.931592 \nL 277.101153 126.709996 \nL 277.403288 104.266804 \nL 278.011697 128.436395 \nL 278.315901 125.846796 \nL 278.597342 130.162795 \nL 278.918101 57.654021 \nL 279.203681 186.270774 \nL 279.474775 178.501977 \nL 279.758285 118.941199 \nL 280.050072 195.765971 \nL 280.348069 62.83322 \nL 280.635717 90.455609 \nL 280.944061 96.498007 \nL 281.211015 87.002811 \nL 281.813216 118.077999 \nL 282.115351 119.804399 \nL 282.409208 80.097213 \nL 282.717551 111.172402 \nL 283.009339 119.804399 \nL 283.321821 160.374784 \nL 283.621886 156.921985 \nL 283.938507 51.611624 \nL 284.257197 110.309202 \nL 284.582096 104.266804 \nL 284.894578 135.341993 \nL 285.190504 75.781215 \nL 285.478153 102.540405 \nL 285.784427 66.286018 \nL 286.119672 123.257197 \nL 286.421807 105.130004 \nL 286.728081 104.266804 \nL 287.030216 138.794792 \nL 287.338559 108.582803 \nL 287.659319 99.087606 \nL 287.959384 78.370814 \nL 288.255311 149.153188 \nL 288.545029 137.931592 \nL 288.843025 77.507614 \nL 289.138952 90.455609 \nL 289.453503 185.407574 \nL 289.755638 109.446002 \nL 290.06812 156.058785 \nL 290.345422 160.374784 \nL 290.63514 103.403605 \nL 290.95383 167.280381 \nL 291.258035 113.762001 \nL 291.59535 105.993204 \nL 291.940942 75.781215 \nL 292.249285 124.983597 \nL 292.561767 119.804399 \nL 292.874249 135.341993 \nL 293.182592 93.045208 \nL 293.478519 122.393998 \nL 293.774446 68.875617 \nL 294.045539 105.993204 \nL 294.314563 80.960413 \nL 294.604282 107.719603 \nL 294.875375 95.634807 \nL 295.156816 127.573196 \nL 295.446535 118.941199 \nL 295.732114 106.856403 \nL 296.005277 88.72921 \nL 296.301204 150.016387 \nL 296.613686 127.573196 \nL 296.911682 157.785185 \nL 297.228303 68.875617 \nL 297.511813 134.478793 \nL 297.818086 120.667598 \nL 298.136777 114.6252 \nL 298.44512 113.762001 \nL 298.741046 93.045208 \nL 299.059737 100.814006 \nL 299.388774 132.752394 \nL 299.715742 117.2148 \nL 300.030293 92.182009 \nL 300.340706 117.2148 \nL 300.663535 102.540405 \nL 300.976017 49.885224 \nL 301.274013 124.120397 \nL 301.572009 146.563589 \nL 301.882421 99.087606 \nL 302.182487 126.709996 \nL 302.49083 143.11079 \nL 302.803312 132.752394 \nL 303.122002 94.771608 \nL 303.432415 83.550012 \nL 303.734549 142.24759 \nL 304.071864 113.762001 \nL 304.394693 105.130004 \nL 304.707175 105.993204 \nL 305.001033 109.446002 \nL 305.29489 80.960413 \nL 305.905368 107.719603 \nL 306.195086 95.634807 \nL 306.482735 102.540405 \nL 306.782801 73.191616 \nL 307.091144 94.771608 \nL 307.407765 138.794792 \nL 307.714038 104.266804 \nL 307.99134 133.615593 \nL 308.326586 117.2148 \nL 308.616304 65.422819 \nL 308.9143 108.582803 \nL 309.195741 114.6252 \nL 309.508223 107.719603 \nL 309.814496 81.823613 \nL 310.141464 84.413212 \nL 310.453946 66.286018 \nL 310.766428 121.530798 \nL 311.103743 150.879587 \nL 311.43278 129.299595 \nL 311.743193 87.002811 \nL 312.353671 146.563589 \nL 312.651667 115.4884 \nL 312.949663 118.941199 \nL 313.249729 74.054815 \nL 313.545655 129.299595 \nL 313.858137 119.804399 \nL 314.170619 91.318809 \nL 314.491379 104.266804 \nL 314.799722 105.993204 \nL 315.114273 77.507614 \nL 315.432963 138.794792 \nL 315.743376 155.195586 \nL 316.064136 100.814006 \nL 316.322813 87.86601 \nL 316.606323 143.97399 \nL 316.877416 150.016387 \nL 317.142302 119.804399 \nL 317.413395 150.879587 \nL 317.698975 96.498007 \nL 317.994902 116.3516 \nL 318.315661 91.318809 \nL 318.60538 55.064422 \nL 318.905445 49.885224 \nL 319.209649 100.814006 \nL 319.499368 101.677205 \nL 319.820127 98.224407 \nL 320.13054 127.573196 \nL 320.428536 74.918015 \nL 320.722393 112.898801 \nL 321.028667 120.667598 \nL 321.353565 105.130004 \nL 321.647423 70.602017 \nL 321.964043 150.016387 \nL 322.291011 78.370814 \nL 322.603493 113.762001 \nL 322.905628 46.432426 \nL 323.213971 119.804399 \nL 323.524384 68.012418 \nL 323.828588 74.054815 \nL 324.153486 87.86601 \nL 324.478385 87.86601 \nL 324.801214 84.413212 \nL 325.095071 142.24759 \nL 325.397206 87.86601 \nL 325.709688 109.446002 \nL 326.032517 143.11079 \nL 326.34293 147.426788 \nL 326.628509 143.11079 \nL 326.920297 102.540405 \nL 327.224501 118.941199 \nL 327.545261 124.983597 \nL 327.861882 94.771608 \nL 328.157808 102.540405 \nL 328.466151 120.667598 \nL 328.784842 114.6252 \nL 329.095254 66.286018 \nL 329.364278 122.393998 \nL 329.647788 131.889194 \nL 329.956132 129.299595 \nL 330.258266 80.960413 \nL 330.550054 142.24759 \nL 330.839773 152.605987 \nL 331.16674 101.677205 \nL 331.470945 118.077999 \nL 331.787566 116.3516 \nL 332.095909 117.2148 \nL 332.400113 136.205193 \nL 332.716734 30.031632 \nL 333.01473 51.611624 \nL 333.310656 120.667598 \nL 333.610722 44.706026 \nL 334.18395 121.530798 \nL 334.477808 76.644414 \nL 334.767526 103.403605 \nL 335.046897 109.446002 \nL 335.628403 191.449972 \nL 335.918122 129.299595 \nL 336.214048 105.130004 \nL 336.532739 100.814006 \nL 336.828665 137.931592 \nL 337.103898 133.615593 \nL 337.422588 110.309202 \nL 337.718515 156.058785 \nL 338.014441 95.634807 \nL 338.318645 133.615593 \nL 338.631127 150.016387 \nL 338.939471 93.045208 \nL 339.245744 147.426788 \nL 339.554087 111.172402 \nL 339.850014 123.257197 \nL 340.150079 124.983597 \nL 340.741933 104.266804 \nL 341.07097 162.101183 \nL 341.352411 126.709996 \nL 341.652476 117.2148 \nL 341.962889 76.644414 \nL 342.265024 87.86601 \nL 342.556811 150.879587 \nL 342.827905 105.130004 \nL 343.140387 84.413212 \nL 343.461147 87.86601 \nL 343.779837 160.374784 \nL 344.413078 87.86601 \nL 344.72556 114.6252 \nL 345.023556 113.762001 \nL 345.315344 127.573196 \nL 345.627826 126.709996 \nL 346.240374 88.72921 \nL 346.552855 109.446002 \nL 346.846713 113.762001 \nL 347.152986 126.709996 \nL 347.728284 57.654021 \nL 348.024211 87.86601 \nL 348.334623 81.823613 \nL 348.640897 154.332386 \nL 348.940963 92.182009 \nL 349.243098 77.507614 \nL 349.555579 146.563589 \nL 349.8722 94.771608 \nL 350.168127 80.960413 \nL 350.466123 79.234013 \nL 350.778605 99.087606 \nL 351.101434 111.172402 \nL 351.420124 66.286018 \nL 351.751231 59.380421 \nL 352.076129 110.309202 \nL 352.423791 116.3516 \nL 352.709371 155.195586 \nL 353.005298 150.879587 \nL 353.326057 95.634807 \nL 353.653025 105.993204 \nL 353.998618 93.045208 \nL 354.313169 113.762001 \nL 354.654623 153.469186 \nL 354.979521 131.025994 \nL 355.323045 68.012418 \nL 355.645874 59.380421 \nL 355.929384 148.289988 \nL 356.233588 121.530798 \nL 356.554348 115.4884 \nL 356.862691 77.507614 \nL 357.460752 137.931592 \nL 357.762887 96.498007 \nL 358.085716 109.446002 \nL 358.367157 115.4884 \nL 358.642389 98.224407 \nL 358.977635 88.72921 \nL 359.271492 131.889194 \nL 359.567419 117.2148 \nL 359.886109 87.002811 \nL 360.190313 107.719603 \nL 360.496587 80.960413 \nL 360.782166 144.837189 \nL 361.078093 134.478793 \nL 361.392644 80.960413 \nL 361.698918 114.6252 \nL 362.032094 99.950806 \nL 362.340437 101.677205 \nL 362.657058 105.130004 \nL 362.981957 114.6252 \nL 363.321341 129.299595 \nL 363.648309 44.706026 \nL 363.948374 112.898801 \nL 364.591963 75.781215 \nL 364.929278 110.309202 \nL 365.243829 98.224407 \nL 365.899835 84.413212 \nL 366.218525 74.054815 \nL 366.545493 146.563589 \nL 366.847627 90.455609 \nL 367.151832 168.143581 \nL 367.451897 57.654021 \nL 367.747824 135.341993 \nL 368.383135 33.48443 \nL 368.701825 124.120397 \nL 369.014307 140.521191 \nL 369.335067 91.318809 \nL 369.624785 137.068392 \nL 369.92485 96.498007 \nL 370.229055 109.446002 \nL 370.535328 112.035601 \nL 370.839533 121.530798 \nL 371.162362 100.814006 \nL 371.478983 99.087606 \nL 371.779048 80.097213 \nL 372.064628 89.59241 \nL 372.368832 70.602017 \nL 372.6958 145.700389 \nL 372.962755 79.234013 \nL 373.252473 105.130004 \nL 373.560816 143.11079 \nL 373.877437 120.667598 \nL 374.196127 111.172402 \nL 374.458943 82.686812 \nL 374.765217 109.446002 \nL 375.069421 104.266804 \nL 375.377764 74.054815 \nL 375.669552 117.2148 \nL 375.971687 87.86601 \nL 376.288308 110.309202 \nL 376.584234 115.4884 \nL 376.896716 143.97399 \nL 377.198851 91.318809 \nL 377.80519 164.690782 \nL 378.105256 106.856403 \nL 378.105256 106.856403 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 58.523438 224.64 \nL 58.523438 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 393.323438 224.64 \nL 393.323438 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 58.523438 224.64 \nL 393.323438 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 58.523438 7.2 \nL 393.323438 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 331.270313 29.878125 \nL 386.323438 29.878125 \nQ 388.323438 29.878125 388.323438 27.878125 \nL 388.323438 14.2 \nQ 388.323438 12.2 386.323438 12.2 \nL 331.270313 12.2 \nQ 329.270313 12.2 329.270313 14.2 \nL 329.270313 27.878125 \nQ 329.270313 29.878125 331.270313 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 333.270313 20.298438 \nL 353.270313 20.298438 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_29\"/>\n    <g id=\"text_16\">\n     <!-- DQN -->\n     <g transform=\"translate(361.270313 23.798438)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n       <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 53.21875 1.3125 \nL 66.21875 -12.890625 \nL 54.296875 -12.890625 \nL 43.5 -1.21875 \nQ 41.890625 -1.3125 41.03125 -1.359375 \nQ 40.1875 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.859375 \nQ 5.609375 19.140625 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 23.6875 67.984375 14.640625 \nQ 62.890625 5.609375 53.21875 1.3125 \nz\n\" id=\"DejaVuSans-81\"/>\n       <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-81\"/>\n      <use x=\"155.712891\" xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p2826b542ae\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"58.523438\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import rlcard\n",
    "from rlcard.agents import RandomAgent,DQN_agent,DQN_conf\n",
    "from rlcard.utils import set_global_seed, tournament\n",
    "from rlcard.utils import Logger\n",
    "\n",
    "# Make environment\n",
    "env = rlcard.make('blackjack', config={'seed': 0})\n",
    "eval_env = rlcard.make('blackjack', config={'seed': 0})\n",
    "\n",
    "# Set the iterations numbers and how frequently we evaluate the performance\n",
    "evaluate_every = 100\n",
    "evaluate_num = 1000\n",
    "episode_num = 100000\n",
    "\n",
    "# The intial memory size\n",
    "memory_init_size = 1000\n",
    "\n",
    "# Train the agent every X steps\n",
    "train_every = 100\n",
    "\n",
    "# The paths for saving the logs and learning curves\n",
    "log_dir = './experiments/blackjack_results_dqn/'\n",
    "\n",
    "# Set a global seed\n",
    "set_global_seed(0)\n",
    "\n",
    "params = {\n",
    "    \"scope\":\"DQN-Agent\",\n",
    "    \"num_actions\":env.action_num,\n",
    "    \"replay_memory_size\":memory_init_size,\n",
    "    \"num_states\":env.state_shape,\n",
    "    \"discount_factor\" :0.99,\n",
    "    \"epsilon_start\" : 1.0,\n",
    "    \"epsilon_end\" : 0.1,\n",
    "    \"epsilon_decay_steps\":20000,\n",
    "    \"batch_size\":32,\n",
    "    \"train_every\":1,\n",
    "    \"mlp_layers\":[128,128],\n",
    "    \"lr\":0.0005,\n",
    "}\n",
    "\n",
    "agent_conf = DQN_conf(**params)\n",
    "agent = DQN_agent(agent_conf)\n",
    "\n",
    "random_agent = RandomAgent(action_num=eval_env.action_num)\n",
    "env.set_agents([agent, random_agent])\n",
    "eval_env.set_agents([agent, random_agent])\n",
    "\n",
    "logger = Logger(log_dir)\n",
    "\n",
    "for episode in range(episode_num):\n",
    "\n",
    "    # Generate data from the environment\n",
    "    trajectories, _ = env.run(is_training=True)\n",
    "\n",
    "    # Feed transitions into agent memory, and train the agent\n",
    "    for ts in trajectories[0]:\n",
    "        agent.feed(ts)\n",
    "\n",
    "    # Evaluate the performance. Play with random agents.\n",
    "    if episode % evaluate_every == 0:\n",
    "        logger.log_performance(env.timestep, tournament(eval_env, evaluate_num)[0])\n",
    "\n",
    "# Close files in the logger\n",
    "logger.close_files()\n",
    "\n",
    "# Plot the learning curve\n",
    "logger.plot('DQN')\n",
    "\n",
    "# Save model\n",
    "save_dir = 'models/blackjack_holdem_dqn_pytorch'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "state_dict = agent.get_state_dict()\n",
    "print(state_dict. keys())\n",
    "torch.save(state_dict, os.path.join(save_dir, 'model.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-0.083]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# random_eval_env = rlcard.make('blackjack', config={'seed': 0})\n",
    "\n",
    "# random_agent = RandomAgent(action_num=random_eval_env.action_num)\n",
    "# random_agent1 = RandomAgent(action_num=random_eval_env.action_num)\n",
    "# random_eval_env.set_agents([random_agent, random_agent1])\n",
    "\n",
    "tournament(eval_env, evaluate_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 8822, rl-loss: 0.6383684277534485\n",
      "----------------------------------------\n",
      "  timestep     |  8822\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 8972, rl-loss: 0.6946665048599243\n",
      "----------------------------------------\n",
      "  timestep     |  8972\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9000, rl-loss: 0.6681729555130005\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 9117, rl-loss: 0.4756609797477722\n",
      "----------------------------------------\n",
      "  timestep     |  9117\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9246, rl-loss: 0.9114235639572144\n",
      "----------------------------------------\n",
      "  timestep     |  9246\n",
      "  reward       |  -0.019\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9383, rl-loss: 0.5044817924499512\n",
      "----------------------------------------\n",
      "  timestep     |  9383\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9539, rl-loss: 0.5713594555854797\n",
      "----------------------------------------\n",
      "  timestep     |  9539\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9681, rl-loss: 0.5824116468429565\n",
      "----------------------------------------\n",
      "  timestep     |  9681\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9820, rl-loss: 0.4212304353713989\n",
      "----------------------------------------\n",
      "  timestep     |  9820\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 9954, rl-loss: 0.4730595350265503\n",
      "----------------------------------------\n",
      "  timestep     |  9954\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10000, rl-loss: 0.6416944265365601\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 10094, rl-loss: 0.526995837688446\n",
      "----------------------------------------\n",
      "  timestep     |  10094\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10238, rl-loss: 0.48896095156669617\n",
      "----------------------------------------\n",
      "  timestep     |  10238\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10376, rl-loss: 0.48137179017066956\n",
      "----------------------------------------\n",
      "  timestep     |  10376\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10518, rl-loss: 0.5624178647994995\n",
      "----------------------------------------\n",
      "  timestep     |  10518\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10660, rl-loss: 0.6229267120361328\n",
      "----------------------------------------\n",
      "  timestep     |  10660\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10805, rl-loss: 0.3341096043586731\n",
      "----------------------------------------\n",
      "  timestep     |  10805\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 10951, rl-loss: 0.5296563506126404\n",
      "----------------------------------------\n",
      "  timestep     |  10951\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11000, rl-loss: 0.3953483998775482\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 11095, rl-loss: 0.36763861775398254\n",
      "----------------------------------------\n",
      "  timestep     |  11095\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11229, rl-loss: 0.9521814584732056\n",
      "----------------------------------------\n",
      "  timestep     |  11229\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11370, rl-loss: 0.3648500144481659\n",
      "----------------------------------------\n",
      "  timestep     |  11370\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11524, rl-loss: 0.3565528690814972\n",
      "----------------------------------------\n",
      "  timestep     |  11524\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11678, rl-loss: 0.6339417695999146\n",
      "----------------------------------------\n",
      "  timestep     |  11678\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11834, rl-loss: 0.39072439074516296\n",
      "----------------------------------------\n",
      "  timestep     |  11834\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 11980, rl-loss: 0.4741780161857605\n",
      "----------------------------------------\n",
      "  timestep     |  11980\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 12000, rl-loss: 0.9571968913078308\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 12125, rl-loss: 0.6006917357444763\n",
      "----------------------------------------\n",
      "  timestep     |  12125\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 12270, rl-loss: 0.4457610249519348\n",
      "----------------------------------------\n",
      "  timestep     |  12270\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 12423, rl-loss: 0.480906218290329\n",
      "----------------------------------------\n",
      "  timestep     |  12423\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 12576, rl-loss: 0.6051181554794312\n",
      "----------------------------------------\n",
      "  timestep     |  12576\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 12719, rl-loss: 0.5527645349502563\n",
      "----------------------------------------\n",
      "  timestep     |  12719\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 12861, rl-loss: 0.41777318716049194\n",
      "----------------------------------------\n",
      "  timestep     |  12861\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13000, rl-loss: 0.6294669508934021\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 13005, rl-loss: 0.5660771727561951\n",
      "----------------------------------------\n",
      "  timestep     |  13005\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13149, rl-loss: 0.5634987950325012\n",
      "----------------------------------------\n",
      "  timestep     |  13149\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13294, rl-loss: 0.5900439620018005\n",
      "----------------------------------------\n",
      "  timestep     |  13294\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13427, rl-loss: 0.583317756652832\n",
      "----------------------------------------\n",
      "  timestep     |  13427\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13566, rl-loss: 0.40310806035995483\n",
      "----------------------------------------\n",
      "  timestep     |  13566\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13703, rl-loss: 0.39550384879112244\n",
      "----------------------------------------\n",
      "  timestep     |  13703\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13844, rl-loss: 0.41610661149024963\n",
      "----------------------------------------\n",
      "  timestep     |  13844\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 13994, rl-loss: 0.4215497672557831\n",
      "----------------------------------------\n",
      "  timestep     |  13994\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 14000, rl-loss: 0.7928565144538879\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 14132, rl-loss: 0.5359743237495422\n",
      "----------------------------------------\n",
      "  timestep     |  14132\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 14278, rl-loss: 0.41422975063323975\n",
      "----------------------------------------\n",
      "  timestep     |  14278\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 14432, rl-loss: 0.7031428813934326\n",
      "----------------------------------------\n",
      "  timestep     |  14432\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 14591, rl-loss: 0.260771781206131\n",
      "----------------------------------------\n",
      "  timestep     |  14591\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 14739, rl-loss: 0.7712999582290649\n",
      "----------------------------------------\n",
      "  timestep     |  14739\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 14897, rl-loss: 0.41532424092292786\n",
      "----------------------------------------\n",
      "  timestep     |  14897\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15000, rl-loss: 0.5421345829963684\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 15048, rl-loss: 0.42987746000289917\n",
      "----------------------------------------\n",
      "  timestep     |  15048\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15191, rl-loss: 0.5567099452018738\n",
      "----------------------------------------\n",
      "  timestep     |  15191\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15331, rl-loss: 0.7800790071487427\n",
      "----------------------------------------\n",
      "  timestep     |  15331\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15479, rl-loss: 0.49194812774658203\n",
      "----------------------------------------\n",
      "  timestep     |  15479\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15621, rl-loss: 0.39778998494148254\n",
      "----------------------------------------\n",
      "  timestep     |  15621\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15763, rl-loss: 0.5612637400627136\n",
      "----------------------------------------\n",
      "  timestep     |  15763\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 15914, rl-loss: 0.4938235878944397\n",
      "----------------------------------------\n",
      "  timestep     |  15914\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16000, rl-loss: 0.7207598686218262\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 16063, rl-loss: 0.49932265281677246\n",
      "----------------------------------------\n",
      "  timestep     |  16063\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16202, rl-loss: 0.4001595675945282\n",
      "----------------------------------------\n",
      "  timestep     |  16202\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16345, rl-loss: 0.7096237540245056\n",
      "----------------------------------------\n",
      "  timestep     |  16345\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16484, rl-loss: 0.6845089197158813\n",
      "----------------------------------------\n",
      "  timestep     |  16484\n",
      "  reward       |  -0.006\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16638, rl-loss: 0.434475839138031\n",
      "----------------------------------------\n",
      "  timestep     |  16638\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16797, rl-loss: 0.6356459856033325\n",
      "----------------------------------------\n",
      "  timestep     |  16797\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 16959, rl-loss: 0.347741037607193\n",
      "----------------------------------------\n",
      "  timestep     |  16959\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 17000, rl-loss: 0.5133082866668701\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 17113, rl-loss: 0.3667328953742981\n",
      "----------------------------------------\n",
      "  timestep     |  17113\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 17266, rl-loss: 0.5867167115211487\n",
      "----------------------------------------\n",
      "  timestep     |  17266\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 17426, rl-loss: 0.5037379264831543\n",
      "----------------------------------------\n",
      "  timestep     |  17426\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 17585, rl-loss: 0.5619378089904785\n",
      "----------------------------------------\n",
      "  timestep     |  17585\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 17730, rl-loss: 0.43137142062187195\n",
      "----------------------------------------\n",
      "  timestep     |  17730\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 17881, rl-loss: 0.5473577976226807\n",
      "----------------------------------------\n",
      "  timestep     |  17881\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18000, rl-loss: 0.40723058581352234\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 18029, rl-loss: 0.4559052884578705\n",
      "----------------------------------------\n",
      "  timestep     |  18029\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18167, rl-loss: 0.5764806866645813\n",
      "----------------------------------------\n",
      "  timestep     |  18167\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18315, rl-loss: 0.3679303824901581\n",
      "----------------------------------------\n",
      "  timestep     |  18315\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18452, rl-loss: 0.5819649696350098\n",
      "----------------------------------------\n",
      "  timestep     |  18452\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18595, rl-loss: 0.5465882420539856\n",
      "----------------------------------------\n",
      "  timestep     |  18595\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18741, rl-loss: 0.5123838782310486\n",
      "----------------------------------------\n",
      "  timestep     |  18741\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 18896, rl-loss: 0.7032471299171448\n",
      "----------------------------------------\n",
      "  timestep     |  18896\n",
      "  reward       |  0.009\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19000, rl-loss: 0.5234530568122864\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 19038, rl-loss: 0.7804789543151855\n",
      "----------------------------------------\n",
      "  timestep     |  19038\n",
      "  reward       |  0.015\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19179, rl-loss: 0.38788753747940063\n",
      "----------------------------------------\n",
      "  timestep     |  19179\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19330, rl-loss: 0.6479536294937134\n",
      "----------------------------------------\n",
      "  timestep     |  19330\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19467, rl-loss: 0.6575186848640442\n",
      "----------------------------------------\n",
      "  timestep     |  19467\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19605, rl-loss: 0.41031038761138916\n",
      "----------------------------------------\n",
      "  timestep     |  19605\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19763, rl-loss: 0.7602071762084961\n",
      "----------------------------------------\n",
      "  timestep     |  19763\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 19910, rl-loss: 0.5664952397346497\n",
      "----------------------------------------\n",
      "  timestep     |  19910\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20000, rl-loss: 0.41946712136268616\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 20065, rl-loss: 0.46168676018714905\n",
      "----------------------------------------\n",
      "  timestep     |  20065\n",
      "  reward       |  -0.137\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20216, rl-loss: 0.656029462814331\n",
      "----------------------------------------\n",
      "  timestep     |  20216\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20360, rl-loss: 0.5700312256813049\n",
      "----------------------------------------\n",
      "  timestep     |  20360\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20512, rl-loss: 0.45780205726623535\n",
      "----------------------------------------\n",
      "  timestep     |  20512\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20659, rl-loss: 0.349019855260849\n",
      "----------------------------------------\n",
      "  timestep     |  20659\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20814, rl-loss: 0.4283068776130676\n",
      "----------------------------------------\n",
      "  timestep     |  20814\n",
      "  reward       |  -0.145\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 20959, rl-loss: 0.679060697555542\n",
      "----------------------------------------\n",
      "  timestep     |  20959\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21000, rl-loss: 0.4743402898311615\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 21098, rl-loss: 0.4266018569469452\n",
      "----------------------------------------\n",
      "  timestep     |  21098\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21248, rl-loss: 0.5563899278640747\n",
      "----------------------------------------\n",
      "  timestep     |  21248\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21398, rl-loss: 0.43885430693626404\n",
      "----------------------------------------\n",
      "  timestep     |  21398\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21539, rl-loss: 0.6981074810028076\n",
      "----------------------------------------\n",
      "  timestep     |  21539\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21690, rl-loss: 0.49369239807128906\n",
      "----------------------------------------\n",
      "  timestep     |  21690\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21843, rl-loss: 0.42402389645576477\n",
      "----------------------------------------\n",
      "  timestep     |  21843\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 21995, rl-loss: 0.5380582809448242\n",
      "----------------------------------------\n",
      "  timestep     |  21995\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 22000, rl-loss: 0.5134169459342957\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 22145, rl-loss: 0.6357209086418152\n",
      "----------------------------------------\n",
      "  timestep     |  22145\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 22287, rl-loss: 0.6961073875427246\n",
      "----------------------------------------\n",
      "  timestep     |  22287\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 22444, rl-loss: 0.5675286650657654\n",
      "----------------------------------------\n",
      "  timestep     |  22444\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 22613, rl-loss: 0.6050318479537964\n",
      "----------------------------------------\n",
      "  timestep     |  22613\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 22752, rl-loss: 0.46610116958618164\n",
      "----------------------------------------\n",
      "  timestep     |  22752\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 22894, rl-loss: 0.5514200925827026\n",
      "----------------------------------------\n",
      "  timestep     |  22894\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23000, rl-loss: 0.5507330894470215\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 23053, rl-loss: 0.4420377016067505\n",
      "----------------------------------------\n",
      "  timestep     |  23053\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23204, rl-loss: 0.4750775992870331\n",
      "----------------------------------------\n",
      "  timestep     |  23204\n",
      "  reward       |  -0.115\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23357, rl-loss: 0.4634493291378021\n",
      "----------------------------------------\n",
      "  timestep     |  23357\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23513, rl-loss: 0.4197925329208374\n",
      "----------------------------------------\n",
      "  timestep     |  23513\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23663, rl-loss: 0.5186666250228882\n",
      "----------------------------------------\n",
      "  timestep     |  23663\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23815, rl-loss: 0.6098437905311584\n",
      "----------------------------------------\n",
      "  timestep     |  23815\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 23954, rl-loss: 0.6482745409011841\n",
      "----------------------------------------\n",
      "  timestep     |  23954\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24000, rl-loss: 0.5081185102462769\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 24086, rl-loss: 0.5452418923377991\n",
      "----------------------------------------\n",
      "  timestep     |  24086\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24236, rl-loss: 0.3863269090652466\n",
      "----------------------------------------\n",
      "  timestep     |  24236\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24381, rl-loss: 0.7190631628036499\n",
      "----------------------------------------\n",
      "  timestep     |  24381\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24536, rl-loss: 0.42007625102996826\n",
      "----------------------------------------\n",
      "  timestep     |  24536\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24665, rl-loss: 0.6201708316802979\n",
      "----------------------------------------\n",
      "  timestep     |  24665\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24807, rl-loss: 0.546379566192627\n",
      "----------------------------------------\n",
      "  timestep     |  24807\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 24955, rl-loss: 0.5486816167831421\n",
      "----------------------------------------\n",
      "  timestep     |  24955\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25000, rl-loss: 0.5811067223548889\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 25097, rl-loss: 0.7462328672409058\n",
      "----------------------------------------\n",
      "  timestep     |  25097\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25245, rl-loss: 0.4611572325229645\n",
      "----------------------------------------\n",
      "  timestep     |  25245\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25390, rl-loss: 0.39148303866386414\n",
      "----------------------------------------\n",
      "  timestep     |  25390\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25539, rl-loss: 0.5321072936058044\n",
      "----------------------------------------\n",
      "  timestep     |  25539\n",
      "  reward       |  -0.115\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25680, rl-loss: 0.5600191950798035\n",
      "----------------------------------------\n",
      "  timestep     |  25680\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25830, rl-loss: 0.6038178205490112\n",
      "----------------------------------------\n",
      "  timestep     |  25830\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 25972, rl-loss: 0.592828631401062\n",
      "----------------------------------------\n",
      "  timestep     |  25972\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 26000, rl-loss: 0.4975801706314087\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 26119, rl-loss: 0.4625745415687561\n",
      "----------------------------------------\n",
      "  timestep     |  26119\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 26280, rl-loss: 0.4123559296131134\n",
      "----------------------------------------\n",
      "  timestep     |  26280\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 26418, rl-loss: 0.583088219165802\n",
      "----------------------------------------\n",
      "  timestep     |  26418\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 26560, rl-loss: 0.6344163417816162\n",
      "----------------------------------------\n",
      "  timestep     |  26560\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 26714, rl-loss: 0.3927677571773529\n",
      "----------------------------------------\n",
      "  timestep     |  26714\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 26855, rl-loss: 0.3855170011520386\n",
      "----------------------------------------\n",
      "  timestep     |  26855\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27000, rl-loss: 0.4207361340522766\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 27004, rl-loss: 0.6663638353347778\n",
      "----------------------------------------\n",
      "  timestep     |  27004\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27162, rl-loss: 0.46559709310531616\n",
      "----------------------------------------\n",
      "  timestep     |  27162\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27310, rl-loss: 0.5219944715499878\n",
      "----------------------------------------\n",
      "  timestep     |  27310\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27437, rl-loss: 0.5226051211357117\n",
      "----------------------------------------\n",
      "  timestep     |  27437\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27583, rl-loss: 0.4688742458820343\n",
      "----------------------------------------\n",
      "  timestep     |  27583\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27739, rl-loss: 0.41549015045166016\n",
      "----------------------------------------\n",
      "  timestep     |  27739\n",
      "  reward       |  0.002\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 27884, rl-loss: 0.34660306572914124\n",
      "----------------------------------------\n",
      "  timestep     |  27884\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28000, rl-loss: 0.6300300359725952\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 28032, rl-loss: 0.3778543770313263\n",
      "----------------------------------------\n",
      "  timestep     |  28032\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28172, rl-loss: 0.4883948266506195\n",
      "----------------------------------------\n",
      "  timestep     |  28172\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28310, rl-loss: 0.4941193759441376\n",
      "----------------------------------------\n",
      "  timestep     |  28310\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28448, rl-loss: 0.4164991080760956\n",
      "----------------------------------------\n",
      "  timestep     |  28448\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28585, rl-loss: 0.5616000890731812\n",
      "----------------------------------------\n",
      "  timestep     |  28585\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28720, rl-loss: 0.5195302963256836\n",
      "----------------------------------------\n",
      "  timestep     |  28720\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 28864, rl-loss: 0.6901658177375793\n",
      "----------------------------------------\n",
      "  timestep     |  28864\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29000, rl-loss: 0.6714895367622375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 29009, rl-loss: 0.6548612117767334\n",
      "----------------------------------------\n",
      "  timestep     |  29009\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29158, rl-loss: 0.4140113890171051\n",
      "----------------------------------------\n",
      "  timestep     |  29158\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29309, rl-loss: 0.5106744766235352\n",
      "----------------------------------------\n",
      "  timestep     |  29309\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29466, rl-loss: 0.41108861565589905\n",
      "----------------------------------------\n",
      "  timestep     |  29466\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29616, rl-loss: 0.4014550745487213\n",
      "----------------------------------------\n",
      "  timestep     |  29616\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29758, rl-loss: 0.6120678782463074\n",
      "----------------------------------------\n",
      "  timestep     |  29758\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 29900, rl-loss: 0.4595271348953247\n",
      "----------------------------------------\n",
      "  timestep     |  29900\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30000, rl-loss: 0.5994257926940918\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 30047, rl-loss: 0.5523245334625244\n",
      "----------------------------------------\n",
      "  timestep     |  30047\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30187, rl-loss: 0.44327303767204285\n",
      "----------------------------------------\n",
      "  timestep     |  30187\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30336, rl-loss: 0.5996202230453491\n",
      "----------------------------------------\n",
      "  timestep     |  30336\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30491, rl-loss: 0.813250720500946\n",
      "----------------------------------------\n",
      "  timestep     |  30491\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30649, rl-loss: 0.8405657410621643\n",
      "----------------------------------------\n",
      "  timestep     |  30649\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30790, rl-loss: 0.4696427285671234\n",
      "----------------------------------------\n",
      "  timestep     |  30790\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 30945, rl-loss: 0.41059255599975586\n",
      "----------------------------------------\n",
      "  timestep     |  30945\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31000, rl-loss: 0.5122725367546082\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 31093, rl-loss: 0.5013862252235413\n",
      "----------------------------------------\n",
      "  timestep     |  31093\n",
      "  reward       |  0.012\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31246, rl-loss: 0.5020685195922852\n",
      "----------------------------------------\n",
      "  timestep     |  31246\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31410, rl-loss: 0.4980679750442505\n",
      "----------------------------------------\n",
      "  timestep     |  31410\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31559, rl-loss: 0.6493764519691467\n",
      "----------------------------------------\n",
      "  timestep     |  31559\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31699, rl-loss: 0.3209749460220337\n",
      "----------------------------------------\n",
      "  timestep     |  31699\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31843, rl-loss: 0.6439993977546692\n",
      "----------------------------------------\n",
      "  timestep     |  31843\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 31992, rl-loss: 0.5681086182594299\n",
      "----------------------------------------\n",
      "  timestep     |  31992\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 32000, rl-loss: 0.6665038466453552\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 32139, rl-loss: 0.3746313750743866\n",
      "----------------------------------------\n",
      "  timestep     |  32139\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 32287, rl-loss: 0.4127248227596283\n",
      "----------------------------------------\n",
      "  timestep     |  32287\n",
      "  reward       |  -0.009\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 32426, rl-loss: 0.4424978792667389\n",
      "----------------------------------------\n",
      "  timestep     |  32426\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 32562, rl-loss: 0.5528233647346497\n",
      "----------------------------------------\n",
      "  timestep     |  32562\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 32710, rl-loss: 0.4322924017906189\n",
      "----------------------------------------\n",
      "  timestep     |  32710\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 32857, rl-loss: 0.6010372638702393\n",
      "----------------------------------------\n",
      "  timestep     |  32857\n",
      "  reward       |  -0.019\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33000, rl-loss: 0.48982730507850647\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 33014, rl-loss: 0.6193422079086304\n",
      "----------------------------------------\n",
      "  timestep     |  33014\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33157, rl-loss: 0.6309287548065186\n",
      "----------------------------------------\n",
      "  timestep     |  33157\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33306, rl-loss: 0.6295907497406006\n",
      "----------------------------------------\n",
      "  timestep     |  33306\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33455, rl-loss: 0.4084628224372864\n",
      "----------------------------------------\n",
      "  timestep     |  33455\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33611, rl-loss: 0.4526579678058624\n",
      "----------------------------------------\n",
      "  timestep     |  33611\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33772, rl-loss: 0.7451894283294678\n",
      "----------------------------------------\n",
      "  timestep     |  33772\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 33919, rl-loss: 0.5951085090637207\n",
      "----------------------------------------\n",
      "  timestep     |  33919\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34000, rl-loss: 0.7076012492179871\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 34063, rl-loss: 0.4655470848083496\n",
      "----------------------------------------\n",
      "  timestep     |  34063\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34205, rl-loss: 0.5004018545150757\n",
      "----------------------------------------\n",
      "  timestep     |  34205\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34350, rl-loss: 0.5806119441986084\n",
      "----------------------------------------\n",
      "  timestep     |  34350\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34496, rl-loss: 0.5580839514732361\n",
      "----------------------------------------\n",
      "  timestep     |  34496\n",
      "  reward       |  -0.002\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34648, rl-loss: 0.5230126976966858\n",
      "----------------------------------------\n",
      "  timestep     |  34648\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34797, rl-loss: 0.49755221605300903\n",
      "----------------------------------------\n",
      "  timestep     |  34797\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 34947, rl-loss: 0.5822911262512207\n",
      "----------------------------------------\n",
      "  timestep     |  34947\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 35000, rl-loss: 0.35180047154426575\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 35095, rl-loss: 0.39282435178756714\n",
      "----------------------------------------\n",
      "  timestep     |  35095\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 35238, rl-loss: 0.5741538405418396\n",
      "----------------------------------------\n",
      "  timestep     |  35238\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 35389, rl-loss: 0.7655324935913086\n",
      "----------------------------------------\n",
      "  timestep     |  35389\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 35538, rl-loss: 0.3863617777824402\n",
      "----------------------------------------\n",
      "  timestep     |  35538\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 35690, rl-loss: 0.5089727640151978\n",
      "----------------------------------------\n",
      "  timestep     |  35690\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 35846, rl-loss: 0.45439082384109497\n",
      "----------------------------------------\n",
      "  timestep     |  35846\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36000, rl-loss: 0.3483046889305115\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 36002, rl-loss: 0.3637082576751709\n",
      "----------------------------------------\n",
      "  timestep     |  36002\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36145, rl-loss: 0.46500352025032043\n",
      "----------------------------------------\n",
      "  timestep     |  36145\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36279, rl-loss: 0.5215427875518799\n",
      "----------------------------------------\n",
      "  timestep     |  36279\n",
      "  reward       |  -0.006\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36419, rl-loss: 0.45723485946655273\n",
      "----------------------------------------\n",
      "  timestep     |  36419\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36569, rl-loss: 0.507597804069519\n",
      "----------------------------------------\n",
      "  timestep     |  36569\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36718, rl-loss: 0.545470118522644\n",
      "----------------------------------------\n",
      "  timestep     |  36718\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 36868, rl-loss: 0.40045180916786194\n",
      "----------------------------------------\n",
      "  timestep     |  36868\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37000, rl-loss: 0.5898730754852295\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 37020, rl-loss: 0.5122725963592529\n",
      "----------------------------------------\n",
      "  timestep     |  37020\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37164, rl-loss: 0.4135880172252655\n",
      "----------------------------------------\n",
      "  timestep     |  37164\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37310, rl-loss: 0.3923882842063904\n",
      "----------------------------------------\n",
      "  timestep     |  37310\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37468, rl-loss: 0.5665498971939087\n",
      "----------------------------------------\n",
      "  timestep     |  37468\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37610, rl-loss: 0.4845287799835205\n",
      "----------------------------------------\n",
      "  timestep     |  37610\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37760, rl-loss: 0.6047264337539673\n",
      "----------------------------------------\n",
      "  timestep     |  37760\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 37903, rl-loss: 0.4354957938194275\n",
      "----------------------------------------\n",
      "  timestep     |  37903\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38000, rl-loss: 0.46494120359420776\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 38047, rl-loss: 0.6666933298110962\n",
      "----------------------------------------\n",
      "  timestep     |  38047\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38194, rl-loss: 0.7414006590843201\n",
      "----------------------------------------\n",
      "  timestep     |  38194\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38329, rl-loss: 0.6731870174407959\n",
      "----------------------------------------\n",
      "  timestep     |  38329\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38487, rl-loss: 0.2789894640445709\n",
      "----------------------------------------\n",
      "  timestep     |  38487\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38636, rl-loss: 0.5606065392494202\n",
      "----------------------------------------\n",
      "  timestep     |  38636\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38784, rl-loss: 0.4919314980506897\n",
      "----------------------------------------\n",
      "  timestep     |  38784\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 38930, rl-loss: 0.6140080094337463\n",
      "----------------------------------------\n",
      "  timestep     |  38930\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39000, rl-loss: 0.33121272921562195\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 39074, rl-loss: 0.4023800194263458\n",
      "----------------------------------------\n",
      "  timestep     |  39074\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39218, rl-loss: 0.7000116109848022\n",
      "----------------------------------------\n",
      "  timestep     |  39218\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39372, rl-loss: 0.7686962485313416\n",
      "----------------------------------------\n",
      "  timestep     |  39372\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39521, rl-loss: 0.7216799855232239\n",
      "----------------------------------------\n",
      "  timestep     |  39521\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39670, rl-loss: 0.564557671546936\n",
      "----------------------------------------\n",
      "  timestep     |  39670\n",
      "  reward       |  -0.133\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39818, rl-loss: 0.47715431451797485\n",
      "----------------------------------------\n",
      "  timestep     |  39818\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 39956, rl-loss: 0.5571855306625366\n",
      "----------------------------------------\n",
      "  timestep     |  39956\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 40000, rl-loss: 0.6177909970283508\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 40098, rl-loss: 0.5122703909873962\n",
      "----------------------------------------\n",
      "  timestep     |  40098\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 40243, rl-loss: 0.559341549873352\n",
      "----------------------------------------\n",
      "  timestep     |  40243\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 40392, rl-loss: 0.4260747730731964\n",
      "----------------------------------------\n",
      "  timestep     |  40392\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 40553, rl-loss: 0.5454552173614502\n",
      "----------------------------------------\n",
      "  timestep     |  40553\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 40697, rl-loss: 0.49685341119766235\n",
      "----------------------------------------\n",
      "  timestep     |  40697\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 40855, rl-loss: 0.8419761061668396\n",
      "----------------------------------------\n",
      "  timestep     |  40855\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41000, rl-loss: 0.45454928278923035\n",
      "INFO - Copied model parameters to target network.\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  41000\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41145, rl-loss: 0.41796642541885376\n",
      "----------------------------------------\n",
      "  timestep     |  41145\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41296, rl-loss: 0.6027643084526062\n",
      "----------------------------------------\n",
      "  timestep     |  41296\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41439, rl-loss: 0.4583948850631714\n",
      "----------------------------------------\n",
      "  timestep     |  41439\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41579, rl-loss: 0.4814181923866272\n",
      "----------------------------------------\n",
      "  timestep     |  41579\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41726, rl-loss: 0.39121124148368835\n",
      "----------------------------------------\n",
      "  timestep     |  41726\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 41874, rl-loss: 0.5845102667808533\n",
      "----------------------------------------\n",
      "  timestep     |  41874\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42000, rl-loss: 0.5526142716407776\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 42016, rl-loss: 0.49962979555130005\n",
      "----------------------------------------\n",
      "  timestep     |  42016\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42181, rl-loss: 0.4955052435398102\n",
      "----------------------------------------\n",
      "  timestep     |  42181\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42328, rl-loss: 0.510063648223877\n",
      "----------------------------------------\n",
      "  timestep     |  42328\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42480, rl-loss: 0.4986962676048279\n",
      "----------------------------------------\n",
      "  timestep     |  42480\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42624, rl-loss: 0.47511428594589233\n",
      "----------------------------------------\n",
      "  timestep     |  42624\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42775, rl-loss: 0.4627875089645386\n",
      "----------------------------------------\n",
      "  timestep     |  42775\n",
      "  reward       |  -0.134\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 42927, rl-loss: 0.5531270503997803\n",
      "----------------------------------------\n",
      "  timestep     |  42927\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43000, rl-loss: 0.4487569034099579\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 43065, rl-loss: 0.5057464838027954\n",
      "----------------------------------------\n",
      "  timestep     |  43065\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43205, rl-loss: 0.6925239562988281\n",
      "----------------------------------------\n",
      "  timestep     |  43205\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43349, rl-loss: 0.5437448620796204\n",
      "----------------------------------------\n",
      "  timestep     |  43349\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43494, rl-loss: 0.695366621017456\n",
      "----------------------------------------\n",
      "  timestep     |  43494\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43646, rl-loss: 0.5211111307144165\n",
      "----------------------------------------\n",
      "  timestep     |  43646\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43791, rl-loss: 0.5689007043838501\n",
      "----------------------------------------\n",
      "  timestep     |  43791\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 43938, rl-loss: 0.6879180669784546\n",
      "----------------------------------------\n",
      "  timestep     |  43938\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44000, rl-loss: 0.49515730142593384\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 44085, rl-loss: 0.5899487733840942\n",
      "----------------------------------------\n",
      "  timestep     |  44085\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44234, rl-loss: 0.42749541997909546\n",
      "----------------------------------------\n",
      "  timestep     |  44234\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44372, rl-loss: 0.4090782105922699\n",
      "----------------------------------------\n",
      "  timestep     |  44372\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44529, rl-loss: 0.6435461044311523\n",
      "----------------------------------------\n",
      "  timestep     |  44529\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44672, rl-loss: 0.48114004731178284\n",
      "----------------------------------------\n",
      "  timestep     |  44672\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44826, rl-loss: 0.3147667348384857\n",
      "----------------------------------------\n",
      "  timestep     |  44826\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 44977, rl-loss: 0.48009443283081055\n",
      "----------------------------------------\n",
      "  timestep     |  44977\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 45000, rl-loss: 0.5207018256187439\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 45134, rl-loss: 0.4030899703502655\n",
      "----------------------------------------\n",
      "  timestep     |  45134\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 45285, rl-loss: 0.6067124009132385\n",
      "----------------------------------------\n",
      "  timestep     |  45285\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 45439, rl-loss: 0.4914264976978302\n",
      "----------------------------------------\n",
      "  timestep     |  45439\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 45589, rl-loss: 0.4733572006225586\n",
      "----------------------------------------\n",
      "  timestep     |  45589\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 45745, rl-loss: 0.5610907673835754\n",
      "----------------------------------------\n",
      "  timestep     |  45745\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 45898, rl-loss: 0.620756983757019\n",
      "----------------------------------------\n",
      "  timestep     |  45898\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46000, rl-loss: 0.48521560430526733\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 46054, rl-loss: 0.4650903344154358\n",
      "----------------------------------------\n",
      "  timestep     |  46054\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46193, rl-loss: 0.5564389228820801\n",
      "----------------------------------------\n",
      "  timestep     |  46193\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46344, rl-loss: 0.6177429556846619\n",
      "----------------------------------------\n",
      "  timestep     |  46344\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46491, rl-loss: 0.5397342443466187\n",
      "----------------------------------------\n",
      "  timestep     |  46491\n",
      "  reward       |  -0.009\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46637, rl-loss: 0.596226692199707\n",
      "----------------------------------------\n",
      "  timestep     |  46637\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46785, rl-loss: 0.4843679964542389\n",
      "----------------------------------------\n",
      "  timestep     |  46785\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 46935, rl-loss: 0.464361310005188\n",
      "----------------------------------------\n",
      "  timestep     |  46935\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47000, rl-loss: 0.6734960675239563\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 47082, rl-loss: 0.552384078502655\n",
      "----------------------------------------\n",
      "  timestep     |  47082\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47232, rl-loss: 0.41781070828437805\n",
      "----------------------------------------\n",
      "  timestep     |  47232\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47383, rl-loss: 0.6475643515586853\n",
      "----------------------------------------\n",
      "  timestep     |  47383\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47516, rl-loss: 0.6926075220108032\n",
      "----------------------------------------\n",
      "  timestep     |  47516\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47667, rl-loss: 0.6076997518539429\n",
      "----------------------------------------\n",
      "  timestep     |  47667\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47815, rl-loss: 0.4966180622577667\n",
      "----------------------------------------\n",
      "  timestep     |  47815\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 47960, rl-loss: 0.4658192992210388\n",
      "----------------------------------------\n",
      "  timestep     |  47960\n",
      "  reward       |  -0.002\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48000, rl-loss: 0.6964733600616455\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 48096, rl-loss: 0.4744222164154053\n",
      "----------------------------------------\n",
      "  timestep     |  48096\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48231, rl-loss: 0.7788578867912292\n",
      "----------------------------------------\n",
      "  timestep     |  48231\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48363, rl-loss: 0.453657865524292\n",
      "----------------------------------------\n",
      "  timestep     |  48363\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48503, rl-loss: 0.6840000748634338\n",
      "----------------------------------------\n",
      "  timestep     |  48503\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48648, rl-loss: 0.44533228874206543\n",
      "----------------------------------------\n",
      "  timestep     |  48648\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48797, rl-loss: 0.7375524044036865\n",
      "----------------------------------------\n",
      "  timestep     |  48797\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 48938, rl-loss: 0.5925420522689819\n",
      "----------------------------------------\n",
      "  timestep     |  48938\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49000, rl-loss: 0.41340193152427673\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 49098, rl-loss: 0.4691505432128906\n",
      "----------------------------------------\n",
      "  timestep     |  49098\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49248, rl-loss: 0.4215925335884094\n",
      "----------------------------------------\n",
      "  timestep     |  49248\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49394, rl-loss: 0.6314594745635986\n",
      "----------------------------------------\n",
      "  timestep     |  49394\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49552, rl-loss: 0.317999005317688\n",
      "----------------------------------------\n",
      "  timestep     |  49552\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49686, rl-loss: 0.4176064431667328\n",
      "----------------------------------------\n",
      "  timestep     |  49686\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49823, rl-loss: 0.5035141706466675\n",
      "----------------------------------------\n",
      "  timestep     |  49823\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 49959, rl-loss: 0.5775451064109802\n",
      "----------------------------------------\n",
      "  timestep     |  49959\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50000, rl-loss: 0.5250810384750366\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 50089, rl-loss: 0.6793832182884216\n",
      "----------------------------------------\n",
      "  timestep     |  50089\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50236, rl-loss: 0.4432685673236847\n",
      "----------------------------------------\n",
      "  timestep     |  50236\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50382, rl-loss: 0.5046973824501038\n",
      "----------------------------------------\n",
      "  timestep     |  50382\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50530, rl-loss: 0.4989657700061798\n",
      "----------------------------------------\n",
      "  timestep     |  50530\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50685, rl-loss: 0.6307951807975769\n",
      "----------------------------------------\n",
      "  timestep     |  50685\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50828, rl-loss: 0.5418925881385803\n",
      "----------------------------------------\n",
      "  timestep     |  50828\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 50978, rl-loss: 0.41277745366096497\n",
      "----------------------------------------\n",
      "  timestep     |  50978\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51000, rl-loss: 0.37707769870758057\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 51127, rl-loss: 0.49162909388542175\n",
      "----------------------------------------\n",
      "  timestep     |  51127\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51271, rl-loss: 0.5771508812904358\n",
      "----------------------------------------\n",
      "  timestep     |  51271\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51414, rl-loss: 0.46855446696281433\n",
      "----------------------------------------\n",
      "  timestep     |  51414\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51555, rl-loss: 0.38336846232414246\n",
      "----------------------------------------\n",
      "  timestep     |  51555\n",
      "  reward       |  -0.006\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51703, rl-loss: 0.4397293031215668\n",
      "----------------------------------------\n",
      "  timestep     |  51703\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51849, rl-loss: 0.48467618227005005\n",
      "----------------------------------------\n",
      "  timestep     |  51849\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 51986, rl-loss: 0.5040323734283447\n",
      "----------------------------------------\n",
      "  timestep     |  51986\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 52000, rl-loss: 0.5686441659927368\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 52140, rl-loss: 0.6105881929397583\n",
      "----------------------------------------\n",
      "  timestep     |  52140\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 52300, rl-loss: 0.5119688510894775\n",
      "----------------------------------------\n",
      "  timestep     |  52300\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 52446, rl-loss: 0.6236288547515869\n",
      "----------------------------------------\n",
      "  timestep     |  52446\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 52583, rl-loss: 0.4656968116760254\n",
      "----------------------------------------\n",
      "  timestep     |  52583\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 52735, rl-loss: 0.5835782885551453\n",
      "----------------------------------------\n",
      "  timestep     |  52735\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 52874, rl-loss: 0.5405286550521851\n",
      "----------------------------------------\n",
      "  timestep     |  52874\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53000, rl-loss: 0.33832937479019165\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 53023, rl-loss: 0.48693355917930603\n",
      "----------------------------------------\n",
      "  timestep     |  53023\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53172, rl-loss: 0.5218610167503357\n",
      "----------------------------------------\n",
      "  timestep     |  53172\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53304, rl-loss: 0.47522422671318054\n",
      "----------------------------------------\n",
      "  timestep     |  53304\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53447, rl-loss: 0.5998755693435669\n",
      "----------------------------------------\n",
      "  timestep     |  53447\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53582, rl-loss: 0.45818108320236206\n",
      "----------------------------------------\n",
      "  timestep     |  53582\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53724, rl-loss: 0.6876717805862427\n",
      "----------------------------------------\n",
      "  timestep     |  53724\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 53869, rl-loss: 0.4326418936252594\n",
      "----------------------------------------\n",
      "  timestep     |  53869\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54000, rl-loss: 0.458881676197052\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 54014, rl-loss: 0.6107163429260254\n",
      "----------------------------------------\n",
      "  timestep     |  54014\n",
      "  reward       |  -0.117\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54152, rl-loss: 0.4752335548400879\n",
      "----------------------------------------\n",
      "  timestep     |  54152\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54289, rl-loss: 0.5348800420761108\n",
      "----------------------------------------\n",
      "  timestep     |  54289\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54427, rl-loss: 0.6941238641738892\n",
      "----------------------------------------\n",
      "  timestep     |  54427\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54561, rl-loss: 0.4422774910926819\n",
      "----------------------------------------\n",
      "  timestep     |  54561\n",
      "  reward       |  0.002\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54714, rl-loss: 0.571292519569397\n",
      "----------------------------------------\n",
      "  timestep     |  54714\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54854, rl-loss: 0.4387756586074829\n",
      "----------------------------------------\n",
      "  timestep     |  54854\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 54991, rl-loss: 0.5463014841079712\n",
      "----------------------------------------\n",
      "  timestep     |  54991\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 55000, rl-loss: 0.4836388826370239\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 55132, rl-loss: 0.3962900936603546\n",
      "----------------------------------------\n",
      "  timestep     |  55132\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 55279, rl-loss: 0.5861469507217407\n",
      "----------------------------------------\n",
      "  timestep     |  55279\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 55430, rl-loss: 0.4693717956542969\n",
      "----------------------------------------\n",
      "  timestep     |  55430\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 55575, rl-loss: 0.8434411883354187\n",
      "----------------------------------------\n",
      "  timestep     |  55575\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 55723, rl-loss: 0.46197018027305603\n",
      "----------------------------------------\n",
      "  timestep     |  55723\n",
      "  reward       |  -0.013\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 55859, rl-loss: 0.4295106530189514\n",
      "----------------------------------------\n",
      "  timestep     |  55859\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56000, rl-loss: 0.5928068161010742\n",
      "INFO - Copied model parameters to target network.\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  56000\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56129, rl-loss: 0.3873959183692932\n",
      "----------------------------------------\n",
      "  timestep     |  56129\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56270, rl-loss: 0.6471198201179504\n",
      "----------------------------------------\n",
      "  timestep     |  56270\n",
      "  reward       |  0.005\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56412, rl-loss: 0.37597209215164185\n",
      "----------------------------------------\n",
      "  timestep     |  56412\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56549, rl-loss: 0.35919180512428284\n",
      "----------------------------------------\n",
      "  timestep     |  56549\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56706, rl-loss: 0.4514840245246887\n",
      "----------------------------------------\n",
      "  timestep     |  56706\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56849, rl-loss: 0.4954797923564911\n",
      "----------------------------------------\n",
      "  timestep     |  56849\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 56996, rl-loss: 0.45900189876556396\n",
      "----------------------------------------\n",
      "  timestep     |  56996\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 57000, rl-loss: 0.5108259916305542\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 57141, rl-loss: 0.542367696762085\n",
      "----------------------------------------\n",
      "  timestep     |  57141\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 57296, rl-loss: 0.3331422805786133\n",
      "----------------------------------------\n",
      "  timestep     |  57296\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 57448, rl-loss: 0.5348784327507019\n",
      "----------------------------------------\n",
      "  timestep     |  57448\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 57601, rl-loss: 0.49925723671913147\n",
      "----------------------------------------\n",
      "  timestep     |  57601\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 57752, rl-loss: 0.6094721555709839\n",
      "----------------------------------------\n",
      "  timestep     |  57752\n",
      "  reward       |  -0.012\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 57905, rl-loss: 0.50472491979599\n",
      "----------------------------------------\n",
      "  timestep     |  57905\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58000, rl-loss: 0.4339727759361267\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 58058, rl-loss: 0.35028865933418274\n",
      "----------------------------------------\n",
      "  timestep     |  58058\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58201, rl-loss: 0.4317351281642914\n",
      "----------------------------------------\n",
      "  timestep     |  58201\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58348, rl-loss: 0.4437141418457031\n",
      "----------------------------------------\n",
      "  timestep     |  58348\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58502, rl-loss: 0.38451915979385376\n",
      "----------------------------------------\n",
      "  timestep     |  58502\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58658, rl-loss: 0.409462034702301\n",
      "----------------------------------------\n",
      "  timestep     |  58658\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58800, rl-loss: 0.44982603192329407\n",
      "----------------------------------------\n",
      "  timestep     |  58800\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 58942, rl-loss: 0.5200175046920776\n",
      "----------------------------------------\n",
      "  timestep     |  58942\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59000, rl-loss: 0.5496058464050293\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 59089, rl-loss: 0.5889180898666382\n",
      "----------------------------------------\n",
      "  timestep     |  59089\n",
      "  reward       |  -0.153\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59220, rl-loss: 0.40525686740875244\n",
      "----------------------------------------\n",
      "  timestep     |  59220\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59366, rl-loss: 0.741296648979187\n",
      "----------------------------------------\n",
      "  timestep     |  59366\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59511, rl-loss: 0.5259184837341309\n",
      "----------------------------------------\n",
      "  timestep     |  59511\n",
      "  reward       |  0.014\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59661, rl-loss: 0.5380089282989502\n",
      "----------------------------------------\n",
      "  timestep     |  59661\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59808, rl-loss: 0.6213293671607971\n",
      "----------------------------------------\n",
      "  timestep     |  59808\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 59961, rl-loss: 0.4676598012447357\n",
      "----------------------------------------\n",
      "  timestep     |  59961\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60000, rl-loss: 0.5728742480278015\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 60113, rl-loss: 0.7173577547073364\n",
      "----------------------------------------\n",
      "  timestep     |  60113\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60259, rl-loss: 0.6850728988647461\n",
      "----------------------------------------\n",
      "  timestep     |  60259\n",
      "  reward       |  -0.018\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60410, rl-loss: 0.3971337378025055\n",
      "----------------------------------------\n",
      "  timestep     |  60410\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60558, rl-loss: 0.3318631649017334\n",
      "----------------------------------------\n",
      "  timestep     |  60558\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60703, rl-loss: 0.6699435114860535\n",
      "----------------------------------------\n",
      "  timestep     |  60703\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60846, rl-loss: 0.5284590125083923\n",
      "----------------------------------------\n",
      "  timestep     |  60846\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 60993, rl-loss: 0.5720657110214233\n",
      "----------------------------------------\n",
      "  timestep     |  60993\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61000, rl-loss: 0.5287396907806396\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 61133, rl-loss: 0.7166584134101868\n",
      "----------------------------------------\n",
      "  timestep     |  61133\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61277, rl-loss: 0.5245503187179565\n",
      "----------------------------------------\n",
      "  timestep     |  61277\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61421, rl-loss: 0.5773512721061707\n",
      "----------------------------------------\n",
      "  timestep     |  61421\n",
      "  reward       |  -0.121\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61564, rl-loss: 0.7427809834480286\n",
      "----------------------------------------\n",
      "  timestep     |  61564\n",
      "  reward       |  -0.142\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61719, rl-loss: 0.6321003437042236\n",
      "----------------------------------------\n",
      "  timestep     |  61719\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61854, rl-loss: 0.3375767767429352\n",
      "----------------------------------------\n",
      "  timestep     |  61854\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 61998, rl-loss: 0.43403661251068115\n",
      "----------------------------------------\n",
      "  timestep     |  61998\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 62000, rl-loss: 0.5850062370300293\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 62149, rl-loss: 0.4979744851589203\n",
      "----------------------------------------\n",
      "  timestep     |  62149\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 62299, rl-loss: 0.5601771473884583\n",
      "----------------------------------------\n",
      "  timestep     |  62299\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 62448, rl-loss: 0.4995060861110687\n",
      "----------------------------------------\n",
      "  timestep     |  62448\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 62599, rl-loss: 0.5972975492477417\n",
      "----------------------------------------\n",
      "  timestep     |  62599\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 62734, rl-loss: 0.5309858322143555\n",
      "----------------------------------------\n",
      "  timestep     |  62734\n",
      "  reward       |  -0.007\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 62883, rl-loss: 0.43623286485671997\n",
      "----------------------------------------\n",
      "  timestep     |  62883\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63000, rl-loss: 0.6121552586555481\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 63026, rl-loss: 0.5950091481208801\n",
      "----------------------------------------\n",
      "  timestep     |  63026\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63179, rl-loss: 0.3847894072532654\n",
      "----------------------------------------\n",
      "  timestep     |  63179\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63327, rl-loss: 0.7669624090194702\n",
      "----------------------------------------\n",
      "  timestep     |  63327\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63461, rl-loss: 0.5424262285232544\n",
      "----------------------------------------\n",
      "  timestep     |  63461\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63615, rl-loss: 0.5574327111244202\n",
      "----------------------------------------\n",
      "  timestep     |  63615\n",
      "  reward       |  -0.014\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63770, rl-loss: 0.5514576435089111\n",
      "----------------------------------------\n",
      "  timestep     |  63770\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 63920, rl-loss: 0.4832903742790222\n",
      "----------------------------------------\n",
      "  timestep     |  63920\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64000, rl-loss: 0.5195183157920837\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 64063, rl-loss: 0.3917316198348999\n",
      "----------------------------------------\n",
      "  timestep     |  64063\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64215, rl-loss: 0.5104198455810547\n",
      "----------------------------------------\n",
      "  timestep     |  64215\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64365, rl-loss: 0.472709983587265\n",
      "----------------------------------------\n",
      "  timestep     |  64365\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64519, rl-loss: 0.553024172782898\n",
      "----------------------------------------\n",
      "  timestep     |  64519\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64657, rl-loss: 0.6144220232963562\n",
      "----------------------------------------\n",
      "  timestep     |  64657\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64807, rl-loss: 0.5983371734619141\n",
      "----------------------------------------\n",
      "  timestep     |  64807\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 64952, rl-loss: 0.41034841537475586\n",
      "----------------------------------------\n",
      "  timestep     |  64952\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65000, rl-loss: 0.7826148867607117\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 65107, rl-loss: 0.6924980878829956\n",
      "----------------------------------------\n",
      "  timestep     |  65107\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65255, rl-loss: 0.35819900035858154\n",
      "----------------------------------------\n",
      "  timestep     |  65255\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65395, rl-loss: 0.5542483925819397\n",
      "----------------------------------------\n",
      "  timestep     |  65395\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65529, rl-loss: 0.7535451650619507\n",
      "----------------------------------------\n",
      "  timestep     |  65529\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65668, rl-loss: 0.49478498101234436\n",
      "----------------------------------------\n",
      "  timestep     |  65668\n",
      "  reward       |  -0.115\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65812, rl-loss: 0.6421374678611755\n",
      "----------------------------------------\n",
      "  timestep     |  65812\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 65951, rl-loss: 0.5563679933547974\n",
      "----------------------------------------\n",
      "  timestep     |  65951\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66000, rl-loss: 0.5836473703384399\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 66103, rl-loss: 0.5461544990539551\n",
      "----------------------------------------\n",
      "  timestep     |  66103\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66245, rl-loss: 0.6070423722267151\n",
      "----------------------------------------\n",
      "  timestep     |  66245\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66391, rl-loss: 0.4549454152584076\n",
      "----------------------------------------\n",
      "  timestep     |  66391\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66522, rl-loss: 0.5352979898452759\n",
      "----------------------------------------\n",
      "  timestep     |  66522\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66655, rl-loss: 0.3933839499950409\n",
      "----------------------------------------\n",
      "  timestep     |  66655\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66797, rl-loss: 0.6030213236808777\n",
      "----------------------------------------\n",
      "  timestep     |  66797\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 66935, rl-loss: 0.5882984399795532\n",
      "----------------------------------------\n",
      "  timestep     |  66935\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67000, rl-loss: 0.41736215353012085\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 67082, rl-loss: 0.4424416124820709\n",
      "----------------------------------------\n",
      "  timestep     |  67082\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67227, rl-loss: 0.4453830420970917\n",
      "----------------------------------------\n",
      "  timestep     |  67227\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67361, rl-loss: 0.6647723913192749\n",
      "----------------------------------------\n",
      "  timestep     |  67361\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67497, rl-loss: 0.5292532444000244\n",
      "----------------------------------------\n",
      "  timestep     |  67497\n",
      "  reward       |  -0.149\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67637, rl-loss: 0.4839317500591278\n",
      "----------------------------------------\n",
      "  timestep     |  67637\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67784, rl-loss: 0.6974503993988037\n",
      "----------------------------------------\n",
      "  timestep     |  67784\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 67947, rl-loss: 0.5976395606994629\n",
      "----------------------------------------\n",
      "  timestep     |  67947\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68000, rl-loss: 0.6483115553855896\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 68091, rl-loss: 0.517300546169281\n",
      "----------------------------------------\n",
      "  timestep     |  68091\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68233, rl-loss: 0.3721787631511688\n",
      "----------------------------------------\n",
      "  timestep     |  68233\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68377, rl-loss: 0.5459373593330383\n",
      "----------------------------------------\n",
      "  timestep     |  68377\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68523, rl-loss: 0.5690333843231201\n",
      "----------------------------------------\n",
      "  timestep     |  68523\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68661, rl-loss: 0.48216748237609863\n",
      "----------------------------------------\n",
      "  timestep     |  68661\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68805, rl-loss: 0.3088974952697754\n",
      "----------------------------------------\n",
      "  timestep     |  68805\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 68952, rl-loss: 0.4799647927284241\n",
      "----------------------------------------\n",
      "  timestep     |  68952\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69000, rl-loss: 0.4698466658592224\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 69095, rl-loss: 0.4764850437641144\n",
      "----------------------------------------\n",
      "  timestep     |  69095\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69243, rl-loss: 0.7121458649635315\n",
      "----------------------------------------\n",
      "  timestep     |  69243\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69389, rl-loss: 0.5650492310523987\n",
      "----------------------------------------\n",
      "  timestep     |  69389\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69540, rl-loss: 0.6904397010803223\n",
      "----------------------------------------\n",
      "  timestep     |  69540\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69685, rl-loss: 0.3796800971031189\n",
      "----------------------------------------\n",
      "  timestep     |  69685\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69839, rl-loss: 0.4118262231349945\n",
      "----------------------------------------\n",
      "  timestep     |  69839\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 69996, rl-loss: 0.44178780913352966\n",
      "----------------------------------------\n",
      "  timestep     |  69996\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 70000, rl-loss: 0.54161536693573\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 70138, rl-loss: 0.484286904335022\n",
      "----------------------------------------\n",
      "  timestep     |  70138\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 70273, rl-loss: 0.54274982213974\n",
      "----------------------------------------\n",
      "  timestep     |  70273\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 70418, rl-loss: 0.5497488379478455\n",
      "----------------------------------------\n",
      "  timestep     |  70418\n",
      "  reward       |  -0.153\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 70562, rl-loss: 0.566352903842926\n",
      "----------------------------------------\n",
      "  timestep     |  70562\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 70707, rl-loss: 0.673927903175354\n",
      "----------------------------------------\n",
      "  timestep     |  70707\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 70858, rl-loss: 0.5931849479675293\n",
      "----------------------------------------\n",
      "  timestep     |  70858\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71000, rl-loss: 0.5357832312583923\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 71002, rl-loss: 0.4024401903152466\n",
      "----------------------------------------\n",
      "  timestep     |  71002\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71146, rl-loss: 0.503865659236908\n",
      "----------------------------------------\n",
      "  timestep     |  71146\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71292, rl-loss: 0.5602583885192871\n",
      "----------------------------------------\n",
      "  timestep     |  71292\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71438, rl-loss: 0.6607564687728882\n",
      "----------------------------------------\n",
      "  timestep     |  71438\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71577, rl-loss: 0.7519669532775879\n",
      "----------------------------------------\n",
      "  timestep     |  71577\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71714, rl-loss: 0.690421462059021\n",
      "----------------------------------------\n",
      "  timestep     |  71714\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71861, rl-loss: 0.6867862939834595\n",
      "----------------------------------------\n",
      "  timestep     |  71861\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 71996, rl-loss: 0.5115475654602051\n",
      "----------------------------------------\n",
      "  timestep     |  71996\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 72000, rl-loss: 0.5436123013496399\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 72135, rl-loss: 0.49101522564888\n",
      "----------------------------------------\n",
      "  timestep     |  72135\n",
      "  reward       |  -0.125\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 72287, rl-loss: 0.5309475660324097\n",
      "----------------------------------------\n",
      "  timestep     |  72287\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 72431, rl-loss: 0.6939668655395508\n",
      "----------------------------------------\n",
      "  timestep     |  72431\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 72575, rl-loss: 0.6567383408546448\n",
      "----------------------------------------\n",
      "  timestep     |  72575\n",
      "  reward       |  0.005\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 72724, rl-loss: 0.45709508657455444\n",
      "----------------------------------------\n",
      "  timestep     |  72724\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 72873, rl-loss: 0.4326281249523163\n",
      "----------------------------------------\n",
      "  timestep     |  72873\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73000, rl-loss: 0.4297223687171936\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 73016, rl-loss: 0.6214455962181091\n",
      "----------------------------------------\n",
      "  timestep     |  73016\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73144, rl-loss: 0.5017501711845398\n",
      "----------------------------------------\n",
      "  timestep     |  73144\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73290, rl-loss: 0.5469446778297424\n",
      "----------------------------------------\n",
      "  timestep     |  73290\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73427, rl-loss: 0.4772822856903076\n",
      "----------------------------------------\n",
      "  timestep     |  73427\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73564, rl-loss: 0.4714493751525879\n",
      "----------------------------------------\n",
      "  timestep     |  73564\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73710, rl-loss: 0.5269619226455688\n",
      "----------------------------------------\n",
      "  timestep     |  73710\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73848, rl-loss: 0.619493842124939\n",
      "----------------------------------------\n",
      "  timestep     |  73848\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 73998, rl-loss: 0.5357170104980469\n",
      "----------------------------------------\n",
      "  timestep     |  73998\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 74000, rl-loss: 0.42746540904045105\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 74147, rl-loss: 0.6247138977050781\n",
      "----------------------------------------\n",
      "  timestep     |  74147\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 74296, rl-loss: 0.5019838213920593\n",
      "----------------------------------------\n",
      "  timestep     |  74296\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 74441, rl-loss: 0.5440491437911987\n",
      "----------------------------------------\n",
      "  timestep     |  74441\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 74579, rl-loss: 0.3925502598285675\n",
      "----------------------------------------\n",
      "  timestep     |  74579\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 74726, rl-loss: 0.36390554904937744\n",
      "----------------------------------------\n",
      "  timestep     |  74726\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 74869, rl-loss: 0.4240771532058716\n",
      "----------------------------------------\n",
      "  timestep     |  74869\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75000, rl-loss: 0.3770003616809845\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 75018, rl-loss: 0.6495388746261597\n",
      "----------------------------------------\n",
      "  timestep     |  75018\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75163, rl-loss: 0.5099746584892273\n",
      "----------------------------------------\n",
      "  timestep     |  75163\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75311, rl-loss: 0.5505741238594055\n",
      "----------------------------------------\n",
      "  timestep     |  75311\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75463, rl-loss: 0.7784914374351501\n",
      "----------------------------------------\n",
      "  timestep     |  75463\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75608, rl-loss: 0.6619736552238464\n",
      "----------------------------------------\n",
      "  timestep     |  75608\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75757, rl-loss: 0.4959444999694824\n",
      "----------------------------------------\n",
      "  timestep     |  75757\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 75896, rl-loss: 0.42002665996551514\n",
      "----------------------------------------\n",
      "  timestep     |  75896\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76000, rl-loss: 0.6411128640174866\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 76052, rl-loss: 0.5272339582443237\n",
      "----------------------------------------\n",
      "  timestep     |  76052\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76196, rl-loss: 0.5552269220352173\n",
      "----------------------------------------\n",
      "  timestep     |  76196\n",
      "  reward       |  -0.014\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76335, rl-loss: 0.6141114830970764\n",
      "----------------------------------------\n",
      "  timestep     |  76335\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76483, rl-loss: 0.5344712138175964\n",
      "----------------------------------------\n",
      "  timestep     |  76483\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76630, rl-loss: 0.6167774200439453\n",
      "----------------------------------------\n",
      "  timestep     |  76630\n",
      "  reward       |  0.004\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76776, rl-loss: 0.6525670289993286\n",
      "----------------------------------------\n",
      "  timestep     |  76776\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 76922, rl-loss: 0.5491001009941101\n",
      "----------------------------------------\n",
      "  timestep     |  76922\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77000, rl-loss: 0.5637194514274597\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 77055, rl-loss: 0.37540310621261597\n",
      "----------------------------------------\n",
      "  timestep     |  77055\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77196, rl-loss: 0.3469321131706238\n",
      "----------------------------------------\n",
      "  timestep     |  77196\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77340, rl-loss: 0.6316950917243958\n",
      "----------------------------------------\n",
      "  timestep     |  77340\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77481, rl-loss: 0.5021991729736328\n",
      "----------------------------------------\n",
      "  timestep     |  77481\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77625, rl-loss: 0.4865570664405823\n",
      "----------------------------------------\n",
      "  timestep     |  77625\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77768, rl-loss: 0.5370350480079651\n",
      "----------------------------------------\n",
      "  timestep     |  77768\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 77909, rl-loss: 0.5321723222732544\n",
      "----------------------------------------\n",
      "  timestep     |  77909\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78000, rl-loss: 0.5779464244842529\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 78055, rl-loss: 0.5551947951316833\n",
      "----------------------------------------\n",
      "  timestep     |  78055\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78204, rl-loss: 0.5808918476104736\n",
      "----------------------------------------\n",
      "  timestep     |  78204\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78356, rl-loss: 0.5122280716896057\n",
      "----------------------------------------\n",
      "  timestep     |  78356\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78505, rl-loss: 0.31481099128723145\n",
      "----------------------------------------\n",
      "  timestep     |  78505\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78651, rl-loss: 0.5150493383407593\n",
      "----------------------------------------\n",
      "  timestep     |  78651\n",
      "  reward       |  -0.022\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78784, rl-loss: 0.5015004277229309\n",
      "----------------------------------------\n",
      "  timestep     |  78784\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 78935, rl-loss: 0.6165847778320312\n",
      "----------------------------------------\n",
      "  timestep     |  78935\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79000, rl-loss: 0.31172704696655273\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 79077, rl-loss: 0.6254128813743591\n",
      "----------------------------------------\n",
      "  timestep     |  79077\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79226, rl-loss: 0.4827343225479126\n",
      "----------------------------------------\n",
      "  timestep     |  79226\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79379, rl-loss: 0.47747647762298584\n",
      "----------------------------------------\n",
      "  timestep     |  79379\n",
      "  reward       |  -0.022\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79521, rl-loss: 0.6165577173233032\n",
      "----------------------------------------\n",
      "  timestep     |  79521\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79666, rl-loss: 0.6707169413566589\n",
      "----------------------------------------\n",
      "  timestep     |  79666\n",
      "  reward       |  -0.123\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79809, rl-loss: 0.5480135679244995\n",
      "----------------------------------------\n",
      "  timestep     |  79809\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 79953, rl-loss: 0.41801080107688904\n",
      "----------------------------------------\n",
      "  timestep     |  79953\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 80000, rl-loss: 0.36143338680267334\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 80103, rl-loss: 0.4444866478443146\n",
      "----------------------------------------\n",
      "  timestep     |  80103\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 80253, rl-loss: 0.6113471984863281\n",
      "----------------------------------------\n",
      "  timestep     |  80253\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 80399, rl-loss: 0.4996068477630615\n",
      "----------------------------------------\n",
      "  timestep     |  80399\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 80549, rl-loss: 0.3881758451461792\n",
      "----------------------------------------\n",
      "  timestep     |  80549\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 80703, rl-loss: 0.5149371027946472\n",
      "----------------------------------------\n",
      "  timestep     |  80703\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 80854, rl-loss: 0.39998379349708557\n",
      "----------------------------------------\n",
      "  timestep     |  80854\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81000, rl-loss: 0.4474738836288452\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 81009, rl-loss: 0.6926296949386597\n",
      "----------------------------------------\n",
      "  timestep     |  81009\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81172, rl-loss: 0.5232629179954529\n",
      "----------------------------------------\n",
      "  timestep     |  81172\n",
      "  reward       |  -0.118\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81315, rl-loss: 0.5427809357643127\n",
      "----------------------------------------\n",
      "  timestep     |  81315\n",
      "  reward       |  -0.114\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81468, rl-loss: 0.5945360064506531\n",
      "----------------------------------------\n",
      "  timestep     |  81468\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81610, rl-loss: 0.48148930072784424\n",
      "----------------------------------------\n",
      "  timestep     |  81610\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81756, rl-loss: 0.31929823756217957\n",
      "----------------------------------------\n",
      "  timestep     |  81756\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 81905, rl-loss: 0.43163174390792847\n",
      "----------------------------------------\n",
      "  timestep     |  81905\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82000, rl-loss: 0.4409891366958618\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 82055, rl-loss: 0.5610998272895813\n",
      "----------------------------------------\n",
      "  timestep     |  82055\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82196, rl-loss: 0.6670635342597961\n",
      "----------------------------------------\n",
      "  timestep     |  82196\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82343, rl-loss: 0.597231924533844\n",
      "----------------------------------------\n",
      "  timestep     |  82343\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82487, rl-loss: 0.6182333827018738\n",
      "----------------------------------------\n",
      "  timestep     |  82487\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82628, rl-loss: 0.37006908655166626\n",
      "----------------------------------------\n",
      "  timestep     |  82628\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82768, rl-loss: 0.46127527952194214\n",
      "----------------------------------------\n",
      "  timestep     |  82768\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 82909, rl-loss: 0.34545013308525085\n",
      "----------------------------------------\n",
      "  timestep     |  82909\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83000, rl-loss: 0.5147086977958679\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 83059, rl-loss: 0.611522912979126\n",
      "----------------------------------------\n",
      "  timestep     |  83059\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83193, rl-loss: 0.46505776047706604\n",
      "----------------------------------------\n",
      "  timestep     |  83193\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83322, rl-loss: 0.5157538652420044\n",
      "----------------------------------------\n",
      "  timestep     |  83322\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83468, rl-loss: 0.6312373876571655\n",
      "----------------------------------------\n",
      "  timestep     |  83468\n",
      "  reward       |  -0.143\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83611, rl-loss: 0.4364681839942932\n",
      "----------------------------------------\n",
      "  timestep     |  83611\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83756, rl-loss: 0.5011111497879028\n",
      "----------------------------------------\n",
      "  timestep     |  83756\n",
      "  reward       |  -0.136\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 83901, rl-loss: 0.4213571548461914\n",
      "----------------------------------------\n",
      "  timestep     |  83901\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84000, rl-loss: 0.5072830319404602\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 84055, rl-loss: 0.534087598323822\n",
      "----------------------------------------\n",
      "  timestep     |  84055\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84189, rl-loss: 0.4229470491409302\n",
      "----------------------------------------\n",
      "  timestep     |  84189\n",
      "  reward       |  -0.13\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84333, rl-loss: 0.4987632930278778\n",
      "----------------------------------------\n",
      "  timestep     |  84333\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84471, rl-loss: 0.5878194570541382\n",
      "----------------------------------------\n",
      "  timestep     |  84471\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84618, rl-loss: 0.46091797947883606\n",
      "----------------------------------------\n",
      "  timestep     |  84618\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84750, rl-loss: 0.4871005415916443\n",
      "----------------------------------------\n",
      "  timestep     |  84750\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 84899, rl-loss: 0.5820122361183167\n",
      "----------------------------------------\n",
      "  timestep     |  84899\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85000, rl-loss: 0.4513299763202667\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 85043, rl-loss: 0.44353827834129333\n",
      "----------------------------------------\n",
      "  timestep     |  85043\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85184, rl-loss: 0.34653741121292114\n",
      "----------------------------------------\n",
      "  timestep     |  85184\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85344, rl-loss: 0.3832646608352661\n",
      "----------------------------------------\n",
      "  timestep     |  85344\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85490, rl-loss: 0.40683960914611816\n",
      "----------------------------------------\n",
      "  timestep     |  85490\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85636, rl-loss: 0.6546064019203186\n",
      "----------------------------------------\n",
      "  timestep     |  85636\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85764, rl-loss: 0.6614460349082947\n",
      "----------------------------------------\n",
      "  timestep     |  85764\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 85899, rl-loss: 0.7149510383605957\n",
      "----------------------------------------\n",
      "  timestep     |  85899\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86000, rl-loss: 0.6025576591491699\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 86048, rl-loss: 0.5242068767547607\n",
      "----------------------------------------\n",
      "  timestep     |  86048\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86191, rl-loss: 0.5962871313095093\n",
      "----------------------------------------\n",
      "  timestep     |  86191\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86337, rl-loss: 0.466082364320755\n",
      "----------------------------------------\n",
      "  timestep     |  86337\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86481, rl-loss: 0.44959428906440735\n",
      "----------------------------------------\n",
      "  timestep     |  86481\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86625, rl-loss: 0.47286534309387207\n",
      "----------------------------------------\n",
      "  timestep     |  86625\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86778, rl-loss: 0.5125812292098999\n",
      "----------------------------------------\n",
      "  timestep     |  86778\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 86927, rl-loss: 0.545407772064209\n",
      "----------------------------------------\n",
      "  timestep     |  86927\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87000, rl-loss: 0.5876609086990356\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 87061, rl-loss: 0.640235185623169\n",
      "----------------------------------------\n",
      "  timestep     |  87061\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87203, rl-loss: 0.5937565565109253\n",
      "----------------------------------------\n",
      "  timestep     |  87203\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87354, rl-loss: 0.580236554145813\n",
      "----------------------------------------\n",
      "  timestep     |  87354\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87500, rl-loss: 0.49606096744537354\n",
      "----------------------------------------\n",
      "  timestep     |  87500\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87635, rl-loss: 0.6097418665885925\n",
      "----------------------------------------\n",
      "  timestep     |  87635\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87781, rl-loss: 0.7374061942100525\n",
      "----------------------------------------\n",
      "  timestep     |  87781\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 87932, rl-loss: 0.566656231880188\n",
      "----------------------------------------\n",
      "  timestep     |  87932\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88000, rl-loss: 0.5418054461479187\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 88074, rl-loss: 0.5332667827606201\n",
      "----------------------------------------\n",
      "  timestep     |  88074\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88228, rl-loss: 0.5612539649009705\n",
      "----------------------------------------\n",
      "  timestep     |  88228\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88379, rl-loss: 0.3870272934436798\n",
      "----------------------------------------\n",
      "  timestep     |  88379\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88526, rl-loss: 0.4972642660140991\n",
      "----------------------------------------\n",
      "  timestep     |  88526\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88678, rl-loss: 0.6642457842826843\n",
      "----------------------------------------\n",
      "  timestep     |  88678\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88825, rl-loss: 0.5910366773605347\n",
      "----------------------------------------\n",
      "  timestep     |  88825\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 88969, rl-loss: 0.6060712337493896\n",
      "----------------------------------------\n",
      "  timestep     |  88969\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89000, rl-loss: 0.6718281507492065\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 89105, rl-loss: 0.6636132001876831\n",
      "----------------------------------------\n",
      "  timestep     |  89105\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89252, rl-loss: 0.3985411822795868\n",
      "----------------------------------------\n",
      "  timestep     |  89252\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89410, rl-loss: 0.37775129079818726\n",
      "----------------------------------------\n",
      "  timestep     |  89410\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89563, rl-loss: 0.5790727734565735\n",
      "----------------------------------------\n",
      "  timestep     |  89563\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89689, rl-loss: 0.4345076382160187\n",
      "----------------------------------------\n",
      "  timestep     |  89689\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89824, rl-loss: 0.69170743227005\n",
      "----------------------------------------\n",
      "  timestep     |  89824\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 89971, rl-loss: 0.634882926940918\n",
      "----------------------------------------\n",
      "  timestep     |  89971\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 90000, rl-loss: 0.4364800453186035\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 90118, rl-loss: 0.7256322503089905\n",
      "----------------------------------------\n",
      "  timestep     |  90118\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 90251, rl-loss: 0.4698931574821472\n",
      "----------------------------------------\n",
      "  timestep     |  90251\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 90403, rl-loss: 0.7858571410179138\n",
      "----------------------------------------\n",
      "  timestep     |  90403\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 90558, rl-loss: 0.587643027305603\n",
      "----------------------------------------\n",
      "  timestep     |  90558\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 90717, rl-loss: 0.5952598452568054\n",
      "----------------------------------------\n",
      "  timestep     |  90717\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 90857, rl-loss: 0.4678955674171448\n",
      "----------------------------------------\n",
      "  timestep     |  90857\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91000, rl-loss: 0.5696201920509338\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 91008, rl-loss: 0.6055474281311035\n",
      "----------------------------------------\n",
      "  timestep     |  91008\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91152, rl-loss: 0.506434440612793\n",
      "----------------------------------------\n",
      "  timestep     |  91152\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91305, rl-loss: 0.42493218183517456\n",
      "----------------------------------------\n",
      "  timestep     |  91305\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91443, rl-loss: 0.5041452050209045\n",
      "----------------------------------------\n",
      "  timestep     |  91443\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91597, rl-loss: 0.45398634672164917\n",
      "----------------------------------------\n",
      "  timestep     |  91597\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91741, rl-loss: 0.487743616104126\n",
      "----------------------------------------\n",
      "  timestep     |  91741\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 91896, rl-loss: 0.38079634308815\n",
      "----------------------------------------\n",
      "  timestep     |  91896\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92000, rl-loss: 0.4648272693157196\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 92038, rl-loss: 0.5142806172370911\n",
      "----------------------------------------\n",
      "  timestep     |  92038\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92182, rl-loss: 0.45285406708717346\n",
      "----------------------------------------\n",
      "  timestep     |  92182\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92328, rl-loss: 0.4701138436794281\n",
      "----------------------------------------\n",
      "  timestep     |  92328\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92482, rl-loss: 0.4980131983757019\n",
      "----------------------------------------\n",
      "  timestep     |  92482\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92629, rl-loss: 0.45006969571113586\n",
      "----------------------------------------\n",
      "  timestep     |  92629\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92776, rl-loss: 0.5351754426956177\n",
      "----------------------------------------\n",
      "  timestep     |  92776\n",
      "  reward       |  -0.138\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 92923, rl-loss: 0.40282490849494934\n",
      "----------------------------------------\n",
      "  timestep     |  92923\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93000, rl-loss: 0.3701096773147583\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 93065, rl-loss: 0.566398561000824\n",
      "----------------------------------------\n",
      "  timestep     |  93065\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93206, rl-loss: 0.7113028764724731\n",
      "----------------------------------------\n",
      "  timestep     |  93206\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93352, rl-loss: 0.4400884509086609\n",
      "----------------------------------------\n",
      "  timestep     |  93352\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93495, rl-loss: 0.4728887379169464\n",
      "----------------------------------------\n",
      "  timestep     |  93495\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93631, rl-loss: 0.34195277094841003\n",
      "----------------------------------------\n",
      "  timestep     |  93631\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93774, rl-loss: 0.40050461888313293\n",
      "----------------------------------------\n",
      "  timestep     |  93774\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 93912, rl-loss: 0.4603334665298462\n",
      "----------------------------------------\n",
      "  timestep     |  93912\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94000, rl-loss: 0.41830405592918396\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 94060, rl-loss: 0.47876912355422974\n",
      "----------------------------------------\n",
      "  timestep     |  94060\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94197, rl-loss: 0.5040565133094788\n",
      "----------------------------------------\n",
      "  timestep     |  94197\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94336, rl-loss: 0.40824756026268005\n",
      "----------------------------------------\n",
      "  timestep     |  94336\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94486, rl-loss: 0.619408130645752\n",
      "----------------------------------------\n",
      "  timestep     |  94486\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94626, rl-loss: 0.6089426875114441\n",
      "----------------------------------------\n",
      "  timestep     |  94626\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94759, rl-loss: 0.5580142736434937\n",
      "----------------------------------------\n",
      "  timestep     |  94759\n",
      "  reward       |  -0.041\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 94913, rl-loss: 0.6334276795387268\n",
      "----------------------------------------\n",
      "  timestep     |  94913\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95000, rl-loss: 0.4019303023815155\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 95046, rl-loss: 0.5436928272247314\n",
      "----------------------------------------\n",
      "  timestep     |  95046\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95192, rl-loss: 0.5171452760696411\n",
      "----------------------------------------\n",
      "  timestep     |  95192\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95341, rl-loss: 0.5212931036949158\n",
      "----------------------------------------\n",
      "  timestep     |  95341\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95502, rl-loss: 0.5523667931556702\n",
      "----------------------------------------\n",
      "  timestep     |  95502\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95647, rl-loss: 0.5580037832260132\n",
      "----------------------------------------\n",
      "  timestep     |  95647\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95806, rl-loss: 0.4818603992462158\n",
      "----------------------------------------\n",
      "  timestep     |  95806\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 95957, rl-loss: 0.44530749320983887\n",
      "----------------------------------------\n",
      "  timestep     |  95957\n",
      "  reward       |  -0.013\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96000, rl-loss: 0.4925776720046997\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 96108, rl-loss: 0.6151654124259949\n",
      "----------------------------------------\n",
      "  timestep     |  96108\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96245, rl-loss: 0.42431893944740295\n",
      "----------------------------------------\n",
      "  timestep     |  96245\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96397, rl-loss: 0.6559831500053406\n",
      "----------------------------------------\n",
      "  timestep     |  96397\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96539, rl-loss: 0.38663250207901\n",
      "----------------------------------------\n",
      "  timestep     |  96539\n",
      "  reward       |  -0.007\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96698, rl-loss: 0.5523308515548706\n",
      "----------------------------------------\n",
      "  timestep     |  96698\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96859, rl-loss: 0.5082544684410095\n",
      "----------------------------------------\n",
      "  timestep     |  96859\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 96999, rl-loss: 0.7302643656730652\n",
      "----------------------------------------\n",
      "  timestep     |  96999\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 97000, rl-loss: 0.6700645685195923\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 97144, rl-loss: 0.6705543398857117\n",
      "----------------------------------------\n",
      "  timestep     |  97144\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 97287, rl-loss: 0.5179320573806763\n",
      "----------------------------------------\n",
      "  timestep     |  97287\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 97433, rl-loss: 0.5631776452064514\n",
      "----------------------------------------\n",
      "  timestep     |  97433\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 97584, rl-loss: 0.42129454016685486\n",
      "----------------------------------------\n",
      "  timestep     |  97584\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 97729, rl-loss: 0.5297597646713257\n",
      "----------------------------------------\n",
      "  timestep     |  97729\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 97874, rl-loss: 0.6115267276763916\n",
      "----------------------------------------\n",
      "  timestep     |  97874\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98000, rl-loss: 0.6045430302619934\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 98013, rl-loss: 0.5271927714347839\n",
      "----------------------------------------\n",
      "  timestep     |  98013\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98155, rl-loss: 0.5067994594573975\n",
      "----------------------------------------\n",
      "  timestep     |  98155\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98299, rl-loss: 0.6934731006622314\n",
      "----------------------------------------\n",
      "  timestep     |  98299\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98449, rl-loss: 0.4855329394340515\n",
      "----------------------------------------\n",
      "  timestep     |  98449\n",
      "  reward       |  -0.161\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98596, rl-loss: 0.41239285469055176\n",
      "----------------------------------------\n",
      "  timestep     |  98596\n",
      "  reward       |  -0.03\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98743, rl-loss: 0.5764083862304688\n",
      "----------------------------------------\n",
      "  timestep     |  98743\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 98897, rl-loss: 0.7364640235900879\n",
      "----------------------------------------\n",
      "  timestep     |  98897\n",
      "  reward       |  -0.028\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99000, rl-loss: 0.7665431499481201\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 99038, rl-loss: 0.4591965675354004\n",
      "----------------------------------------\n",
      "  timestep     |  99038\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99183, rl-loss: 0.5570521950721741\n",
      "----------------------------------------\n",
      "  timestep     |  99183\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99332, rl-loss: 0.5607390403747559\n",
      "----------------------------------------\n",
      "  timestep     |  99332\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99467, rl-loss: 0.5851532220840454\n",
      "----------------------------------------\n",
      "  timestep     |  99467\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99615, rl-loss: 0.5797701478004456\n",
      "----------------------------------------\n",
      "  timestep     |  99615\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99762, rl-loss: 0.45952343940734863\n",
      "----------------------------------------\n",
      "  timestep     |  99762\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 99902, rl-loss: 0.6953234672546387\n",
      "----------------------------------------\n",
      "  timestep     |  99902\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100000, rl-loss: 0.3843821585178375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 100044, rl-loss: 0.39926350116729736\n",
      "----------------------------------------\n",
      "  timestep     |  100044\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100193, rl-loss: 0.5040604472160339\n",
      "----------------------------------------\n",
      "  timestep     |  100193\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100339, rl-loss: 0.3952699303627014\n",
      "----------------------------------------\n",
      "  timestep     |  100339\n",
      "  reward       |  -0.001\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100493, rl-loss: 0.4638960063457489\n",
      "----------------------------------------\n",
      "  timestep     |  100493\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100647, rl-loss: 0.48807644844055176\n",
      "----------------------------------------\n",
      "  timestep     |  100647\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100799, rl-loss: 0.6087237596511841\n",
      "----------------------------------------\n",
      "  timestep     |  100799\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 100940, rl-loss: 0.4449557662010193\n",
      "----------------------------------------\n",
      "  timestep     |  100940\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101000, rl-loss: 0.5055541396141052\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 101078, rl-loss: 0.60923171043396\n",
      "----------------------------------------\n",
      "  timestep     |  101078\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101225, rl-loss: 0.653045654296875\n",
      "----------------------------------------\n",
      "  timestep     |  101225\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101380, rl-loss: 0.5950868725776672\n",
      "----------------------------------------\n",
      "  timestep     |  101380\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101522, rl-loss: 0.5740140080451965\n",
      "----------------------------------------\n",
      "  timestep     |  101522\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101662, rl-loss: 0.6168422698974609\n",
      "----------------------------------------\n",
      "  timestep     |  101662\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101804, rl-loss: 0.6117111444473267\n",
      "----------------------------------------\n",
      "  timestep     |  101804\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 101950, rl-loss: 0.5023144483566284\n",
      "----------------------------------------\n",
      "  timestep     |  101950\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102000, rl-loss: 0.5075914859771729\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 102103, rl-loss: 0.596233606338501\n",
      "----------------------------------------\n",
      "  timestep     |  102103\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102252, rl-loss: 0.598369836807251\n",
      "----------------------------------------\n",
      "  timestep     |  102252\n",
      "  reward       |  -0.002\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102401, rl-loss: 0.7108967900276184\n",
      "----------------------------------------\n",
      "  timestep     |  102401\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102539, rl-loss: 0.5583817958831787\n",
      "----------------------------------------\n",
      "  timestep     |  102539\n",
      "  reward       |  -0.128\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102690, rl-loss: 0.4529499411582947\n",
      "----------------------------------------\n",
      "  timestep     |  102690\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102836, rl-loss: 0.41675618290901184\n",
      "----------------------------------------\n",
      "  timestep     |  102836\n",
      "  reward       |  -0.036\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 102987, rl-loss: 0.6733314990997314\n",
      "----------------------------------------\n",
      "  timestep     |  102987\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 103000, rl-loss: 0.5686148405075073\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 103138, rl-loss: 0.5551549196243286\n",
      "----------------------------------------\n",
      "  timestep     |  103138\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 103291, rl-loss: 0.5094496011734009\n",
      "----------------------------------------\n",
      "  timestep     |  103291\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 103439, rl-loss: 0.5806761980056763\n",
      "----------------------------------------\n",
      "  timestep     |  103439\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 103587, rl-loss: 0.5537405014038086\n",
      "----------------------------------------\n",
      "  timestep     |  103587\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 103738, rl-loss: 0.507369875907898\n",
      "----------------------------------------\n",
      "  timestep     |  103738\n",
      "  reward       |  -0.108\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 103880, rl-loss: 0.5561632513999939\n",
      "----------------------------------------\n",
      "  timestep     |  103880\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104000, rl-loss: 0.3029870092868805\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 104041, rl-loss: 0.5379650592803955\n",
      "----------------------------------------\n",
      "  timestep     |  104041\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104197, rl-loss: 0.5732077360153198\n",
      "----------------------------------------\n",
      "  timestep     |  104197\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104344, rl-loss: 0.5386762022972107\n",
      "----------------------------------------\n",
      "  timestep     |  104344\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104501, rl-loss: 0.3099467158317566\n",
      "----------------------------------------\n",
      "  timestep     |  104501\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104648, rl-loss: 0.6455323696136475\n",
      "----------------------------------------\n",
      "  timestep     |  104648\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104794, rl-loss: 0.544702410697937\n",
      "----------------------------------------\n",
      "  timestep     |  104794\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 104936, rl-loss: 0.4245418906211853\n",
      "----------------------------------------\n",
      "  timestep     |  104936\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105000, rl-loss: 0.47221386432647705\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 105072, rl-loss: 0.4794396460056305\n",
      "----------------------------------------\n",
      "  timestep     |  105072\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105214, rl-loss: 0.4593569338321686\n",
      "----------------------------------------\n",
      "  timestep     |  105214\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105346, rl-loss: 0.6041145324707031\n",
      "----------------------------------------\n",
      "  timestep     |  105346\n",
      "  reward       |  -0.025\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105499, rl-loss: 0.6260710954666138\n",
      "----------------------------------------\n",
      "  timestep     |  105499\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105637, rl-loss: 0.44879254698753357\n",
      "----------------------------------------\n",
      "  timestep     |  105637\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105782, rl-loss: 0.5175786018371582\n",
      "----------------------------------------\n",
      "  timestep     |  105782\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 105932, rl-loss: 0.45895916223526\n",
      "----------------------------------------\n",
      "  timestep     |  105932\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106000, rl-loss: 0.6413664221763611\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 106083, rl-loss: 0.5401236414909363\n",
      "----------------------------------------\n",
      "  timestep     |  106083\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106225, rl-loss: 0.5295268893241882\n",
      "----------------------------------------\n",
      "  timestep     |  106225\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106382, rl-loss: 0.5274829864501953\n",
      "----------------------------------------\n",
      "  timestep     |  106382\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106550, rl-loss: 0.4628826975822449\n",
      "----------------------------------------\n",
      "  timestep     |  106550\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106690, rl-loss: 0.4981530010700226\n",
      "----------------------------------------\n",
      "  timestep     |  106690\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106846, rl-loss: 0.36661890149116516\n",
      "----------------------------------------\n",
      "  timestep     |  106846\n",
      "  reward       |  0.004\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 106981, rl-loss: 0.6350468993186951\n",
      "----------------------------------------\n",
      "  timestep     |  106981\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 107000, rl-loss: 0.6635647416114807\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 107124, rl-loss: 0.42573797702789307\n",
      "----------------------------------------\n",
      "  timestep     |  107124\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 107280, rl-loss: 0.49288833141326904\n",
      "----------------------------------------\n",
      "  timestep     |  107280\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 107426, rl-loss: 0.5586354732513428\n",
      "----------------------------------------\n",
      "  timestep     |  107426\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 107563, rl-loss: 0.6072798371315002\n",
      "----------------------------------------\n",
      "  timestep     |  107563\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 107719, rl-loss: 0.5833789110183716\n",
      "----------------------------------------\n",
      "  timestep     |  107719\n",
      "  reward       |  -0.038\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 107868, rl-loss: 0.5852653980255127\n",
      "----------------------------------------\n",
      "  timestep     |  107868\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108000, rl-loss: 0.5493415594100952\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 108019, rl-loss: 0.6157763004302979\n",
      "----------------------------------------\n",
      "  timestep     |  108019\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108171, rl-loss: 0.5909825563430786\n",
      "----------------------------------------\n",
      "  timestep     |  108171\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108326, rl-loss: 0.5476633310317993\n",
      "----------------------------------------\n",
      "  timestep     |  108326\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108489, rl-loss: 0.6822028160095215\n",
      "----------------------------------------\n",
      "  timestep     |  108489\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108647, rl-loss: 0.43291449546813965\n",
      "----------------------------------------\n",
      "  timestep     |  108647\n",
      "  reward       |  0.003\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108801, rl-loss: 0.39714181423187256\n",
      "----------------------------------------\n",
      "  timestep     |  108801\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 108955, rl-loss: 0.6107408404350281\n",
      "----------------------------------------\n",
      "  timestep     |  108955\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109000, rl-loss: 0.44203174114227295\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 109108, rl-loss: 0.40756118297576904\n",
      "----------------------------------------\n",
      "  timestep     |  109108\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109257, rl-loss: 0.42838412523269653\n",
      "----------------------------------------\n",
      "  timestep     |  109257\n",
      "  reward       |  -0.116\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109409, rl-loss: 0.7014386653900146\n",
      "----------------------------------------\n",
      "  timestep     |  109409\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109550, rl-loss: 0.4380861818790436\n",
      "----------------------------------------\n",
      "  timestep     |  109550\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109694, rl-loss: 0.4714202284812927\n",
      "----------------------------------------\n",
      "  timestep     |  109694\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109840, rl-loss: 0.4875398576259613\n",
      "----------------------------------------\n",
      "  timestep     |  109840\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 109981, rl-loss: 0.37586426734924316\n",
      "----------------------------------------\n",
      "  timestep     |  109981\n",
      "  reward       |  -0.127\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 110000, rl-loss: 0.3914467692375183\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 110132, rl-loss: 0.5618090629577637\n",
      "----------------------------------------\n",
      "  timestep     |  110132\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 110286, rl-loss: 0.5278810858726501\n",
      "----------------------------------------\n",
      "  timestep     |  110286\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 110434, rl-loss: 0.4880502223968506\n",
      "----------------------------------------\n",
      "  timestep     |  110434\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 110570, rl-loss: 0.7887384295463562\n",
      "----------------------------------------\n",
      "  timestep     |  110570\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 110712, rl-loss: 0.5484195351600647\n",
      "----------------------------------------\n",
      "  timestep     |  110712\n",
      "  reward       |  -0.04\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 110861, rl-loss: 0.49544593691825867\n",
      "----------------------------------------\n",
      "  timestep     |  110861\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111000, rl-loss: 0.5991087555885315\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 111012, rl-loss: 0.5740072131156921\n",
      "----------------------------------------\n",
      "  timestep     |  111012\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111161, rl-loss: 0.5419224500656128\n",
      "----------------------------------------\n",
      "  timestep     |  111161\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111309, rl-loss: 0.7603785395622253\n",
      "----------------------------------------\n",
      "  timestep     |  111309\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111453, rl-loss: 0.6058898568153381\n",
      "----------------------------------------\n",
      "  timestep     |  111453\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111594, rl-loss: 0.43894898891448975\n",
      "----------------------------------------\n",
      "  timestep     |  111594\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111739, rl-loss: 0.7133587002754211\n",
      "----------------------------------------\n",
      "  timestep     |  111739\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 111889, rl-loss: 0.4779302477836609\n",
      "----------------------------------------\n",
      "  timestep     |  111889\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112000, rl-loss: 0.4666711688041687\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 112024, rl-loss: 0.745975136756897\n",
      "----------------------------------------\n",
      "  timestep     |  112024\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112182, rl-loss: 0.7720198035240173\n",
      "----------------------------------------\n",
      "  timestep     |  112182\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112324, rl-loss: 0.5251654386520386\n",
      "----------------------------------------\n",
      "  timestep     |  112324\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112465, rl-loss: 0.3993701934814453\n",
      "----------------------------------------\n",
      "  timestep     |  112465\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112607, rl-loss: 0.45446720719337463\n",
      "----------------------------------------\n",
      "  timestep     |  112607\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112754, rl-loss: 0.6030728220939636\n",
      "----------------------------------------\n",
      "  timestep     |  112754\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 112906, rl-loss: 0.6419300436973572\n",
      "----------------------------------------\n",
      "  timestep     |  112906\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113000, rl-loss: 0.3363201916217804\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 113050, rl-loss: 0.6371241211891174\n",
      "----------------------------------------\n",
      "  timestep     |  113050\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113191, rl-loss: 0.6583393812179565\n",
      "----------------------------------------\n",
      "  timestep     |  113191\n",
      "  reward       |  -0.019\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113347, rl-loss: 0.4509022533893585\n",
      "----------------------------------------\n",
      "  timestep     |  113347\n",
      "  reward       |  -0.082\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113495, rl-loss: 0.40846002101898193\n",
      "----------------------------------------\n",
      "  timestep     |  113495\n",
      "  reward       |  -0.137\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113645, rl-loss: 0.5526800155639648\n",
      "----------------------------------------\n",
      "  timestep     |  113645\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113782, rl-loss: 0.5232085585594177\n",
      "----------------------------------------\n",
      "  timestep     |  113782\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 113933, rl-loss: 0.5299097895622253\n",
      "----------------------------------------\n",
      "  timestep     |  113933\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114000, rl-loss: 0.47324463725090027\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 114077, rl-loss: 0.530369758605957\n",
      "----------------------------------------\n",
      "  timestep     |  114077\n",
      "  reward       |  -0.126\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114223, rl-loss: 0.32195883989334106\n",
      "----------------------------------------\n",
      "  timestep     |  114223\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114370, rl-loss: 0.46976929903030396\n",
      "----------------------------------------\n",
      "  timestep     |  114370\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114509, rl-loss: 0.4964026212692261\n",
      "----------------------------------------\n",
      "  timestep     |  114509\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114667, rl-loss: 0.5370544195175171\n",
      "----------------------------------------\n",
      "  timestep     |  114667\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114811, rl-loss: 0.44749951362609863\n",
      "----------------------------------------\n",
      "  timestep     |  114811\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 114961, rl-loss: 0.37429413199424744\n",
      "----------------------------------------\n",
      "  timestep     |  114961\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115000, rl-loss: 0.5027614235877991\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 115113, rl-loss: 0.4339912533760071\n",
      "----------------------------------------\n",
      "  timestep     |  115113\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115251, rl-loss: 0.5833022594451904\n",
      "----------------------------------------\n",
      "  timestep     |  115251\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115390, rl-loss: 0.31532377004623413\n",
      "----------------------------------------\n",
      "  timestep     |  115390\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115532, rl-loss: 0.718953013420105\n",
      "----------------------------------------\n",
      "  timestep     |  115532\n",
      "  reward       |  -0.101\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115678, rl-loss: 0.5251914262771606\n",
      "----------------------------------------\n",
      "  timestep     |  115678\n",
      "  reward       |  -0.138\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115830, rl-loss: 0.5214082598686218\n",
      "----------------------------------------\n",
      "  timestep     |  115830\n",
      "  reward       |  -0.081\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 115966, rl-loss: 0.4906373918056488\n",
      "----------------------------------------\n",
      "  timestep     |  115966\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116000, rl-loss: 0.5692116022109985\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 116113, rl-loss: 0.4663490355014801\n",
      "----------------------------------------\n",
      "  timestep     |  116113\n",
      "  reward       |  -0.042\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116258, rl-loss: 0.635725736618042\n",
      "----------------------------------------\n",
      "  timestep     |  116258\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116397, rl-loss: 0.5939566493034363\n",
      "----------------------------------------\n",
      "  timestep     |  116397\n",
      "  reward       |  -0.068\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116541, rl-loss: 0.40611231327056885\n",
      "----------------------------------------\n",
      "  timestep     |  116541\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116679, rl-loss: 0.4761885404586792\n",
      "----------------------------------------\n",
      "  timestep     |  116679\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116831, rl-loss: 0.5723481774330139\n",
      "----------------------------------------\n",
      "  timestep     |  116831\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 116998, rl-loss: 0.41268840432167053\n",
      "----------------------------------------\n",
      "  timestep     |  116998\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 117000, rl-loss: 0.6163109540939331\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 117133, rl-loss: 0.3503321409225464\n",
      "----------------------------------------\n",
      "  timestep     |  117133\n",
      "  reward       |  0.004\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 117280, rl-loss: 0.5829837322235107\n",
      "----------------------------------------\n",
      "  timestep     |  117280\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 117423, rl-loss: 0.6535555720329285\n",
      "----------------------------------------\n",
      "  timestep     |  117423\n",
      "  reward       |  -0.088\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 117562, rl-loss: 0.4871273636817932\n",
      "----------------------------------------\n",
      "  timestep     |  117562\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 117713, rl-loss: 0.6293514370918274\n",
      "----------------------------------------\n",
      "  timestep     |  117713\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 117859, rl-loss: 0.5306341648101807\n",
      "----------------------------------------\n",
      "  timestep     |  117859\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118000, rl-loss: 0.35871315002441406\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 118002, rl-loss: 0.44312942028045654\n",
      "----------------------------------------\n",
      "  timestep     |  118002\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118143, rl-loss: 0.3322272300720215\n",
      "----------------------------------------\n",
      "  timestep     |  118143\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118290, rl-loss: 0.5732303261756897\n",
      "----------------------------------------\n",
      "  timestep     |  118290\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118442, rl-loss: 0.5259542465209961\n",
      "----------------------------------------\n",
      "  timestep     |  118442\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118572, rl-loss: 0.3502967059612274\n",
      "----------------------------------------\n",
      "  timestep     |  118572\n",
      "  reward       |  -0.001\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118702, rl-loss: 0.429727166891098\n",
      "----------------------------------------\n",
      "  timestep     |  118702\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118836, rl-loss: 0.6181633472442627\n",
      "----------------------------------------\n",
      "  timestep     |  118836\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 118984, rl-loss: 0.4280286431312561\n",
      "----------------------------------------\n",
      "  timestep     |  118984\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 119000, rl-loss: 0.5122540593147278\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 119131, rl-loss: 0.4400874972343445\n",
      "----------------------------------------\n",
      "  timestep     |  119131\n",
      "  reward       |  -0.01\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 119275, rl-loss: 0.5027366876602173\n",
      "----------------------------------------\n",
      "  timestep     |  119275\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 119417, rl-loss: 0.6852118372917175\n",
      "----------------------------------------\n",
      "  timestep     |  119417\n",
      "  reward       |  -0.016\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 119558, rl-loss: 0.3967164158821106\n",
      "----------------------------------------\n",
      "  timestep     |  119558\n",
      "  reward       |  -0.05\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 119712, rl-loss: 0.4745903015136719\n",
      "----------------------------------------\n",
      "  timestep     |  119712\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 119857, rl-loss: 0.3776606321334839\n",
      "----------------------------------------\n",
      "  timestep     |  119857\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120000, rl-loss: 0.5745092630386353\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 120002, rl-loss: 0.5813181400299072\n",
      "----------------------------------------\n",
      "  timestep     |  120002\n",
      "  reward       |  -0.017\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120138, rl-loss: 0.6754693984985352\n",
      "----------------------------------------\n",
      "  timestep     |  120138\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120281, rl-loss: 0.5716297030448914\n",
      "----------------------------------------\n",
      "  timestep     |  120281\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120414, rl-loss: 0.5604127645492554\n",
      "----------------------------------------\n",
      "  timestep     |  120414\n",
      "  reward       |  -0.085\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120570, rl-loss: 0.5461567640304565\n",
      "----------------------------------------\n",
      "  timestep     |  120570\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120712, rl-loss: 0.46344056725502014\n",
      "----------------------------------------\n",
      "  timestep     |  120712\n",
      "  reward       |  -0.123\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120849, rl-loss: 0.4952230155467987\n",
      "----------------------------------------\n",
      "  timestep     |  120849\n",
      "  reward       |  -0.124\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 120989, rl-loss: 0.461157888174057\n",
      "----------------------------------------\n",
      "  timestep     |  120989\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 121000, rl-loss: 0.47855523228645325\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 121131, rl-loss: 0.493319571018219\n",
      "----------------------------------------\n",
      "  timestep     |  121131\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 121271, rl-loss: 0.7537442445755005\n",
      "----------------------------------------\n",
      "  timestep     |  121271\n",
      "  reward       |  -0.074\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 121415, rl-loss: 0.47908324003219604\n",
      "----------------------------------------\n",
      "  timestep     |  121415\n",
      "  reward       |  -0.069\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 121561, rl-loss: 0.4717117249965668\n",
      "----------------------------------------\n",
      "  timestep     |  121561\n",
      "  reward       |  -0.065\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 121712, rl-loss: 0.5535387992858887\n",
      "----------------------------------------\n",
      "  timestep     |  121712\n",
      "  reward       |  -0.075\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 121867, rl-loss: 0.5060806274414062\n",
      "----------------------------------------\n",
      "  timestep     |  121867\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122000, rl-loss: 0.6442422866821289\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 122017, rl-loss: 0.4729679524898529\n",
      "----------------------------------------\n",
      "  timestep     |  122017\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122153, rl-loss: 0.4469790458679199\n",
      "----------------------------------------\n",
      "  timestep     |  122153\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122294, rl-loss: 0.4844411015510559\n",
      "----------------------------------------\n",
      "  timestep     |  122294\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122443, rl-loss: 0.4010114371776581\n",
      "----------------------------------------\n",
      "  timestep     |  122443\n",
      "  reward       |  -0.098\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122583, rl-loss: 0.5500255227088928\n",
      "----------------------------------------\n",
      "  timestep     |  122583\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122736, rl-loss: 0.4786374568939209\n",
      "----------------------------------------\n",
      "  timestep     |  122736\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 122879, rl-loss: 0.497319757938385\n",
      "----------------------------------------\n",
      "  timestep     |  122879\n",
      "  reward       |  -0.111\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123000, rl-loss: 0.4897194504737854\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 123034, rl-loss: 0.45644479990005493\n",
      "----------------------------------------\n",
      "  timestep     |  123034\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123185, rl-loss: 0.5248267650604248\n",
      "----------------------------------------\n",
      "  timestep     |  123185\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123335, rl-loss: 0.516223132610321\n",
      "----------------------------------------\n",
      "  timestep     |  123335\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123481, rl-loss: 0.47616398334503174\n",
      "----------------------------------------\n",
      "  timestep     |  123481\n",
      "  reward       |  -0.086\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123642, rl-loss: 0.9797466397285461\n",
      "----------------------------------------\n",
      "  timestep     |  123642\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123795, rl-loss: 0.5161985158920288\n",
      "----------------------------------------\n",
      "  timestep     |  123795\n",
      "  reward       |  0.013\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 123943, rl-loss: 0.44504040479660034\n",
      "----------------------------------------\n",
      "  timestep     |  123943\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124000, rl-loss: 0.44359955191612244\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 124094, rl-loss: 0.646616518497467\n",
      "----------------------------------------\n",
      "  timestep     |  124094\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124244, rl-loss: 0.6334704756736755\n",
      "----------------------------------------\n",
      "  timestep     |  124244\n",
      "  reward       |  -0.008\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124389, rl-loss: 0.48768502473831177\n",
      "----------------------------------------\n",
      "  timestep     |  124389\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124528, rl-loss: 0.426659494638443\n",
      "----------------------------------------\n",
      "  timestep     |  124528\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124669, rl-loss: 0.31362107396125793\n",
      "----------------------------------------\n",
      "  timestep     |  124669\n",
      "  reward       |  -0.024\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124809, rl-loss: 0.4724041521549225\n",
      "----------------------------------------\n",
      "  timestep     |  124809\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 124945, rl-loss: 0.6240391135215759\n",
      "----------------------------------------\n",
      "  timestep     |  124945\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125000, rl-loss: 0.5085854530334473\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 125093, rl-loss: 0.4114252030849457\n",
      "----------------------------------------\n",
      "  timestep     |  125093\n",
      "  reward       |  -0.099\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125240, rl-loss: 0.5038965940475464\n",
      "----------------------------------------\n",
      "  timestep     |  125240\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125383, rl-loss: 0.504831075668335\n",
      "----------------------------------------\n",
      "  timestep     |  125383\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125523, rl-loss: 0.5401797294616699\n",
      "----------------------------------------\n",
      "  timestep     |  125523\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125680, rl-loss: 0.6110773086547852\n",
      "----------------------------------------\n",
      "  timestep     |  125680\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125822, rl-loss: 0.4844714105129242\n",
      "----------------------------------------\n",
      "  timestep     |  125822\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 125958, rl-loss: 0.6472167372703552\n",
      "----------------------------------------\n",
      "  timestep     |  125958\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126000, rl-loss: 0.3589527904987335\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 126107, rl-loss: 0.4163025915622711\n",
      "----------------------------------------\n",
      "  timestep     |  126107\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126250, rl-loss: 0.7246010303497314\n",
      "----------------------------------------\n",
      "  timestep     |  126250\n",
      "  reward       |  -0.097\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126392, rl-loss: 0.5500935316085815\n",
      "----------------------------------------\n",
      "  timestep     |  126392\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126545, rl-loss: 0.5151195526123047\n",
      "----------------------------------------\n",
      "  timestep     |  126545\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126690, rl-loss: 0.5243068337440491\n",
      "----------------------------------------\n",
      "  timestep     |  126690\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126837, rl-loss: 0.6601852178573608\n",
      "----------------------------------------\n",
      "  timestep     |  126837\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 126974, rl-loss: 0.6488114595413208\n",
      "----------------------------------------\n",
      "  timestep     |  126974\n",
      "  reward       |  -0.103\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127000, rl-loss: 0.6812307834625244\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 127120, rl-loss: 0.6457487344741821\n",
      "----------------------------------------\n",
      "  timestep     |  127120\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127267, rl-loss: 0.5528414249420166\n",
      "----------------------------------------\n",
      "  timestep     |  127267\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127410, rl-loss: 0.5258584022521973\n",
      "----------------------------------------\n",
      "  timestep     |  127410\n",
      "  reward       |  -0.095\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127552, rl-loss: 0.6610387563705444\n",
      "----------------------------------------\n",
      "  timestep     |  127552\n",
      "  reward       |  -0.104\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127685, rl-loss: 0.5895182490348816\n",
      "----------------------------------------\n",
      "  timestep     |  127685\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127834, rl-loss: 0.40087300539016724\n",
      "----------------------------------------\n",
      "  timestep     |  127834\n",
      "  reward       |  -0.12\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 127965, rl-loss: 0.7606958746910095\n",
      "----------------------------------------\n",
      "  timestep     |  127965\n",
      "  reward       |  -0.084\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128000, rl-loss: 0.5205921530723572\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 128103, rl-loss: 0.4822423458099365\n",
      "----------------------------------------\n",
      "  timestep     |  128103\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128261, rl-loss: 0.5181061625480652\n",
      "----------------------------------------\n",
      "  timestep     |  128261\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128414, rl-loss: 0.5118052363395691\n",
      "----------------------------------------\n",
      "  timestep     |  128414\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128564, rl-loss: 0.6758720874786377\n",
      "----------------------------------------\n",
      "  timestep     |  128564\n",
      "  reward       |  -0.129\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128695, rl-loss: 0.692479133605957\n",
      "----------------------------------------\n",
      "  timestep     |  128695\n",
      "  reward       |  -0.073\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128847, rl-loss: 0.8047934770584106\n",
      "----------------------------------------\n",
      "  timestep     |  128847\n",
      "  reward       |  -0.052\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 128992, rl-loss: 0.49606189131736755\n",
      "----------------------------------------\n",
      "  timestep     |  128992\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 129000, rl-loss: 0.43505772948265076\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 129148, rl-loss: 0.47919294238090515\n",
      "----------------------------------------\n",
      "  timestep     |  129148\n",
      "  reward       |  -0.115\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 129296, rl-loss: 0.39006006717681885\n",
      "----------------------------------------\n",
      "  timestep     |  129296\n",
      "  reward       |  -0.08\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 129453, rl-loss: 0.3824699819087982\n",
      "----------------------------------------\n",
      "  timestep     |  129453\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 129598, rl-loss: 0.42976996302604675\n",
      "----------------------------------------\n",
      "  timestep     |  129598\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 129751, rl-loss: 0.453967809677124\n",
      "----------------------------------------\n",
      "  timestep     |  129751\n",
      "  reward       |  -0.062\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 129907, rl-loss: 0.6719974875450134\n",
      "----------------------------------------\n",
      "  timestep     |  129907\n",
      "  reward       |  -0.072\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130000, rl-loss: 0.5532834529876709\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 130060, rl-loss: 0.6275860667228699\n",
      "----------------------------------------\n",
      "  timestep     |  130060\n",
      "  reward       |  -0.089\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130213, rl-loss: 0.6308028697967529\n",
      "----------------------------------------\n",
      "  timestep     |  130213\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130362, rl-loss: 0.45977967977523804\n",
      "----------------------------------------\n",
      "  timestep     |  130362\n",
      "  reward       |  -0.048\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130508, rl-loss: 0.37066522240638733\n",
      "----------------------------------------\n",
      "  timestep     |  130508\n",
      "  reward       |  -0.093\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130655, rl-loss: 0.5693047046661377\n",
      "----------------------------------------\n",
      "  timestep     |  130655\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130794, rl-loss: 0.7647050023078918\n",
      "----------------------------------------\n",
      "  timestep     |  130794\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 130935, rl-loss: 0.5868184566497803\n",
      "----------------------------------------\n",
      "  timestep     |  130935\n",
      "  reward       |  -0.049\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131000, rl-loss: 0.37112924456596375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 131077, rl-loss: 0.4347766637802124\n",
      "----------------------------------------\n",
      "  timestep     |  131077\n",
      "  reward       |  -0.003\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131223, rl-loss: 0.5238437056541443\n",
      "----------------------------------------\n",
      "  timestep     |  131223\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131374, rl-loss: 0.2902410924434662\n",
      "----------------------------------------\n",
      "  timestep     |  131374\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131523, rl-loss: 0.2738009989261627\n",
      "----------------------------------------\n",
      "  timestep     |  131523\n",
      "  reward       |  -0.147\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131669, rl-loss: 0.5033906102180481\n",
      "----------------------------------------\n",
      "  timestep     |  131669\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131817, rl-loss: 0.4486483633518219\n",
      "----------------------------------------\n",
      "  timestep     |  131817\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 131978, rl-loss: 0.6562229990959167\n",
      "----------------------------------------\n",
      "  timestep     |  131978\n",
      "  reward       |  -0.113\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 132000, rl-loss: 0.5372892618179321\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 132135, rl-loss: 0.45873287320137024\n",
      "----------------------------------------\n",
      "  timestep     |  132135\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 132279, rl-loss: 0.42368924617767334\n",
      "----------------------------------------\n",
      "  timestep     |  132279\n",
      "  reward       |  -0.029\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 132421, rl-loss: 0.6860417723655701\n",
      "----------------------------------------\n",
      "  timestep     |  132421\n",
      "  reward       |  -0.032\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 132567, rl-loss: 0.3809036612510681\n",
      "----------------------------------------\n",
      "  timestep     |  132567\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 132719, rl-loss: 0.5454434156417847\n",
      "----------------------------------------\n",
      "  timestep     |  132719\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 132867, rl-loss: 0.5817570686340332\n",
      "----------------------------------------\n",
      "  timestep     |  132867\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133000, rl-loss: 0.46755078434944153\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 133011, rl-loss: 0.4622785747051239\n",
      "----------------------------------------\n",
      "  timestep     |  133011\n",
      "  reward       |  0.0\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133153, rl-loss: 0.38498592376708984\n",
      "----------------------------------------\n",
      "  timestep     |  133153\n",
      "  reward       |  -0.122\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133308, rl-loss: 0.48373883962631226\n",
      "----------------------------------------\n",
      "  timestep     |  133308\n",
      "  reward       |  -0.045\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133446, rl-loss: 0.6439468860626221\n",
      "----------------------------------------\n",
      "  timestep     |  133446\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133589, rl-loss: 0.4060770869255066\n",
      "----------------------------------------\n",
      "  timestep     |  133589\n",
      "  reward       |  -0.102\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133749, rl-loss: 0.5620058178901672\n",
      "----------------------------------------\n",
      "  timestep     |  133749\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 133905, rl-loss: 0.4774453043937683\n",
      "----------------------------------------\n",
      "  timestep     |  133905\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134000, rl-loss: 0.5830134153366089\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 134068, rl-loss: 0.7371223568916321\n",
      "----------------------------------------\n",
      "  timestep     |  134068\n",
      "  reward       |  -0.027\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134217, rl-loss: 0.58460932970047\n",
      "----------------------------------------\n",
      "  timestep     |  134217\n",
      "  reward       |  -0.023\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134376, rl-loss: 0.5003510117530823\n",
      "----------------------------------------\n",
      "  timestep     |  134376\n",
      "  reward       |  -0.132\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134525, rl-loss: 0.4536053538322449\n",
      "----------------------------------------\n",
      "  timestep     |  134525\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134676, rl-loss: 0.7212874293327332\n",
      "----------------------------------------\n",
      "  timestep     |  134676\n",
      "  reward       |  -0.015\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134834, rl-loss: 0.42433270812034607\n",
      "----------------------------------------\n",
      "  timestep     |  134834\n",
      "  reward       |  -0.003\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 134986, rl-loss: 0.5615289807319641\n",
      "----------------------------------------\n",
      "  timestep     |  134986\n",
      "  reward       |  -0.083\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 135000, rl-loss: 0.5920879244804382\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 135137, rl-loss: 0.6723229885101318\n",
      "----------------------------------------\n",
      "  timestep     |  135137\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 135297, rl-loss: 0.4685673117637634\n",
      "----------------------------------------\n",
      "  timestep     |  135297\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 135459, rl-loss: 0.46600914001464844\n",
      "----------------------------------------\n",
      "  timestep     |  135459\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 135619, rl-loss: 0.46348321437835693\n",
      "----------------------------------------\n",
      "  timestep     |  135619\n",
      "  reward       |  -0.058\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 135761, rl-loss: 0.44543397426605225\n",
      "----------------------------------------\n",
      "  timestep     |  135761\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 135911, rl-loss: 0.5827592015266418\n",
      "----------------------------------------\n",
      "  timestep     |  135911\n",
      "  reward       |  -0.053\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136000, rl-loss: 0.5343718528747559\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 136070, rl-loss: 0.5808678269386292\n",
      "----------------------------------------\n",
      "  timestep     |  136070\n",
      "  reward       |  -0.046\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136215, rl-loss: 0.6199212074279785\n",
      "----------------------------------------\n",
      "  timestep     |  136215\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136361, rl-loss: 0.6377355456352234\n",
      "----------------------------------------\n",
      "  timestep     |  136361\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136524, rl-loss: 0.4763968288898468\n",
      "----------------------------------------\n",
      "  timestep     |  136524\n",
      "  reward       |  -0.044\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136668, rl-loss: 0.557263195514679\n",
      "----------------------------------------\n",
      "  timestep     |  136668\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136820, rl-loss: 0.6357612013816833\n",
      "----------------------------------------\n",
      "  timestep     |  136820\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 136981, rl-loss: 0.46012216806411743\n",
      "----------------------------------------\n",
      "  timestep     |  136981\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 137000, rl-loss: 0.5676193237304688\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 137129, rl-loss: 0.584048867225647\n",
      "----------------------------------------\n",
      "  timestep     |  137129\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 137276, rl-loss: 0.5605533123016357\n",
      "----------------------------------------\n",
      "  timestep     |  137276\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 137414, rl-loss: 0.6451692581176758\n",
      "----------------------------------------\n",
      "  timestep     |  137414\n",
      "  reward       |  -0.11\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 137556, rl-loss: 0.6857713460922241\n",
      "----------------------------------------\n",
      "  timestep     |  137556\n",
      "  reward       |  -0.1\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 137716, rl-loss: 0.46341055631637573\n",
      "----------------------------------------\n",
      "  timestep     |  137716\n",
      "  reward       |  -0.021\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 137873, rl-loss: 0.632066547870636\n",
      "----------------------------------------\n",
      "  timestep     |  137873\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138000, rl-loss: 0.6040267944335938\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 138038, rl-loss: 0.36647120118141174\n",
      "----------------------------------------\n",
      "  timestep     |  138038\n",
      "  reward       |  -0.063\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138187, rl-loss: 0.4464680552482605\n",
      "----------------------------------------\n",
      "  timestep     |  138187\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138343, rl-loss: 0.41045746207237244\n",
      "----------------------------------------\n",
      "  timestep     |  138343\n",
      "  reward       |  -0.061\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138498, rl-loss: 0.5749521851539612\n",
      "----------------------------------------\n",
      "  timestep     |  138498\n",
      "  reward       |  -0.077\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138651, rl-loss: 0.5700881481170654\n",
      "----------------------------------------\n",
      "  timestep     |  138651\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138804, rl-loss: 0.6254477500915527\n",
      "----------------------------------------\n",
      "  timestep     |  138804\n",
      "  reward       |  0.009\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 138947, rl-loss: 0.35607650876045227\n",
      "----------------------------------------\n",
      "  timestep     |  138947\n",
      "  reward       |  -0.031\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 139000, rl-loss: 0.4450269937515259\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 139100, rl-loss: 0.7311612963676453\n",
      "----------------------------------------\n",
      "  timestep     |  139100\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 139253, rl-loss: 0.49805691838264465\n",
      "----------------------------------------\n",
      "  timestep     |  139253\n",
      "  reward       |  -0.047\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 139407, rl-loss: 0.557851254940033\n",
      "----------------------------------------\n",
      "  timestep     |  139407\n",
      "  reward       |  -0.07\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 139557, rl-loss: 0.3349171280860901\n",
      "----------------------------------------\n",
      "  timestep     |  139557\n",
      "  reward       |  -0.064\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 139714, rl-loss: 0.4263654351234436\n",
      "----------------------------------------\n",
      "  timestep     |  139714\n",
      "  reward       |  -0.026\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 139873, rl-loss: 0.3965124785900116\n",
      "----------------------------------------\n",
      "  timestep     |  139873\n",
      "  reward       |  -0.034\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140000, rl-loss: 0.3960770070552826\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 140019, rl-loss: 0.8397909998893738\n",
      "----------------------------------------\n",
      "  timestep     |  140019\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140176, rl-loss: 0.5004140138626099\n",
      "----------------------------------------\n",
      "  timestep     |  140176\n",
      "  reward       |  -0.112\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140320, rl-loss: 0.6023369431495667\n",
      "----------------------------------------\n",
      "  timestep     |  140320\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140462, rl-loss: 0.5113106369972229\n",
      "----------------------------------------\n",
      "  timestep     |  140462\n",
      "  reward       |  -0.135\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140604, rl-loss: 0.6038826107978821\n",
      "----------------------------------------\n",
      "  timestep     |  140604\n",
      "  reward       |  -0.013\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140746, rl-loss: 0.5278021097183228\n",
      "----------------------------------------\n",
      "  timestep     |  140746\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 140897, rl-loss: 0.5515774488449097\n",
      "----------------------------------------\n",
      "  timestep     |  140897\n",
      "  reward       |  -0.066\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141000, rl-loss: 0.6425791382789612\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 141051, rl-loss: 0.6120990514755249\n",
      "----------------------------------------\n",
      "  timestep     |  141051\n",
      "  reward       |  0.017\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141200, rl-loss: 0.4366786479949951\n",
      "----------------------------------------\n",
      "  timestep     |  141200\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141350, rl-loss: 0.612006425857544\n",
      "----------------------------------------\n",
      "  timestep     |  141350\n",
      "  reward       |  -0.096\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141506, rl-loss: 0.6357794404029846\n",
      "----------------------------------------\n",
      "  timestep     |  141506\n",
      "  reward       |  -0.076\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141655, rl-loss: 0.3368689715862274\n",
      "----------------------------------------\n",
      "  timestep     |  141655\n",
      "  reward       |  -0.109\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141808, rl-loss: 0.4418688118457794\n",
      "----------------------------------------\n",
      "  timestep     |  141808\n",
      "  reward       |  -0.079\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 141951, rl-loss: 0.6275419592857361\n",
      "----------------------------------------\n",
      "  timestep     |  141951\n",
      "  reward       |  -0.059\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 142000, rl-loss: 0.6884313821792603\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 142102, rl-loss: 0.5308616757392883\n",
      "----------------------------------------\n",
      "  timestep     |  142102\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 142248, rl-loss: 0.5069222450256348\n",
      "----------------------------------------\n",
      "  timestep     |  142248\n",
      "  reward       |  -0.078\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 142408, rl-loss: 0.5774020552635193\n",
      "----------------------------------------\n",
      "  timestep     |  142408\n",
      "  reward       |  -0.087\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 142568, rl-loss: 0.6193531155586243\n",
      "----------------------------------------\n",
      "  timestep     |  142568\n",
      "  reward       |  -0.06\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 142719, rl-loss: 0.5139647722244263\n",
      "----------------------------------------\n",
      "  timestep     |  142719\n",
      "  reward       |  -0.054\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 142861, rl-loss: 0.4688083231449127\n",
      "----------------------------------------\n",
      "  timestep     |  142861\n",
      "  reward       |  -0.043\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143000, rl-loss: 0.5014308094978333\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 143012, rl-loss: 0.5113641023635864\n",
      "----------------------------------------\n",
      "  timestep     |  143012\n",
      "  reward       |  -0.037\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143168, rl-loss: 0.5861127376556396\n",
      "----------------------------------------\n",
      "  timestep     |  143168\n",
      "  reward       |  -0.107\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143300, rl-loss: 0.5369675159454346\n",
      "----------------------------------------\n",
      "  timestep     |  143300\n",
      "  reward       |  -0.033\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143438, rl-loss: 0.4108164310455322\n",
      "----------------------------------------\n",
      "  timestep     |  143438\n",
      "  reward       |  -0.057\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143585, rl-loss: 0.5203489661216736\n",
      "----------------------------------------\n",
      "  timestep     |  143585\n",
      "  reward       |  -0.071\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143746, rl-loss: 0.38202568888664246\n",
      "----------------------------------------\n",
      "  timestep     |  143746\n",
      "  reward       |  -0.092\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 143897, rl-loss: 0.40268707275390625\n",
      "----------------------------------------\n",
      "  timestep     |  143897\n",
      "  reward       |  -0.051\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144000, rl-loss: 0.6408966183662415\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 144027, rl-loss: 0.5924964547157288\n",
      "----------------------------------------\n",
      "  timestep     |  144027\n",
      "  reward       |  -0.039\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144178, rl-loss: 0.6137310266494751\n",
      "----------------------------------------\n",
      "  timestep     |  144178\n",
      "  reward       |  -0.106\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144338, rl-loss: 0.44033336639404297\n",
      "----------------------------------------\n",
      "  timestep     |  144338\n",
      "  reward       |  -0.067\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144493, rl-loss: 0.48966044187545776\n",
      "----------------------------------------\n",
      "  timestep     |  144493\n",
      "  reward       |  -0.02\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144645, rl-loss: 0.7252539396286011\n",
      "----------------------------------------\n",
      "  timestep     |  144645\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144790, rl-loss: 0.3783685564994812\n",
      "----------------------------------------\n",
      "  timestep     |  144790\n",
      "  reward       |  -0.035\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 144951, rl-loss: 0.5856594443321228\n",
      "----------------------------------------\n",
      "  timestep     |  144951\n",
      "  reward       |  -0.094\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 145000, rl-loss: 0.4585196077823639\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 145102, rl-loss: 0.5553810596466064\n",
      "----------------------------------------\n",
      "  timestep     |  145102\n",
      "  reward       |  -0.091\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 145261, rl-loss: 0.5024046301841736\n",
      "----------------------------------------\n",
      "  timestep     |  145261\n",
      "  reward       |  -0.105\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 145404, rl-loss: 0.7690930962562561\n",
      "----------------------------------------\n",
      "  timestep     |  145404\n",
      "  reward       |  -0.055\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 145553, rl-loss: 0.5122385621070862\n",
      "----------------------------------------\n",
      "  timestep     |  145553\n",
      "  reward       |  -0.09\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 145704, rl-loss: 0.557452380657196\n",
      "----------------------------------------\n",
      "  timestep     |  145704\n",
      "  reward       |  -0.125\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 145865, rl-loss: 0.6237395405769348\n",
      "----------------------------------------\n",
      "  timestep     |  145865\n",
      "  reward       |  -0.056\n",
      "----------------------------------------\n",
      "INFO - Agent double dqn, step 146000, rl-loss: 0.5412867069244385\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Agent double dqn, step 146014, rl-loss: 0.5551947355270386./experiments/blackjack_double_dqn_result/performance.csv\n",
      "dict_keys(['double dqn_q_estimator', 'double dqn_target_estimator'])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 394.160937 262.19625\" width=\"394.160937pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-27T14:54:55.999356</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 394.160937 262.19625 \nL 394.160937 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 52.160938 224.64 \nL 386.960938 224.64 \nL 386.960938 7.2 \nL 52.160938 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 67.377033 224.64 \nL 67.377033 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9f647946b3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"67.377033\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(64.195783 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 109.109556 224.64 \nL 109.109556 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"109.109556\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20000 -->\n      <g transform=\"translate(93.203306 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 150.842079 224.64 \nL 150.842079 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.842079\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40000 -->\n      <g transform=\"translate(134.935829 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 192.574602 224.64 \nL 192.574602 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"192.574602\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60000 -->\n      <g transform=\"translate(176.668352 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 234.307124 224.64 \nL 234.307124 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.307124\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80000 -->\n      <g transform=\"translate(218.400874 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 276.039647 224.64 \nL 276.039647 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"276.039647\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100000 -->\n      <g transform=\"translate(256.952147 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 317.77217 224.64 \nL 317.77217 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"317.77217\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120000 -->\n      <g transform=\"translate(298.68467 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 359.504693 224.64 \nL 359.504693 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.504693\" xlink:href=\"#m9f647946b3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140000 -->\n      <g transform=\"translate(340.417193 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- timestep -->\n     <g transform=\"translate(197.449219 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"66.992188\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"164.404297\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"225.927734\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"278.027344\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"317.236328\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"378.759766\" xlink:href=\"#DejaVuSans-112\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 52.160938 223.695315 \nL 386.960938 223.695315 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m2712756b29\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#m2712756b29\" y=\"223.695315\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −1.0 -->\n      <g transform=\"translate(20.878125 227.494534)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 52.160938 183.063717 \nL 386.960938 183.063717 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#m2712756b29\" y=\"183.063717\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −0.8 -->\n      <g transform=\"translate(20.878125 186.862935)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 52.160938 142.432118 \nL 386.960938 142.432118 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#m2712756b29\" y=\"142.432118\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- −0.6 -->\n      <g transform=\"translate(20.878125 146.231337)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 52.160938 101.800519 \nL 386.960938 101.800519 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#m2712756b29\" y=\"101.800519\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- −0.4 -->\n      <g transform=\"translate(20.878125 105.599738)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 52.160938 61.168921 \nL 386.960938 61.168921 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#m2712756b29\" y=\"61.168921\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- −0.2 -->\n      <g transform=\"translate(20.878125 64.96814)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pd390b93753)\" d=\"M 52.160938 20.537322 \nL 386.960938 20.537322 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#m2712756b29\" y=\"20.537322\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.0 -->\n      <g transform=\"translate(29.257812 24.336541)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- reward -->\n     <g transform=\"translate(14.798437 133.234844)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"38.863281\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.386719\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"182.173828\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"243.453125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"282.816406\" xlink:href=\"#DejaVuSans-100\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#pd390b93753)\" d=\"M 67.379119 214.756364 \nL 67.654554 214.756364 \nL 67.925815 213.943732 \nL 68.203337 209.880572 \nL 68.789679 213.943732 \nL 69.396887 209.474256 \nL 69.686928 55.683655 \nL 69.995749 49.182599 \nL 70.26701 36.99312 \nL 70.534098 41.665754 \nL 70.803273 28.257326 \nL 71.11418 28.257326 \nL 71.944657 44.713123 \nL 72.215919 27.85101 \nL 72.522653 41.259438 \nL 72.800174 41.665754 \nL 73.075609 44.509965 \nL 73.378169 31.711012 \nL 73.653604 28.8668 \nL 73.954078 38.00891 \nL 74.260812 41.868912 \nL 74.54042 41.462596 \nL 74.811682 32.726802 \nL 75.103809 42.884701 \nL 75.379244 30.288906 \nL 75.675545 41.868912 \nL 75.969759 36.789962 \nL 76.261887 41.665754 \nL 76.556101 23.178376 \nL 76.844056 41.259438 \nL 77.123663 34.148908 \nL 77.417878 29.679432 \nL 77.703745 38.00891 \nL 78.008393 21.553112 \nL 78.317214 39.634174 \nL 78.628121 40.853122 \nL 78.909815 39.837332 \nL 79.189423 35.164698 \nL 79.481551 39.431016 \nL 79.771592 40.04049 \nL 80.080413 29.476274 \nL 80.374627 29.273116 \nL 80.658408 42.275228 \nL 80.960969 36.383646 \nL 81.234317 40.446806 \nL 82.081487 33.94575 \nL 82.379875 32.726802 \nL 82.663656 26.632062 \nL 82.924484 36.180488 \nL 83.222872 40.446806 \nL 83.521259 40.04049 \nL 83.800867 40.446806 \nL 84.076302 30.288906 \nL 84.637604 38.415226 \nL 84.935992 27.444694 \nL 85.223946 33.539434 \nL 85.499381 33.539434 \nL 85.785249 34.96154 \nL 86.098242 25.616272 \nL 86.400803 31.91417 \nL 86.669978 24.397324 \nL 86.955846 27.85101 \nL 87.28136 42.275228 \nL 87.57766 36.789962 \nL 88.147309 33.133118 \nL 88.439437 40.446806 \nL 88.739911 37.602594 \nL 89.027866 42.275228 \nL 89.620467 25.413114 \nL 89.923028 37.196278 \nL 90.227676 37.196278 \nL 90.52815 33.133118 \nL 90.807758 36.383646 \nL 91.101972 44.306807 \nL 91.744653 34.555224 \nL 92.070167 28.8668 \nL 92.374814 37.196278 \nL 92.677375 39.227858 \nL 92.979936 36.586804 \nL 93.299189 31.91417 \nL 93.618443 42.478385 \nL 93.916831 27.241536 \nL 94.213132 26.428904 \nL 94.513606 40.243648 \nL 94.81408 41.665754 \nL 95.116641 31.507854 \nL 95.394162 29.273116 \nL 95.970071 42.07207 \nL 96.264285 38.415226 \nL 96.577279 23.991008 \nL 96.865233 25.81943 \nL 97.169881 39.0247 \nL 97.491221 44.306807 \nL 97.822995 44.103649 \nL 98.131815 35.774172 \nL 98.461502 23.78785 \nL 98.776583 27.444694 \nL 99.367098 41.868912 \nL 99.675919 36.180488 \nL 99.97222 41.462596 \nL 100.583601 31.91417 \nL 100.894508 31.304696 \nL 101.18455 38.00891 \nL 101.482937 27.647852 \nL 101.772978 21.75627 \nL 102.094319 36.383646 \nL 102.426092 25.209956 \nL 102.764126 40.649964 \nL 103.085466 30.288906 \nL 103.40472 44.103649 \nL 103.73858 30.492064 \nL 104.070353 32.726802 \nL 104.372914 35.774172 \nL 104.687995 30.085748 \nL 104.996816 32.92996 \nL 105.28477 33.539434 \nL 105.593591 26.83522 \nL 105.879458 25.81943 \nL 106.177846 35.367856 \nL 106.482493 29.679432 \nL 106.80592 18.7089 \nL 107.102221 17.489952 \nL 107.711516 39.227858 \nL 107.997384 39.837332 \nL 108.285338 26.83522 \nL 108.921759 33.133118 \nL 109.245186 48.369967 \nL 109.560267 39.837332 \nL 109.860741 27.444694 \nL 110.177908 37.602594 \nL 110.484642 37.602594 \nL 110.808069 49.995231 \nL 111.11063 31.507854 \nL 111.400671 28.460484 \nL 111.713665 41.868912 \nL 112.026659 37.196278 \nL 112.320873 35.97733 \nL 112.635954 33.539434 \nL 112.955208 36.586804 \nL 113.272375 32.726802 \nL 113.585369 31.101538 \nL 113.88167 31.507854 \nL 114.20927 28.054168 \nL 114.56191 42.275228 \nL 114.851951 42.884701 \nL 115.148252 32.320486 \nL 115.480025 34.555224 \nL 115.795106 43.900491 \nL 116.11436 30.695222 \nL 116.439873 37.399436 \nL 116.752867 38.00891 \nL 117.070034 42.275228 \nL 117.360075 35.164698 \nL 117.63551 34.555224 \nL 117.948504 38.212068 \nL 118.251065 34.148908 \nL 118.574492 37.399436 \nL 119.139968 34.555224 \nL 119.745089 43.494175 \nL 120.05391 41.462596 \nL 120.356471 23.991008 \nL 120.667378 43.900491 \nL 121.274586 29.88259 \nL 121.570887 30.085748 \nL 121.877621 35.571014 \nL 122.213568 35.571014 \nL 122.501522 43.291017 \nL 122.797823 25.413114 \nL 123.119164 39.837332 \nL 123.413378 29.069958 \nL 123.724285 33.133118 \nL 124.053972 31.711012 \nL 124.362793 37.602594 \nL 124.627794 29.069958 \nL 124.932442 22.975218 \nL 125.257955 20.131006 \nL 125.560516 32.726802 \nL 125.869337 29.88259 \nL 126.161465 32.726802 \nL 126.449419 37.602594 \nL 126.737373 38.00891 \nL 127.023241 33.742592 \nL 127.304936 36.586804 \nL 127.60541 30.695222 \nL 127.907971 38.212068 \nL 128.218878 31.101538 \nL 128.533958 42.07207 \nL 128.861559 36.586804 \nL 129.174553 26.632062 \nL 129.470854 43.494175 \nL 129.767154 34.352066 \nL 130.073889 29.679432 \nL 130.366016 32.523644 \nL 130.676923 31.304696 \nL 131.000351 34.148908 \nL 131.330037 29.88259 \nL 131.624252 29.069958 \nL 131.947679 34.352066 \nL 132.256499 18.099426 \nL 132.575753 29.679432 \nL 132.91796 31.711012 \nL 133.228867 27.444694 \nL 133.520995 32.92996 \nL 133.821469 41.665754 \nL 134.132376 38.212068 \nL 134.43911 31.711012 \nL 134.747931 22.365744 \nL 135.037972 37.805752 \nL 135.321753 32.92996 \nL 135.630574 41.665754 \nL 135.937308 24.397324 \nL 136.264908 27.038378 \nL 136.563296 35.571014 \nL 136.874203 31.304696 \nL 137.18511 39.431016 \nL 137.510624 31.101538 \nL 137.846571 36.99312 \nL 138.153305 33.94575 \nL 138.453779 41.868912 \nL 138.75008 26.022588 \nL 139.052641 38.212068 \nL 139.357288 20.943638 \nL 139.674455 34.758382 \nL 139.985363 23.584692 \nL 140.298357 36.99312 \nL 140.607177 35.571014 \nL 140.905565 40.853122 \nL 141.220645 27.85101 \nL 141.531553 28.8668 \nL 141.84872 37.602594 \nL 142.174234 36.99312 \nL 142.499747 29.476274 \nL 142.798135 37.196278 \nL 143.077743 21.75627 \nL 143.36987 29.069958 \nL 143.993772 35.97733 \nL 144.306765 28.8668 \nL 144.623933 27.241536 \nL 144.924407 31.91417 \nL 145.229054 29.069958 \nL 145.558741 42.681543 \nL 145.855042 32.726802 \nL 146.168036 34.96154 \nL 146.466424 42.275228 \nL 147.073632 34.96154 \nL 147.355326 39.634174 \nL 147.685013 33.94575 \nL 147.995921 24.600482 \nL 148.304741 42.884701 \nL 148.609389 32.523644 \nL 148.909863 27.85101 \nL 149.210337 28.054168 \nL 149.531677 38.00891 \nL 149.842585 41.259438 \nL 150.153492 47.557335 \nL 150.462313 42.275228 \nL 150.750267 28.663642 \nL 151.046568 33.742592 \nL 151.349129 30.492064 \nL 151.660036 33.336276 \nL 151.995983 35.367856 \nL 152.626144 42.478385 \nL 152.928705 39.227858 \nL 153.231266 40.649964 \nL 153.546346 43.087859 \nL 153.844734 36.99312 \nL 154.443595 29.476274 \nL 154.752416 34.148908 \nL 155.048717 26.225746 \nL 155.39301 44.306807 \nL 155.699744 29.476274 \nL 156.016911 25.209956 \nL 156.317386 38.821542 \nL 156.632466 47.760493 \nL 156.949633 25.413114 \nL 157.237588 40.853122 \nL 157.529715 35.774172 \nL 157.83019 28.054168 \nL 158.13275 35.164698 \nL 158.449918 39.837332 \nL 158.752478 36.99312 \nL 159.059212 31.304696 \nL 159.365946 30.695222 \nL 159.676854 34.352066 \nL 159.964808 28.8668 \nL 160.292408 29.273116 \nL 160.590796 43.494175 \nL 160.912136 41.462596 \nL 161.554817 25.209956 \nL 161.869898 40.446806 \nL 162.191238 26.022588 \nL 162.504232 40.04049 \nL 162.829746 30.085748 \nL 163.149 45.322597 \nL 163.474513 30.89838 \nL 163.764554 38.00891 \nL 164.079635 31.304696 \nL 164.386369 22.365744 \nL 164.691016 42.07207 \nL 164.999837 39.634174 \nL 165.312831 44.916281 \nL 166.247639 23.991008 \nL 166.525161 29.273116 \nL 166.840241 28.663642 \nL 167.149062 33.336276 \nL 167.451623 20.943638 \nL 167.735404 23.78785 \nL 168.292533 36.99312 \nL 168.584661 40.243648 \nL 168.887222 39.431016 \nL 169.198129 32.726802 \nL 169.492343 45.322597 \nL 169.826203 44.509965 \nL 170.139197 28.460484 \nL 170.443845 38.00891 \nL 170.773532 26.022588 \nL 171.622788 38.212068 \nL 171.89405 37.805752 \nL 172.200784 30.492064 \nL 172.505431 30.288906 \nL 172.814252 41.05628 \nL 173.137679 39.837332 \nL 173.436067 32.523644 \nL 173.74906 41.259438 \nL 174.059968 36.586804 \nL 174.360442 34.555224 \nL 174.658829 36.180488 \nL 174.953044 21.75627 \nL 175.261864 33.336276 \nL 175.566512 26.022588 \nL 175.85238 29.069958 \nL 176.17372 31.304696 \nL 176.50758 28.663642 \nL 176.812228 29.069958 \nL 177.098095 26.022588 \nL 177.415263 32.320486 \nL 177.705304 25.413114 \nL 178.016211 25.413114 \nL 178.327118 39.837332 \nL 178.90094 25.616272 \nL 179.182635 41.05628 \nL 179.478936 31.91417 \nL 179.781497 44.916281 \nL 180.084057 44.306807 \nL 180.372012 40.243648 \nL 180.65788 37.805752 \nL 180.945834 43.291017 \nL 181.225442 20.131006 \nL 181.544696 27.647852 \nL 181.836823 30.085748 \nL 182.122691 27.241536 \nL 182.723639 33.742592 \nL 183.03872 30.89838 \nL 183.341281 42.681543 \nL 183.650102 23.178376 \nL 184.228097 36.789962 \nL 184.497272 36.586804 \nL 184.791486 19.521532 \nL 185.087787 38.415226 \nL 185.373655 26.225746 \nL 185.701255 33.133118 \nL 185.999643 32.117328 \nL 186.306377 37.602594 \nL 186.608937 35.774172 \nL 186.932364 30.695222 \nL 187.249532 33.94575 \nL 187.568785 32.726802 \nL 187.883866 22.975218 \nL 188.20312 25.81943 \nL 188.522374 27.038378 \nL 188.820761 33.94575 \nL 189.127495 29.88259 \nL 189.448836 39.837332 \nL 189.774349 26.022588 \nL 190.07065 40.853122 \nL 190.366951 29.476274 \nL 190.673685 51.620495 \nL 191.251681 25.616272 \nL 191.554241 17.69311 \nL 191.867235 36.180488 \nL 192.173969 32.726802 \nL 192.493223 31.91417 \nL 192.81039 27.038378 \nL 193.115038 24.194166 \nL 193.738939 35.164698 \nL 194.0415 33.336276 \nL 194.339887 29.273116 \nL 194.646621 28.663642 \nL 194.938749 35.571014 \nL 195.239223 31.101538 \nL 195.539697 45.119439 \nL 195.838085 49.385757 \nL 196.161512 42.07207 \nL 196.443206 25.81943 \nL 196.743681 41.462596 \nL 197.058761 41.665754 \nL 197.371755 23.991008 \nL 197.997743 34.96154 \nL 198.279437 21.959428 \nL 198.590345 36.99312 \nL 198.888732 40.853122 \nL 199.207986 31.507854 \nL 199.516807 35.97733 \nL 199.796415 32.92996 \nL 200.117755 23.381534 \nL 200.754176 36.586804 \nL 201.052564 37.399436 \nL 201.369731 33.133118 \nL 201.682725 27.038378 \nL 202.004065 42.275228 \nL 202.29202 33.539434 \nL 202.605013 32.726802 \nL 202.907574 28.8668 \nL 203.231001 30.695222 \nL 203.539822 39.227858 \nL 203.83195 31.91417 \nL 204.111558 29.069958 \nL 204.401599 43.900491 \nL 204.702073 26.83522 \nL 204.992114 43.291017 \nL 205.309281 29.069958 \nL 205.605582 27.647852 \nL 205.910229 36.180488 \nL 206.183577 37.602594 \nL 206.461099 33.742592 \nL 206.757399 34.758382 \nL 207.045354 40.446806 \nL 207.654649 31.101538 \nL 207.934257 22.162586 \nL 208.218038 50.807863 \nL 208.816899 24.80364 \nL 209.15702 35.367856 \nL 209.753795 28.460484 \nL 210.054269 34.555224 \nL 210.358916 27.85101 \nL 210.646871 33.94575 \nL 210.947345 33.539434 \nL 211.254079 36.180488 \nL 211.552466 32.92996 \nL 211.861287 38.212068 \nL 212.165934 39.227858 \nL 212.481015 33.133118 \nL 212.783576 36.383646 \nL 213.104916 43.697333 \nL 213.432517 27.647852 \nL 214.010512 38.00891 \nL 214.313073 51.620495 \nL 214.613547 35.571014 \nL 214.916108 30.695222 \nL 215.231188 36.789962 \nL 215.531662 34.148908 \nL 215.832137 37.805752 \nL 216.136784 34.148908 \nL 216.441431 24.80364 \nL 216.731472 36.180488 \nL 217.01734 37.196278 \nL 217.324074 35.774172 \nL 217.605769 31.507854 \nL 217.89581 45.932071 \nL 218.212977 32.320486 \nL 218.513451 31.91417 \nL 218.813925 19.521532 \nL 219.124833 36.586804 \nL 219.43574 22.162586 \nL 219.734127 33.94575 \nL 220.001216 34.555224 \nL 220.305863 27.444694 \nL 220.591731 43.697333 \nL 220.877599 28.054168 \nL 221.182246 28.663642 \nL 221.4702 27.647852 \nL 221.783194 26.022588 \nL 222.094102 40.04049 \nL 222.405009 35.774172 \nL 222.70757 22.162586 \nL 222.995524 37.602594 \nL 223.302258 37.602594 \nL 223.600646 39.837332 \nL 223.911553 33.742592 \nL 224.214114 32.92996 \nL 224.522934 35.97733 \nL 224.840102 25.413114 \nL 225.142662 28.8668 \nL 225.45357 39.0247 \nL 225.743611 37.805752 \nL 226.069124 31.507854 \nL 226.369599 23.381534 \nL 226.65964 42.275228 \nL 226.96846 25.413114 \nL 227.275194 19.72469 \nL 227.579842 35.97733 \nL 227.884489 30.695222 \nL 228.16201 38.00891 \nL 228.456225 38.00891 \nL 228.756699 39.0247 \nL 229.050913 27.444694 \nL 229.351387 27.241536 \nL 229.649775 44.916281 \nL 230.248637 26.225746 \nL 230.559544 27.444694 \nL 231.187618 44.509965 \nL 231.492266 25.006798 \nL 231.769787 34.758382 \nL 232.084868 34.148908 \nL 232.381169 29.069958 \nL 232.692076 33.336276 \nL 233.01133 25.006798 \nL 233.307631 30.492064 \nL 233.610191 45.525755 \nL 233.908579 33.133118 \nL 234.209053 35.774172 \nL 234.522047 30.695222 \nL 234.835041 29.273116 \nL 235.139688 32.320486 \nL 235.452682 39.431016 \nL 235.774023 26.83522 \nL 236.089103 30.288906 \nL 236.41253 29.273116 \nL 236.75265 44.509965 \nL 237.051038 43.697333 \nL 237.370292 25.616272 \nL 237.666593 30.288906 \nL 237.97124 39.634174 \nL 238.282147 38.212068 \nL 238.595141 25.81943 \nL 238.889356 41.05628 \nL 239.19609 30.89838 \nL 239.790778 34.758382 \nL 240.082906 34.352066 \nL 240.37712 33.133118 \nL 240.690114 35.571014 \nL 240.969722 32.92996 \nL 241.238897 26.225746 \nL 241.543544 49.588915 \nL 241.841932 35.571014 \nL 242.144492 48.166809 \nL 242.447053 30.695222 \nL 242.768394 34.758382 \nL 243.048001 46.947861 \nL 243.348476 33.539434 \nL 243.63643 27.85101 \nL 243.943164 36.99312 \nL 244.218599 28.460484 \nL 244.529506 33.133118 \nL 244.82998 26.225746 \nL 245.124194 26.428904 \nL 245.458055 41.05628 \nL 245.762702 29.679432 \nL 246.067349 31.101538 \nL 246.334438 38.00891 \nL 246.616132 36.586804 \nL 246.927039 32.523644 \nL 247.225427 39.227858 \nL 247.830549 26.225746 \nL 248.131023 40.04049 \nL 248.450277 35.164698 \nL 248.761184 22.162586 \nL 249.040792 38.618384 \nL 249.337093 26.022588 \nL 249.652173 36.180488 \nL 249.956821 25.81943 \nL 250.238515 23.78785 \nL 250.543163 31.101538 \nL 250.858243 32.117328 \nL 251.154544 34.758382 \nL 251.475884 30.492064 \nL 251.790965 22.162586 \nL 252.097699 28.663642 \nL 252.414866 25.209956 \nL 252.7216 29.476274 \nL 253.022074 28.460484 \nL 253.305856 35.774172 \nL 253.61259 23.584692 \nL 253.942277 31.101538 \nL 254.26153 23.78785 \nL 254.524445 34.758382 \nL 254.80614 22.568902 \nL 255.112874 34.555224 \nL 255.419608 39.431016 \nL 255.697129 33.539434 \nL 256.014296 33.94575 \nL 256.337723 33.336276 \nL 256.669497 34.352066 \nL 256.961625 41.259438 \nL 257.276705 32.523644 \nL 257.577179 43.087859 \nL 258.184387 30.492064 \nL 258.505728 40.446806 \nL 258.806202 30.085748 \nL 259.129629 25.616272 \nL 259.42593 37.196278 \nL 259.726404 25.81943 \nL 260.031052 39.837332 \nL 260.352392 35.774172 \nL 260.96586 48.573125 \nL 261.568895 31.304696 \nL 261.863109 34.96154 \nL 262.167757 34.352066 \nL 262.749925 30.695222 \nL 263.048313 39.227858 \nL 263.336267 38.212068 \nL 263.645088 31.101538 \nL 263.930956 27.647852 \nL 264.220997 27.038378 \nL 264.533991 37.399436 \nL 264.826119 37.602594 \nL 265.10364 28.8668 \nL 265.42498 25.209956 \nL 265.702501 33.94575 \nL 266.007149 35.571014 \nL 266.318056 25.413114 \nL 266.654003 41.665754 \nL 266.956564 30.288906 \nL 267.288337 38.618384 \nL 267.603418 23.178376 \nL 267.918498 32.726802 \nL 268.204366 32.523644 \nL 268.521533 32.117328 \nL 268.817834 21.959428 \nL 269.485555 42.884701 \nL 269.777682 38.821542 \nL 270.378631 35.774172 \nL 270.683278 41.259438 \nL 270.998359 41.05628 \nL 271.300919 39.0247 \nL 271.60348 22.568902 \nL 271.893521 38.415226 \nL 272.189822 30.89838 \nL 272.490296 33.94575 \nL 272.80329 53.245759 \nL 273.110024 26.632062 \nL 273.416758 32.117328 \nL 273.738099 26.225746 \nL 274.032313 34.555224 \nL 274.334874 34.96154 \nL 274.645781 29.679432 \nL 274.927476 31.91417 \nL 275.236296 31.101538 \nL 275.54303 31.304696 \nL 275.835158 38.212068 \nL 276.131459 36.586804 \nL 276.442366 39.837332 \nL 276.747014 20.74048 \nL 277.068354 33.539434 \nL 277.389695 34.758382 \nL 277.706862 41.259438 \nL 278.001076 26.428904 \nL 278.28903 34.96154 \nL 278.595764 35.164698 \nL 278.919192 41.05628 \nL 279.215492 28.054168 \nL 279.50762 38.00891 \nL 279.803921 42.07207 \nL 280.108568 34.148908 \nL 280.427822 29.679432 \nL 280.73873 20.943638 \nL 281.049637 45.728913 \nL 281.337591 46.541545 \nL 281.652672 28.054168 \nL 281.957319 27.85101 \nL 282.2724 45.728913 \nL 282.58748 31.91417 \nL 282.906734 31.91417 \nL 283.215555 35.97733 \nL 283.524375 24.80364 \nL 283.839456 42.478385 \nL 284.135757 29.476274 \nL 284.471704 36.383646 \nL 284.797217 26.428904 \nL 285.103951 33.336276 \nL 285.431552 37.805752 \nL 285.738286 36.180488 \nL 286.042933 27.241536 \nL 286.339234 32.523644 \nL 286.623015 23.78785 \nL 286.919316 38.618384 \nL 287.194751 25.616272 \nL 287.514005 35.367856 \nL 287.801959 27.647852 \nL 288.10452 29.476274 \nL 288.417514 26.428904 \nL 288.732594 31.711012 \nL 289.028895 25.209956 \nL 289.356496 41.462596 \nL 289.707049 39.634174 \nL 289.999176 44.916281 \nL 290.32469 19.72469 \nL 290.606385 41.05628 \nL 290.904772 32.523644 \nL 291.230286 35.774172 \nL 291.534933 32.523644 \nL 291.820801 30.89838 \nL 292.146315 28.257326 \nL 292.457222 36.383646 \nL 292.772303 36.383646 \nL 293.08947 36.789962 \nL 293.412897 39.0247 \nL 293.753017 32.92996 \nL 294.082704 19.927848 \nL 294.404044 38.00891 \nL 295.044638 31.101538 \nL 295.355546 44.103649 \nL 295.672713 42.07207 \nL 295.966927 43.494175 \nL 296.267401 27.241536 \nL 296.572049 34.352066 \nL 296.866263 46.338387 \nL 297.181344 40.243648 \nL 297.811505 33.94575 \nL 298.095286 37.196278 \nL 298.391587 28.663642 \nL 299.017575 38.618384 \nL 299.328482 30.085748 \nL 299.637303 35.164698 \nL 299.937777 27.038378 \nL 300.231991 29.476274 \nL 300.534552 42.884701 \nL 300.847546 37.196278 \nL 301.12924 38.618384 \nL 301.458927 29.679432 \nL 301.755228 25.413114 \nL 302.345743 38.00891 \nL 302.652477 29.88259 \nL 302.969644 29.679432 \nL 303.270119 36.99312 \nL 303.564333 24.397324 \nL 304.198667 48.369967 \nL 304.797529 33.742592 \nL 305.11261 35.367856 \nL 305.413084 46.135229 \nL 305.717731 38.212068 \nL 306.024465 33.539434 \nL 306.314506 27.038378 \nL 306.644193 41.05628 \nL 306.944667 35.571014 \nL 307.257661 26.022588 \nL 307.574828 36.99312 \nL 307.862783 32.92996 \nL 308.152824 38.618384 \nL 308.449125 41.05628 \nL 308.753772 48.573125 \nL 309.354721 26.022588 \nL 309.661455 29.069958 \nL 309.964015 42.275228 \nL 310.254056 34.352066 \nL 310.554531 38.212068 \nL 310.842485 30.695222 \nL 311.159652 35.164698 \nL 311.508119 30.288906 \nL 311.789813 19.72469 \nL 312.096547 23.78785 \nL 312.394935 38.415226 \nL 312.684976 34.96154 \nL 313.000056 34.555224 \nL 313.304704 35.97733 \nL 313.603091 26.83522 \nL 313.897306 36.383646 \nL 314.20404 34.96154 \nL 314.521207 37.805752 \nL 314.792468 20.74048 \nL 315.06373 39.227858 \nL 315.343338 27.444694 \nL 315.652158 38.618384 \nL 315.958892 22.568902 \nL 316.259366 35.571014 \nL 316.555667 23.78785 \nL 316.849882 30.695222 \nL 317.171222 26.022588 \nL 317.473783 29.88259 \nL 317.776344 23.991008 \nL 318.060125 39.227858 \nL 318.358512 38.821542 \nL 318.636034 37.805752 \nL 319.257848 45.525755 \nL 319.543716 45.728913 \nL 319.835844 35.367856 \nL 320.132145 40.649964 \nL 320.424272 35.571014 \nL 321.029394 33.742592 \nL 321.344474 35.774172 \nL 321.667901 35.367856 \nL 321.980895 28.054168 \nL 322.264676 33.336276 \nL 322.558891 41.259438 \nL 322.869798 40.446806 \nL 323.161926 31.304696 \nL 323.48118 41.462596 \nL 323.779567 43.087859 \nL 324.102994 31.711012 \nL 324.418075 31.91417 \nL 324.731069 38.00891 \nL 325.035716 38.00891 \nL 325.371663 42.884701 \nL 325.690917 17.896268 \nL 325.999737 29.476274 \nL 326.314818 34.96154 \nL 326.627812 22.162586 \nL 326.930373 36.383646 \nL 327.220414 36.383646 \nL 327.514628 25.413114 \nL 327.806756 26.022588 \nL 328.090537 30.288906 \nL 328.399357 40.649964 \nL 328.706091 38.821542 \nL 329.004479 40.853122 \nL 329.296607 32.726802 \nL 329.624207 30.288906 \nL 329.920508 36.180488 \nL 330.204289 36.180488 \nL 330.515196 31.304696 \nL 330.813584 40.243648 \nL 331.109885 29.476274 \nL 331.429139 39.0247 \nL 331.731699 39.431016 \nL 332.038433 30.085748 \nL 332.324301 41.462596 \nL 332.628949 42.275228 \nL 332.935683 32.117328 \nL 333.23407 39.837332 \nL 333.530371 41.665754 \nL 333.807892 32.523644 \nL 334.1188 44.916281 \nL 334.392148 37.602594 \nL 334.680102 34.758382 \nL 335.009789 26.428904 \nL 335.329043 33.133118 \nL 335.642037 46.744703 \nL 335.915385 35.367856 \nL 336.232552 31.101538 \nL 336.535113 32.320486 \nL 336.860626 43.900491 \nL 337.497047 30.288906 \nL 337.799608 33.133118 \nL 338.118862 33.133118 \nL 338.444376 35.164698 \nL 338.763629 38.618384 \nL 339.393791 30.288906 \nL 339.698438 39.431016 \nL 340.005172 33.336276 \nL 340.295213 41.868912 \nL 340.885728 21.146796 \nL 341.190376 31.91417 \nL 341.505456 29.476274 \nL 341.816363 50.401547 \nL 342.121011 29.476274 \nL 342.429832 30.085748 \nL 342.765778 43.494175 \nL 343.093379 31.304696 \nL 343.393853 26.428904 \nL 343.690154 27.038378 \nL 343.994801 33.336276 \nL 344.620789 39.0247 \nL 344.921263 20.537322 \nL 345.217564 45.322597 \nL 345.540991 29.679432 \nL 345.828946 42.275228 \nL 346.127333 41.259438 \nL 346.461193 33.336276 \nL 346.786707 31.91417 \nL 347.126827 26.022588 \nL 347.437734 25.209956 \nL 347.769508 47.354177 \nL 348.395496 23.584692 \nL 348.725183 21.146796 \nL 349.04235 37.399436 \nL 349.35743 34.148908 \nL 349.691291 38.212068 \nL 350.029324 36.383646 \nL 350.363184 32.320486 \nL 350.659485 32.523644 \nL 351.304253 29.88259 \nL 351.606813 31.91417 \nL 351.911461 31.711012 \nL 352.251581 29.476274 \nL 352.869222 38.821542 \nL 353.205169 28.054168 \nL 353.51399 31.711012 \nL 353.820724 33.336276 \nL 354.108678 42.884701 \nL 354.404979 40.853122 \nL 354.738839 24.80364 \nL 355.06644 38.821542 \nL 355.72164 28.054168 \nL 356.370581 36.180488 \nL 356.689835 36.383646 \nL 357.009088 18.7089 \nL 357.62673 33.539434 \nL 357.945984 30.085748 \nL 358.267324 34.758382 \nL 358.580318 33.539434 \nL 358.907918 25.81943 \nL 359.544339 29.273116 \nL 359.87194 43.291017 \nL 360.172414 32.117328 \nL 360.468715 47.963651 \nL 360.765016 23.178376 \nL 361.061316 40.04049 \nL 361.376397 33.94575 \nL 361.697737 17.083636 \nL 362.008645 39.227858 \nL 362.321639 40.04049 \nL 362.647152 35.97733 \nL 362.95806 42.681543 \nL 363.575701 32.523644 \nL 363.890781 32.726802 \nL 364.195429 36.383646 \nL 364.529289 38.212068 \nL 364.863149 32.726802 \nL 365.17823 31.507854 \nL 365.474531 29.273116 \nL 365.789611 28.054168 \nL 366.115125 42.275228 \nL 366.39056 27.241536 \nL 366.678514 32.117328 \nL 366.985248 34.96154 \nL 367.321195 39.227858 \nL 367.636275 30.89838 \nL 367.907537 28.460484 \nL 368.222617 42.07207 \nL 368.879905 24.600482 \nL 369.197072 31.711012 \nL 369.499633 27.647852 \nL 369.835579 39.634174 \nL 370.15066 39.0247 \nL 370.482433 41.868912 \nL 370.780821 31.711012 \nL 371.406809 45.932071 \nL 371.742756 31.91417 \nL 371.742756 31.91417 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 52.160938 224.64 \nL 52.160938 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 386.960938 224.64 \nL 386.960938 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 52.160937 224.64 \nL 386.960938 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 52.160937 7.2 \nL 386.960938 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 286.29375 219.64 \nL 379.960938 219.64 \nQ 381.960938 219.64 381.960938 217.64 \nL 381.960938 203.961875 \nQ 381.960938 201.961875 379.960938 201.961875 \nL 286.29375 201.961875 \nQ 284.29375 201.961875 284.29375 203.961875 \nL 284.29375 217.64 \nQ 284.29375 219.64 286.29375 219.64 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_30\">\n     <path d=\"M 288.29375 210.060312 \nL 308.29375 210.060312 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_31\"/>\n    <g id=\"text_17\">\n     <!-- Double DQN -->\n     <g transform=\"translate(316.29375 213.560312)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 53.21875 1.3125 \nL 66.21875 -12.890625 \nL 54.296875 -12.890625 \nL 43.5 -1.21875 \nQ 41.890625 -1.3125 41.03125 -1.359375 \nQ 40.1875 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.859375 \nQ 5.609375 19.140625 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 23.6875 67.984375 14.640625 \nQ 62.890625 5.609375 53.21875 1.3125 \nz\n\" id=\"DejaVuSans-81\"/>\n       <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"201.5625\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"265.039062\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"292.822266\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"354.345703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"386.132812\" xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"463.134766\" xlink:href=\"#DejaVuSans-81\"/>\n      <use x=\"541.845703\" xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd390b93753\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"52.160938\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "''' An example of learning a Deep-Q Agent on Leduc Holdem\n",
    "'''\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import rlcard\n",
    "from rlcard.agents import DQNAgentPytorch as DQNAgent\n",
    "from rlcard.agents import RandomAgent\n",
    "from rlcard.utils import set_global_seed, tournament\n",
    "from rlcard.utils import Logger\n",
    "\n",
    "# Make environment\n",
    "env = rlcard.make('blackjack', config={'seed': 0})\n",
    "eval_env = rlcard.make('blackjack', config={'seed': 0})\n",
    "\n",
    "# Set the iterations numbers and how frequently we evaluate the performance\n",
    "evaluate_every = 100\n",
    "evaluate_num = 1000\n",
    "episode_num = 100000\n",
    "\n",
    "# The intial memory size\n",
    "memory_init_size = 1000\n",
    "\n",
    "# Train the agent every X steps\n",
    "train_every = 1\n",
    "\n",
    "# The paths for saving the logs and learning curves\n",
    "log_dir = './experiments/blackjack_double_dqn_result/'\n",
    "\n",
    "# Set a global seed\n",
    "set_global_seed(0)\n",
    "\n",
    "agent = DQNAgent(scope='double dqn',\n",
    "                 action_num=env.action_num,\n",
    "                 replay_memory_init_size=memory_init_size,\n",
    "                 train_every=train_every,\n",
    "                 state_shape=env.state_shape,\n",
    "                 mlp_layers=[128, 128],\n",
    "                 device=torch.device('cpu'))\n",
    "random_agent = RandomAgent(action_num=eval_env.action_num)\n",
    "env.set_agents([agent, random_agent])\n",
    "eval_env.set_agents([agent, random_agent])\n",
    "\n",
    "# Init a Logger to plot the learning curve\n",
    "logger = Logger(log_dir)\n",
    "\n",
    "for episode in range(episode_num):\n",
    "\n",
    "    # Generate data from the environment\n",
    "    trajectories, _ = env.run(is_training=True)\n",
    "\n",
    "    # Feed transitions into agent memory, and train the agent\n",
    "    for ts in trajectories[0]:\n",
    "        agent.feed(ts)\n",
    "\n",
    "    # Evaluate the performance. Play with random agents.\n",
    "    if episode % evaluate_every == 0:\n",
    "        logger.log_performance(env.timestep, tournament(eval_env, evaluate_num)[0])\n",
    "\n",
    "# Close files in the logger\n",
    "logger.close_files()\n",
    "\n",
    "# Plot the learning curve\n",
    "logger.plot('Double DQN')\n",
    "\n",
    "# Save model\n",
    "save_dir = 'models/blackjack_double_dqn_pytorch'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "state_dict = agent.get_state_dict()\n",
    "print(state_dict. keys())\n",
    "torch.save(state_dict, os.path.join(save_dir, 'model.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-0.045]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "\n",
    "from rlcard.agents import DQNAgentPytorch as DQNAgent\n",
    "\n",
    "\n",
    "# Set 'record_action' to True because we need it to print results\n",
    "player_num = 2\n",
    "env = rlcard.make('blackjack', config={'record_action': True, 'game_player_num': player_num})\n",
    "\n",
    "\n",
    "evaluate_every = 100\n",
    "evaluate_num = 1000\n",
    "episode_num = 100000\n",
    "memory_init_size = 1000\n",
    "train_every = 1\n",
    "\n",
    "# Double DQN model\n",
    "agent_doubledqn = DQNAgent(scope='double dqn',\n",
    "                 action_num=env.action_num,\n",
    "                 replay_memory_init_size=memory_init_size,\n",
    "                 train_every=train_every,\n",
    "                 state_shape=env.state_shape,\n",
    "                 mlp_layers=[128, 128],\n",
    "                 device=torch.device('cpu'))\n",
    "\n",
    "DQN_PATH = './models/blackjack_double_dqn_pytorch/model.pth'\n",
    "agent.load(torch.load(DQN_PATH))\n",
    "agent.use_raw=True\n",
    "\n",
    "# DQN model\n",
    "params = {\n",
    "    \"scope\":\"DQN-Agent\",\n",
    "    \"num_actions\":env.action_num,\n",
    "    \"replay_memory_size\":memory_init_size,\n",
    "    \"num_states\":env.state_shape,\n",
    "    \"discount_factor\" :0.99,\n",
    "    \"epsilon_start\" : 1.0,\n",
    "    \"epsilon_end\" : 0.1,\n",
    "    \"epsilon_decay_steps\":20000,\n",
    "    \"batch_size\":32,\n",
    "    \"train_every\":1,\n",
    "    \"mlp_layers\":[128,128],\n",
    "    \"lr\":0.00005,\n",
    "}\n",
    "\n",
    "agent_conf = DQN_conf(**params)\n",
    "agent_dqn = DQN_agent(agent_conf)\n",
    "DQN_PATH = './models/blackjack_holdem_dqn_pytorch/model.pth'\n",
    "agent_dqn.load(torch.load(DQN_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([[[{'obs': array([15, 10]), 'legal_actions': [0, 1]},\n",
       "    0,\n",
       "    -1,\n",
       "    {'obs': array([23, 20]), 'legal_actions': [0, 1]},\n",
       "    True]]],\n",
       " array([-1]))"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "eval_env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">> Blackjack human agent\n",
      ">> Start a new game\n",
      ">> Player 0 chooses 0\n",
      ">> Player 1 chooses hit\n",
      ">> Player 0 chooses 1\n",
      ">> Player 1 chooses stand\n",
      "===============   Dealer hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│5        │   │K        │   │A        │   │2        │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│    ♠    │   │    ♦    │   │    ♦    │   │    ♠    │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│        5│   │        K│   │        A│   │        2│\n",
      "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 0 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│4        │   │5        │   │9        │   │8        │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│    ♦    │   │    ♥    │   │    ♥    │   │    ♣    │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│        4│   │        5│   │        9│   │        8│\n",
      "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 1 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│4        │   │6        │   │J        │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│    ♠    │   │    ♥    │   │    ♦    │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│        4│   │        6│   │        J│\n",
      "└─────────┘   └─────────┘   └─────────┘\n",
      "===============     Result     ===============\n",
      "Player 0 lose 1 chip!\n",
      "\n",
      "Player 1 win 1 chip!\n",
      "\n",
      ">> Start a new game\n",
      ">> Player 0 chooses 1\n",
      ">> Player 1 chooses stand\n",
      ">> Player 0 chooses 0\n",
      "===============   Dealer hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│Q        │   │6        │   │7        │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│    ♦    │   │    ♥    │   │    ♠    │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│        Q│   │        6│   │        7│\n",
      "└─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 0 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│6        │   │J        │   │A        │   │J        │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│    ♠    │   │    ♠    │   │    ♠    │   │    ♥    │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│        6│   │        J│   │        A│   │        J│\n",
      "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 1 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐\n",
      "│10       │   │4        │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│    ♥    │   │    ♣    │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│       01│   │        4│\n",
      "└─────────┘   └─────────┘\n",
      "===============     Result     ===============\n",
      "Player 0 lose 1 chip!\n",
      "\n",
      "Player 1 win 1 chip!\n",
      "\n",
      ">> Start a new game\n",
      ">> Player 0 chooses 1\n",
      ">> Player 1 chooses stand\n",
      "===============   Dealer hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│A        │   │5        │   │9        │   │K        │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│    ♠    │   │    ♥    │   │    ♠    │   │    ♥    │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│        A│   │        5│   │        9│   │        K│\n",
      "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 0 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│10       │   │Q        │   │3        │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│    ♣    │   │    ♣    │   │    ♦    │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│       01│   │        Q│   │        3│\n",
      "└─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 1 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐\n",
      "│K        │   │Q        │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│    ♣    │   │    ♦    │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│        K│   │        Q│\n",
      "└─────────┘   └─────────┘\n",
      "===============     Result     ===============\n",
      "Player 0 lose 1 chip!\n",
      "\n",
      "Player 1 win 1 chip!\n",
      "\n",
      ">> Start a new game\n",
      ">> Player 0 chooses 0\n",
      ">> Player 1 chooses hit\n",
      "===============   Dealer hand   ===============\n",
      "┌─────────┐   ┌─────────┐\n",
      "│Q        │   │A        │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│    ♣    │   │    ♦    │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│        Q│   │        A│\n",
      "└─────────┘   └─────────┘\n",
      "===============   Player 0 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│8        │   │9        │   │Q        │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│    ♥    │   │    ♦    │   │    ♥    │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│        8│   │        9│   │        Q│\n",
      "└─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 1 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│8        │   │7        │   │10       │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│    ♣    │   │    ♠    │   │    ♣    │\n",
      "│         │   │         │   │         │\n",
      "│         │   │         │   │         │\n",
      "│        8│   │        7│   │       01│\n",
      "└─────────┘   └─────────┘   └─────────┘\n",
      "===============     Result     ===============\n",
      "Player 0 lose 1 chip!\n",
      "\n",
      "Player 1 lose 1 chip!\n",
      "\n",
      ">> Start a new game\n",
      ">> Player 0 chooses 0\n",
      ">> Player 1 chooses hit\n",
      ">> Player 0 chooses 1\n",
      ">> Player 1 chooses hit\n",
      "===============   Dealer hand   ===============\n",
      "┌─────────┐   ┌─────────┐\n",
      "│10       │   │10       │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│    ♦    │   │    ♠    │\n",
      "│         │   │         │\n",
      "│         │   │         │\n",
      "│       01│   │       01│\n",
      "└─────────┘   └─────────┘\n",
      "===============   Player 0 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│5        │   │5        │   │K        │   │K        │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│    ♣    │   │    ♠    │   │    ♣    │   │    ♦    │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│        5│   │        5│   │        K│   │        K│\n",
      "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
      "===============   Player 1 Hand   ===============\n",
      "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
      "│A        │   │J        │   │7        │   │7        │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│    ♥    │   │    ♣    │   │    ♥    │   │    ♣    │\n",
      "│         │   │         │   │         │   │         │\n",
      "│         │   │         │   │         │   │         │\n",
      "│        A│   │        J│   │        7│   │        7│\n",
      "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
      "===============     Result     ===============\n",
      "Player 0 lose 1 chip!\n",
      "\n",
      "Player 1 lose 1 chip!\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce9845bf2925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Press any key to continue...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/rlcard/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rlcard/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "import rlcard\n",
    "from rlcard.agents import RandomAgent as RandomAgent\n",
    "from rlcard.utils.utils import print_card\n",
    "from rlcard.agents import DQNAgentPytorch as DQNAgent\n",
    "from rlcard.agents import DQN_agent,DQN_conf\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Make environment and enable human mode\n",
    "# Set 'record_action' to True because we need it to print results\n",
    "player_num = 2\n",
    "env = rlcard.make('blackjack', config={'record_action': True, 'game_player_num': player_num})\n",
    "\n",
    "\n",
    "evaluate_every = 100\n",
    "evaluate_num = 1000\n",
    "episode_num = 100000\n",
    "memory_init_size = 1000\n",
    "train_every = 1\n",
    "\n",
    "# Double DQN model\n",
    "agent = DQNAgent(scope='double dqn',\n",
    "                 action_num=env.action_num,\n",
    "                 replay_memory_init_size=memory_init_size,\n",
    "                 train_every=train_every,\n",
    "                 state_shape=env.state_shape,\n",
    "                 mlp_layers=[128, 128],\n",
    "                 device=torch.device('cpu'))\n",
    "\n",
    "DQN_PATH = './models/blackjack_double_dqn_pytorch/model.pth'\n",
    "agent.load(torch.load(DQN_PATH))\n",
    "agent.use_raw=True\n",
    "\n",
    "# # DQN model\n",
    "# params = {\n",
    "#     \"scope\":\"DQN-Agent\",\n",
    "#     \"num_actions\":env.action_num,\n",
    "#     \"replay_memory_size\":memory_init_size,\n",
    "#     \"num_states\":env.state_shape,\n",
    "#     \"discount_factor\" :0.99,\n",
    "#     \"epsilon_start\" : 1.0,\n",
    "#     \"epsilon_end\" : 0.1,\n",
    "#     \"epsilon_decay_steps\":20000,\n",
    "#     \"batch_size\":32,\n",
    "#     \"train_every\":1,\n",
    "#     \"mlp_layers\":[128,128],\n",
    "#     \"lr\":0.00005,\n",
    "# }\n",
    "\n",
    "# agent_conf = DQN_conf(**params)\n",
    "# agent = DQN_agent(agent_conf)\n",
    "# DQN_PATH = './models/blackjack_holdem_dqn_pytorch/model.pth'\n",
    "# agent.load(torch.load(DQN_PATH))\n",
    "\n",
    "# human_agent = HumanAgent(env.action_num)\n",
    "random_agent = RandomAgent(env.action_num)\n",
    "random_agent1 = RandomAgent(env.action_num)\n",
    "# env.set_agents([human_agent, random_agent])\n",
    "env.set_agents([agent, random_agent])\n",
    "\n",
    "print(\">> Blackjack human agent\")\n",
    "\n",
    "while (True):\n",
    "    print(\">> Start a new game\")\n",
    "\n",
    "    trajectories, payoffs = env.run(is_training=False)\n",
    "    # If the human does not take the final action, we need to\n",
    "    # print other players action\n",
    "\n",
    "    if len(trajectories[0]) != 0:\n",
    "        final_state = []\n",
    "        action_record = []\n",
    "        state = []\n",
    "        _action_list = []\n",
    "\n",
    "        for i in range(player_num):\n",
    "            final_state.append(trajectories[i][-1][-2])\n",
    "            state.append(final_state[i]['raw_obs'])\n",
    "\n",
    "        action_record.append(final_state[i]['action_record'])\n",
    "        for i in range(1, len(action_record) + 1):\n",
    "            _action_list.insert(0, action_record[-i])\n",
    "\n",
    "        for pair in _action_list[0]:\n",
    "            print('>> Player', pair[0], 'chooses', pair[1])\n",
    "\n",
    "    # Let's take a look at what the agent card is\n",
    "    print('===============   Dealer hand   ===============')\n",
    "    print_card(state[0]['state'][1])\n",
    "\n",
    "    for i in range(player_num):\n",
    "        print('===============   Player {} Hand   ==============='.format(i))\n",
    "        print_card(state[i]['state'][0])\n",
    "\n",
    "    print('===============     Result     ===============')\n",
    "    for i in range(player_num):\n",
    "        if payoffs[i] == 1:\n",
    "            print('Player {} win {} chip!'.format(i, payoffs[i]))\n",
    "        elif payoffs[i] == 0:\n",
    "            print('Player {} is tie'.format(i))\n",
    "        else:\n",
    "            print('Player {} lose {} chip!'.format(i, -payoffs[i]))\n",
    "        print('')\n",
    "\n",
    "    input(\"Press any key to continue...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1.0, -0.4107]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from rlcard.utils import set_global_seed, tournament\n",
    "tournament(env,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}